---
title: 浅析 I/O（3）—— I/O模型
author: ratears
categories:
	- [Operating-Systems,I/O]
tags:
	- Operating-Systems
	- I/O
date: 2022-09-19 22:06:09
updated: 2022-09-19 22:06:09
---

<br>

- 网络通信中，最底层的就是内核中的网络 I/O 模型了。

> 随着技术的发展，操作系统内核的网络模型衍生出了**五种 I/O 模型**，《UNIX网络编程》一书将这五种 I/O 模型分为 `阻塞式 I/O`、`非阻塞式 I/O`、`I/O 复用`、`信号驱动式 I/O` 和 `异步 I/O`。每一种 I/O 模型的出现，都是基于前一种 I/O 模型的优化升级。

<br>

<br>

<br>

# ① 阻塞IO模型

- 阻塞式 IO （Blocking IO）：应用进程从发起 IO 系统调用，至内核返回成功标识，这整个期间是处于阻塞状态的。

> 当应用A发起读取数据申请时，在内核数据没有准备好之前，应用A会一直处于等待数据状态，直到内核把数据准备好了交给应用A才结束。

> **Tips：我们之前所学过的所有的套接字，默认都是阻塞方式。**



<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.7wrvgu36e5k.webp" width="75%">



<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.qd7jcvl1as0.webp" width="75%">




- 优点：开发相对简单，在阻塞期间，用户线程被挂起，挂起期间不会占用CPU资源；
- 缺点：
  - 1）连接利用率不高，内核如果没有响应数据，则该连接一直处于阻塞状态，占用连接资源
  - 2）一个线程维护一个IO资源，当用大量并发请求时，需要创建等价的线程来处理请求，不适合用于高并发场景；

<br>

<br>

<br>

# ② 非阻塞IO模型

- 非阻塞式IO（Non-Blocking IO）：应用进程可以将 Socket 设置为非阻塞，这样应用进程在发起 IO 系统调用后，会立刻返回。应用进程可以轮询的发起 IO 系统调用，直到内核返回成功标识。

> 当应用A发起读取数据申请时，在内核数据没有准备好之前，应用A会一直处于等待数据状态，直到内核把数据准备好了交给应用A才结束。



<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3utzrtza30.webp" width="70%">



<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.79dq8pifksg0.webp" width="60%">



- 优点：每次发起IO调用去内核获取数据时，在内核等待数据的过程中可以立即返回，用户线程不会被阻塞，实时性较好；
- 缺点：
  - 1）当用户线程A没有获取到数据时，不断轮询内核，查看是否有新的数据，占用大量CPU时间，效率不高；
  - 2）和阻塞IO一样，一个线程维护一个IO资源，当用大量并发请求时，需要创建等价的线程来处理请求，不适合用于高并发场景；

<br>

<br>

<br>

# ③ 复用IO模型（IO多路复用模型）

- IO 多路复用（IO Multiplexin）：可以将多个应用进程的 Socket 注册到一个 Select（多路复用器）上，然后使用一个进程来监听该 Select（该操作会阻塞），Select 会监听所有注册进来的 Socket。只要有一个 Socket 的数据准备好，就会返回该Socket。再由应用进程发起 IO 系统调用，来完成数据读取。



<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5bxxajmccj00.webp" width="60%">



<br>

<br>

&emsp;&emsp;如果在并发的环境下，可能会N个人向应用B发送消息，这种情况下我们的应用就必须创建多个线程去接收N个人发送过来的请求，每个请求都是一个独立的线程来处理；在并发量呈线性增长时，我们需要创建的线程数也随之而然的激增；



<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4qf0gyqhcao0.webp" width="70%">



&emsp;&emsp;这种情况下应用B就需要创建N个线程去读取数据，同时又因为应用线程是不知道什么时候会有数据读取，为了保证消息能及时读取到，那么这些线程自己必须不断的向内核发送请求来读取数据（非阻塞式）；

&emsp;&emsp;这么多的线程不断请求数据，先不说服务器能不能扛得住这么多线程，就算扛得住那么很明显这种方式是不是太浪费资源了，线程是我们操作系统的宝贵资源，大量的线程用来去读取数据了，那么就意味着能做其它事情的线程就会少。

&emsp;&emsp;后来，有人就提出了一个思路，能不能提供一种方式，可以由一个线程监控多个网络请求（**linux系统把所有网络请求以一个fd来标识，我们后面将称为fd即文件描述符**），这样就可以只需要一个或几个线程就可以完成数据状态询问的操作，当有数据准备就绪之后再分配对应的线程去读取数据，这么做就可以节省出大量的线程资源出来，这个就是**IO复用模型**的思路。



<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4gods2kobxu0.webp" width="70%">



&emsp;&emsp;IO复用模型的思路就是系统提供了一种函数（select/poll/epoll）可以同时监控多个fd的操作，有了这个函数后，应用线程通过调用select函数就可以同时监控多个fd，如果select监听的fd都没有可读数据，**select调用进程会被阻塞**；而只要有任何一个fd准备就绪了，select函数就会返回可读状态，这时询问线程再去通知处理数据的线程，对应的线程此时再发起请求去读取内核中准备好的数据；

> **Tips：在IO复用模型下，允许单线程内处理多个IO请求；**

<br>

<br>

- <font color="red">**Linux中IO复用的实现方式主要有select，poll和epoll**</font>

## 1）select

- **线性轮询扫描所有的fd**，不管他们是否活跃，监听的IO最大连接数不能多于FD_ SIZE（32位操作系统1024，64位操作系统2048）。
- 时间复杂度O(n)



> **Tips：select方式仅仅知道有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），用户线程只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。**



<br>

## 2）poll

- 原理和select相似，poll底层需要分配一个pollfd结构数组，维护在内核中，它没有数量限制，但IO数量大，扫描线性性能下降。
- 时间复杂度O(n)



<br>

## 3）epoll

- 用于代替poll和select，没有大小限制。**epoll采用事件驱动代替了轮询**，epoll会把哪个流发生了怎样的I/O事件通知用户线程，所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时用户线程对这些流的操作都是有意义的。（复杂度降低到了O(1)），另外epoll模型采用mmap内存映射实现内核与用户空间的消息传递，减少用户态和内核态数据传输的开销，epoll模型在Linux2.6后内核支持。
- 时间复杂度O(1)



<br>

---

- <font color="red">select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符准备就绪，能够通知程序进行相应的读写操作。**但select，poll，epoll本质上都是同步I/O**，因为他们都需要在读写事件就绪后自己负责进行读写(一个个的处理)，也就是说这个读写过程是**阻塞的**，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。</font>

> Tips：epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现



<br>

## 复用IO模型小结

- 关于IO复用模型，下面这个例子可以很好的说明IO复用模型的原理：

> 某教室有10名学生和1名老师，这些学生上课会不停的提问，所以一个老师处理不了这么多的问题。那么学校为每个学生都配一名老师，也就是这个教室目前有10名老师。此后，只要有新的转校生，那么就会为这个学生专门分配一个老师，因为转校生也喜欢提问题。如果把以上例子中的学生比作客户端，那么老师就是负责进行数据交换的服务端。则该例子可以比作是多进程的方式。
>
> 后来有一天，来了一位具有超能力的老师，这位老师回答问题非常迅速，并且可以应对所有的问题。而这位老师采用的方式是学生提问前必须先举手，确认举手学生后在回答问题。则现在的情况就是IO复用。



- **IO复用模型的优点**：系统不必创建和维护大量的线程，只使用一个或几个线程来监听select选择器的操作，而一个选择器可同时处理成千上万个连接，大大减少了系统的开销；
- **IO复用模型的缺点**：select本质上还是同步阻塞模式；



&emsp;&emsp;**总结：** 复用IO的基本思路就是通过select或poll、epoll来监控多fd ，来达到不必为每个fd创建一个对应的监控线程，从而减少线程资源创建的目的。**复用IO模型的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。**

<br>

<br>

<br>

# ④ 信号驱动IO模型

- 信号驱动 IO（Signal Driven IO）：可以为 Socket 开启信号驱动 IO 功能，应用进程需向内核注册一个信号处理程序，该操作并立即返回。当内核中有数据准备好，会发送一个信号给应用进程，应用进程便可以在信号处理程序中发起 IO 系统调用，来完成数据读取了。



<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.75x9qhoc2nk0.webp" width="60%">

<br>

<br>

&emsp;&emsp;当进程发起一个IO操作，系统调用sigaction执行一个信号处理函数，该函数向内核注册一个信号处理函数（回调函数），然后进程返回，并且不阻塞当前进程；当内核数据准备好时，内核使用信号（SIGIO）通知应用线程调用recvfrom来读取数据（运行回调函数）。

&emsp;&emsp;信号驱动IO它也可以看成是一种**异步非阻塞IO**



<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.1qy5yemvy6rk.webp" width="60%">



&emsp;&emsp;我们说信号驱动IO模型是一种异步非阻塞IO模型，指的是用户线程去内核空间请求数据时，直接注册一个信号处理函数，然后用户线程返回（异步），而内核空间接收到请求后，开始处理（此时并不会阻塞，内核空间可以同时接收多个请求，注册多个信号处理函数）；

&emsp;&emsp;但是，等到内核空间读取到数据之后，应用线程需要将数据从内核空间拷贝到用户空间，**此时是用户线程是阻塞的；**也就是说：**应用程序将数据从内核态拷贝到用户态的过程是阻塞等待的，这是和异步IO的本质区别；**

<br>

<br>

<br>

# ⑤ 异步IO模型

- 异步 IO（Asynchronous IO）： 应用进程发起 IO 系统调用后，会立即返回。当内核中数据完全准备后，并且也复制到了用户空间，会产生一个信号来通知应用进程。

<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.448rjyvy1va0.webp" width="70%">



<br>

<br>

&emsp;&emsp;在前面几种IO模型中，应用线程要获取数据总是先发送请求到内核，然后进行如下处理：

> 1）**阻塞IO**：应用线程等待内核响应数据，期间什么都不能做
>
> 2）**非阻塞IO**：应用线程立即响应，可以去处理其他事情，但需要不断轮询内核去获取数据
>
> 3）**复用IO**：采用IO复用机制，请求都先交给select函数，由应用线程调用select函数来轮询所有的请求，当有请求需要获取数据时，应用线程再去内核获取数据；
>
> 4）**信号驱动IO**：系统注册一个信号处理函数（回调函数），然后应用线程返回（不阻塞）；当内核中准备好数据后，应用线程需要把内核中的数据拷贝到用户空间，**此时用户线程是阻塞的**；

&emsp;&emsp;在以上4种IO模型中，每次要去读取数据时都是事先发送请求询问内核是否有可读数据，然后再发起真正的读取数据请求；

&emsp;&emsp;在异步IO模型中，应用只需要向内核发送一个请求，告诉内核它要读取数据后即刻返回；内核收到请求后会建立一个信号联系，当数据准备就绪，**内核会主动把数据从内核复制到用户空间**（而信号驱动是告诉应用程序何时可以开始拷贝数据），异步IO模型真正的做到了完完全全的非阻塞；

> Tips：异步IO模型和前面模型最大的区别是：**前4个都是阻塞的**，需要自己把用户准备好的数据，去内核拷贝到用户空间。而全异步不同，用户线程完全不需要关心实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接去使用数据，它是最理想的模型。

<br>

<br>

<br>

# 总结

&emsp;&emsp;从上述五种 IO 模型可以看出，应用进程对内核发起 IO 系统调用后，内核会经过两个阶段来完成数据的传输：

- 第一阶段：等待数据。即应用进程发起 IO 系统调用后，会一直等待数据；当有数据传入服务器，会将数据放入内核空间，此时数据准备好。
- 第二阶段：将数据从内核空间复制到用户空间，并返回给应用程序成功标识。

<img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.1i7o657cwvsw.webp" width="60%">



&emsp;&emsp;前四种模型的第二阶段是相同的，都是处于阻塞状态，其主要区别在第一阶段。而异步 IO 模型则不同，应用进程在这两个阶段是完全不阻塞的。

|   IO 模型    |    第一阶段    | 第二阶段 |
| :----------: | :------------: | :------: |
|   阻塞式IO   |      阻塞      |   阻塞   |
|  非阻塞式IO  |     非阻塞     |   阻塞   |
| IO多路程复用 | 阻塞（Select） |   阻塞   |
| 信号驱动式IO |      异步      |   阻塞   |
|    异步IO    |      异步      |   异步   |

<br>

<br>

<br>

# Reference

- segmentfault：[浅聊Linux的五种IO模型](https://segmentfault.com/a/1190000039898780)
- w3cjava：[五种IO模型：操作系统五种IO模型大全](https://www.w3cjava.com/e-book/operate-system/124699009.html)

<br>

