<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ratears</title>
  
  <subtitle>ratears&#39;s blog</subtitle>
  <link href="https://ratears.github.io/dev.ratears.life/atom.xml" rel="self"/>
  
  <link href="https://ratears.github.io/dev.ratears.life/"/>
  <updated>2023-01-24T16:48:37.000Z</updated>
  <id>https://ratears.github.io/dev.ratears.life/</id>
  
  <author>
    <name>ratears</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《从 0 开始学大数据》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8A%E4%BB%8E-0-%E5%BC%80%E5%A7%8B%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8A%E4%BB%8E-0-%E5%BC%80%E5%A7%8B%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E3%80%8Bstudy-notes/</id>
    <published>2023-01-24T16:48:37.000Z</published>
    <updated>2023-01-24T16:48:37.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="开篇词-为什么说每个软件工程师都应该懂大数据技术？"><a href="#开篇词-为什么说每个软件工程师都应该懂大数据技术？" class="headerlink" title="开篇词 | 为什么说每个软件工程师都应该懂大数据技术？"></a>开篇词 | 为什么说每个软件工程师都应该懂大数据技术？</h1><ul><li><p><strong>软件编程技术-核心价值</strong>：把现实世界的业务操作搬到计算机上，通过计算机软件和网络进行业务和数据处理</p></li><li><p><code>时至今日，能用计算机软件提高效率的地方，几乎已经被全部发掘过了</code>，想让计算机软件包括互联网应用，能够继续提高我们的生活<br>工作效率，那就必须能够发掘出用户自己都没有发现的需求，必须洞悉用户自己都不了解的自己</p></li><li><p><strong>大数据技术和机器学习技术/AI</strong>：计算机软件不能再像以前那样，等用户输入操作，然后根据编写好的逻辑执行用户的操作，而是<br>应该能够预测用户的期望，在你还没想好要做什么的情况下，主动提供操作建议和选项，提醒你应该做什么</p></li><li><p>观点：</p><ul><li>在未来，软件开发将是“面向 AI 编程”，软件的核心业务逻辑和价值将围绕机器学习的结果也就是 AI 展开，软件工程师的工作就是考虑如何将机器学习的结果更好地呈现出来，如何更好地实现人和 AI 的交互。</li><li>即使自己不做大数据与机器学习相关的开发，每个程序员也应该懂大数据和机器学习</li><li>将来，数据会越来越成为公司的核心资产和主要竞争力，公司的业务展开和产品进化也越来越朝着如何利用好数据价值的方向发展。</li><li>不懂大数据和机器学习，可能连最基本的产品逻辑和商业意图都搞不清楚。如果只懂编程，工程师的生存空间会越来越窄，发展也会处处受限</li></ul></li></ul><br><br><br><h1 id="预习模块-3讲"><a href="#预习模块-3讲" class="headerlink" title="预习模块 (3讲)"></a>预习模块 (3讲)</h1><h2 id="预习-01-大数据技术发展史：大数据的前世今生"><a href="#预习-01-大数据技术发展史：大数据的前世今生" class="headerlink" title="预习 01 | 大数据技术发展史：大数据的前世今生"></a>预习 01 | 大数据技术发展史：大数据的前世今生</h2><ul><li><p><strong>学习方法</strong>：不管是学习某门技术，还是讨论某个事情，最好的方式一定不是一头扎到具体细节里，而是应该从时空的角度先了解它的来龙去脉，以及它为什么会演进成为现在的状态。当你深刻理解了这些前因后果之后，再去看现状，就会明朗很多，也能更直接地看到现状背后的本质</p></li><li><p>大数据技术起源于 Google 在 2004 年前后发表的三篇论文（三驾马车）：</p><ul><li>分布式文件系统 GFS</li><li>大数据分布式计算框架 MapReduce</li><li>NoSQL 数据库系统 BigTable</li></ul></li></ul><blockquote><p>Google 的思路是部署一个大规模的服务器集群，通过分布式的方式将海量数据存储在这个集群上，然后利用集群上的所有机器进行数据计算</p></blockquote><ul><li><p>Lucene 开源项目的创始人 Doug Cutting 正在开发开源搜索引擎Nutch，阅读了 Google 的论文后，他非常兴奋，紧接着就根据论文原理初步实现了类似 GFS和 MapReduce 的功能</p></li><li><p>2006 年，Doug Cutting 将这些大数据相关的功能从 Nutch 中分离了出来，然后启动了一个独立的项目专门开发维护大数据技术/Hadoop（主要包括Hadoop 分布式文件系统 HDFS 和大数据计算引擎 MapReduce）</p></li></ul><blockquote><p>我们在做软件开发的时候，也可以多思考一下，我们所开发软件的价值点在哪里？真正需要使用软件实现价值的地方在哪里？你应该关注业务、理解业务，有价值导向，用自己的技术为公司创造真正的价值，进而实现自己的人生价值。而不是整天埋头在需求说明文档里，做一个没有思考的代码机器人</p></blockquote><ul><li>Hadoop 发布之后，Yahoo 很快就用了起来。大概又过了一年到了 2007 年，百度和阿里巴巴也开始使用 Hadoop 进行大数据存储与计算</li><li></li></ul><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">red</span>&gt;</span><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><img src="" width="70%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;开篇词-为什么说每个软件工程师都应该懂大数据技术？&quot;&gt;&lt;a href=&quot;#开篇词-为什么说每个软件工程师都应该懂大数据技术？&quot; class=&quot;headerlink&quot; title=&quot;开篇词 | 为什么说每个软件工程师都应该懂大数据技术？&quot;&gt;&lt;/a&gt;开篇词 | 为什么</summary>
      
    
    
    
    <category term="BigData" scheme="https://ratears.github.io/dev.ratears.life/Categories/BigData/"/>
    
    
    <category term="BigData" scheme="https://ratears.github.io/dev.ratears.life/Tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>《Spring Cloud 微服务项目实战》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8ASpring-Cloud-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8ASpring-Cloud-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/</id>
    <published>2023-01-23T02:45:00.000Z</published>
    <updated>2023-01-23T02:45:00.000Z</updated>
    
    <content type="html"><![CDATA[<br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">red</span>&gt;</span><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><img src="" width="70%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;br&gt;

&lt;br&gt;

&lt;br&gt;

&lt;h1 id=&quot;学习备注&quot;&gt;&lt;a href=&quot;#学习备注&quot; class=&quot;headerlink&quot; title=&quot;学习备注&quot;&gt;&lt;/a&gt;学习备注&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure cla</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>《微服务架构核心 20 讲》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8A%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E6%A0%B8%E5%BF%83-20-%E8%AE%B2%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8A%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E6%A0%B8%E5%BF%83-20-%E8%AE%B2%E3%80%8Bstudy-notes/</id>
    <published>2023-01-23T02:44:28.000Z</published>
    <updated>2023-01-23T02:44:28.000Z</updated>
    
    <content type="html"><![CDATA[<br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">red</span>&gt;</span><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><img src="" width="70%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;br&gt;

&lt;br&gt;

&lt;br&gt;

&lt;h1 id=&quot;学习备注&quot;&gt;&lt;a href=&quot;#学习备注&quot; class=&quot;headerlink&quot; title=&quot;学习备注&quot;&gt;&lt;/a&gt;学习备注&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure cla</summary>
      
    
    
    
    <category term="MicroService" scheme="https://ratears.github.io/dev.ratears.life/Categories/MicroService/"/>
    
    <category term="SpringCloud" scheme="https://ratears.github.io/dev.ratears.life/Categories/MicroService/SpringCloud/"/>
    
    
    <category term="SpringCloud" scheme="https://ratears.github.io/dev.ratears.life/Tags/SpringCloud/"/>
    
    <category term="MicroService" scheme="https://ratears.github.io/dev.ratears.life/Tags/MicroService/"/>
    
  </entry>
  
  <entry>
    <title>《从 0 开始学微服务》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8A%E4%BB%8E-0-%E5%BC%80%E5%A7%8B%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8A%E4%BB%8E-0-%E5%BC%80%E5%A7%8B%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1%E3%80%8Bstudy-notes/</id>
    <published>2023-01-23T02:43:59.000Z</published>
    <updated>2023-01-23T02:43:59.000Z</updated>
    
    <content type="html"><![CDATA[<br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">red</span>&gt;</span><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><img src="" width="70%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;br&gt;

&lt;br&gt;

&lt;br&gt;

&lt;h1 id=&quot;学习备注&quot;&gt;&lt;a href=&quot;#学习备注&quot; class=&quot;headerlink&quot; title=&quot;学习备注&quot;&gt;&lt;/a&gt;学习备注&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure cla</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>《线程八大核心+Java并发原理及企业级并发解决方案》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8A%E7%BA%BF%E7%A8%8B%E5%85%AB%E5%A4%A7%E6%A0%B8%E5%BF%83-Java%E5%B9%B6%E5%8F%91%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%B9%B6%E5%8F%91%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8A%E7%BA%BF%E7%A8%8B%E5%85%AB%E5%A4%A7%E6%A0%B8%E5%BF%83-Java%E5%B9%B6%E5%8F%91%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%B9%B6%E5%8F%91%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%8Bstudy-notes/</id>
    <published>2022-12-25T18:28:04.000Z</published>
    <updated>2022-12-25T18:28:04.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第1章-开宗明义"><a href="#第1章-开宗明义" class="headerlink" title="第1章 开宗明义"></a>第1章 开宗明义</h1><h2 id="为什么要学习并发编程"><a href="#为什么要学习并发编程" class="headerlink" title="为什么要学习并发编程"></a>为什么要学习并发编程</h2><ol><li>源于JD（job description）的硬性要求，尤其是大厂</li><li>并发痛点（面试中高频出现、内容繁杂、做归纳整理耗时、网上文章水平参差不齐难辨真伪）</li><li>并发学习，是成为高级工程师的必经之路（①几乎所有的程序或多或少都需要并发和多线程；②线上服务用户量过大，并发上万，如果不使用并发编程，性能很快成为瓶颈；③我们在职场打怪升级的过程中，并发编程是绕不过去的内容）</li><li>并发是众多框架的的原理和基础，学好后可以做到一通百通（①Spring中对线程池、单例的应用；②数据库中的乐观锁思想；③Log4j2对阻塞队列的应用）</li></ol><br><h2 id="配套资料"><a href="#配套资料" class="headerlink" title="配套资料"></a>配套资料</h2><ul><li><a class="link"   href="https://docs.qq.com/doc/DSVNyZ2FNWWFkeFpO" >https://docs.qq.com/doc/DSVNyZ2FNWWFkeFpO<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://naotu.baidu.com/file/07f437ff6bc3fa7939e171b00f133e17?token=6744a1c6ca6860a0" >https://naotu.baidu.com/file/07f437ff6bc3fa7939e171b00f133e17?token=6744a1c6ca6860a0<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://naotu.baidu.com/file/60a0bdcaca7c6b92fcc5f796fe6f6bc9?token=bcdbae34bb3b0533" >https://naotu.baidu.com/file/60a0bdcaca7c6b92fcc5f796fe6f6bc9?token=bcdbae34bb3b0533<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://coding.imooc.com/class/chapter/362.html#Anchor" >https://coding.imooc.com/class/chapter/362.html#Anchor<i class="fas fa-external-link-alt"></i></a></li><li><a class="link"   href="https://shimo.im/docs/zdkyBdQb94H255A6" >https://shimo.im/docs/zdkyBdQb94H255A6<i class="fas fa-external-link-alt"></i></a></li></ul><br><br><br><h1 id="第2章-线程八大核心纵观全貌"><a href="#第2章-线程八大核心纵观全貌" class="headerlink" title="第2章 线程八大核心纵观全貌"></a>第2章 线程八大核心纵观全貌</h1><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.6lp13ul4qko0.webp" width="50%"><br><h2 id="线程八大核心基础"><a href="#线程八大核心基础" class="headerlink" title="线程八大核心基础"></a>线程八大核心基础</h2><ol><li>实现多线程的方法到底有1种还是2种还是4种 ?</li><li>怎样才是正确的线程启动方式?</li><li>上山容易下山难如何正确停止线程 ?( 难点）</li><li>线程的一生6个状态(生命周期）</li><li>Thread和Obiect类中的重要方法详解</li><li>线程的各个属性</li><li>未捕获异常如何处理 ?</li><li>双刃剑: 多线程会导致的问题</li></ol><br><br><br><h1 id="第3章-核心1：实现多线程的正确姿势【解读官方文档】"><a href="#第3章-核心1：实现多线程的正确姿势【解读官方文档】" class="headerlink" title="第3章 核心1：实现多线程的正确姿势【解读官方文档】"></a>第3章 核心1：实现多线程的正确姿势【解读官方文档】</h1><h2 id="创建新线程的正确方法"><a href="#创建新线程的正确方法" class="headerlink" title="创建新线程的正确方法"></a>创建新线程的正确方法</h2><ul><li>oracle官方文档：<ul><li>方法一：继承Thread类</li><li>方法二：实现Runnable接口</li></ul></li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3bqyazhh2dk.webp" width="1000%"><br><h3 id="总结：创建新线程的方法-精确描述"><a href="#总结：创建新线程的方法-精确描述" class="headerlink" title="总结：创建新线程的方法-精确描述"></a>总结：创建新线程的方法-精确描述</h3><ul><li>通常我们可以分为两类，官网也是这么说的</li><li>准确的讲，创建线程只有一种方式那就是构造Thread类，而实现线程的执行单元有两种方式：<ul><li>方法一：重写Thread的run方法(继承Thread类)</li><li>方法二：实现Runnable接口的run 方法，并把Runnable实例传给Thread类</li></ul></li></ul><br><h2 id="两种方法的本质对比"><a href="#两种方法的本质对比" class="headerlink" title="两种方法的本质对比"></a>两种方法的本质对比</h2><ul><li>“实现Runnable接口并传入Thread类”和“继承Thread类然后重写run()方法”在实现多线程的本质上，并没有区别，都是最终调用了start()方法来新建线程。这两个方法的最主要区别在于run()方法的内容来源:</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">       <span class="keyword">if</span> (target != <span class="literal">null</span>) &#123;</span><br><span class="line">           target.run();</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><ul><li>实现Runnable接口方式: 最终调用target.run ();</li><li>继承Thread类方式: run()整个都被重写</li></ul><br><h2 id="典型错误观点分析"><a href="#典型错误观点分析" class="headerlink" title="典型错误观点分析"></a>典型错误观点分析</h2><ul><li>“线程池创建线程也算是一种新建线程的方式”</li><li>“通过Callable和FutureTask创建线程，也算是一种新建线程的方式”</li><li>“无返回值是实现runnable接口，有返回值是实现callable接口，所以callable是新的实现线程的方式”</li><li>定时器</li><li>匿名内部类</li><li>Lambda表达式</li></ul><p><strong>多线程的实现方式，在代码中写法千变万化，但其本质万变不离其宗</strong></p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><h3 id="同时用两种方法会怎么样"><a href="#同时用两种方法会怎么样" class="headerlink" title="同时用两种方法会怎么样"></a>同时用两种方法会怎么样</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BothRunnableThread</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;我来自Runnable&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)&#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;我来自Thread&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>最终会执行 Thread 类的run方法，因为 run方法已被重写</li></ul><br><h2 id="实现多线程—常见面试问题"><a href="#实现多线程—常见面试问题" class="headerlink" title="实现多线程—常见面试问题"></a>实现多线程—常见面试问题</h2><h3 id="有多少种实现线程的方法？"><a href="#有多少种实现线程的方法？" class="headerlink" title="有多少种实现线程的方法？"></a>有多少种实现线程的方法？</h3><ol><li>从不同的角度（代码实现方法，本质实现方法）看，会有不同的答案</li><li>典型答案是两种，分别是实现Runnable接口和继承Thread类，然后具体展开说;各自的优势，劣势</li><li>但是，我们看原理，其实Thread类实现了Runnable接口，并且看Thread类的run方法，会发现其实那两种本质都是一样的</li></ol><blockquote><p>“实现Runnable接口并传入Thread类”和“继承Thread类然后重写run0”在实现多线程的本质上，并没有区别，都是最终调用了start (方法来新建线程。这两个方法的最主要区别在于run0方法的内容来源:</p><ul><li>方法一: 最终调用target.run ();</li><li>方法二:run()整个都被重写</li></ul></blockquote><ol start="4"><li>然后具体展开说其他方式:还有其他的实现线程的方法，例如线程池、定时器，它们也能新建线程，但是细看源码，从没有逃出过本质，也就是实现Runnable接口和继承Thread类。</li><li>结论:我们只能通过新建Thread类这一种方式来创建线程，但是类里面的run方法有两种方式来5实现，第一种是重写run方法，第二种实现Runnable接口的run方法，然后再把该runnable实例传给Thread类。除此之外，从表面上看线程池、定时器等工具类也可以创建线程，但是它们的本质都逃不出刚才所说的范围。</li></ol><blockquote><p>以上这种描述比直接回答一种、两种、多种都更准确。</p></blockquote><br><h3 id="实现Runnable接口和继承Thread类哪种方式更好"><a href="#实现Runnable接口和继承Thread类哪种方式更好" class="headerlink" title="实现Runnable接口和继承Thread类哪种方式更好?"></a>实现Runnable接口和继承Thread类哪种方式更好?</h3><ul><li>实现Runnable接口更好</li></ul><ol><li>从代码架构角度，具体的任务 (run方法)应该和“创建和运行线程的机制(Thread类)”解耦。</li><li>使用继承Thread的方式的话，那么每次想新建一个任务，只能新建一个独立的线程，而这样做的损耗会比较大。如果使用Runnable和线程池，就可以大大减小这样的损耗。</li><li>继承Thread类以后，由于Java语言不支持双继承，这样就无法再继承其他的类，限制了可扩展性。</li></ol><br><br><br><h1 id="第4章-核心2：开启多线程启动的世界"><a href="#第4章-核心2：开启多线程启动的世界" class="headerlink" title="第4章 核心2：开启多线程启动的世界"></a>第4章 核心2：开启多线程启动的世界</h1><h2 id="start-方法含义"><a href="#start-方法含义" class="headerlink" title="start()方法含义"></a>start()方法含义</h2><ol><li>启动新线程</li><li>准备工作</li><li>不能重复start()</li></ol><br><h2 id="start-源码解析"><a href="#start-源码解析" class="headerlink" title="start()源码解析"></a>start()源码解析</h2><ol><li>启动新线程检查线程状态</li><li>加入线程组</li><li>调用start()</li></ol><br><h2 id="启动线程—常见面试题问题"><a href="#启动线程—常见面试题问题" class="headerlink" title="启动线程—常见面试题问题"></a>启动线程—常见面试题问题</h2><h3 id="一个线程两次调用start-方法会出现什么情况-为什么"><a href="#一个线程两次调用start-方法会出现什么情况-为什么" class="headerlink" title="一个线程两次调用start()方法会出现什么情况? 为什么?"></a>一个线程两次调用start()方法会出现什么情况? 为什么?</h3><ul><li>从start()源码可以看出，start的时候会先检查线程状态，只有NEW状态下的线程才能继续执行，否则会抛IllegalThreadStateException(在运行中或者已结束的线程，都不能再次启动)。</li></ul><br><h3 id="既然-start-方法会调用-run-方法，为什么我们选择调用-start-方法而不是直接调用-run-方法呢"><a href="#既然-start-方法会调用-run-方法，为什么我们选择调用-start-方法而不是直接调用-run-方法呢" class="headerlink" title="既然 start()方法会调用 run()方法，为什么我们选择调用 start() 方法而不是直接调用 run()方法呢?"></a>既然 start()方法会调用 run()方法，为什么我们选择调用 start() 方法而不是直接调用 run()方法呢?</h3><ul><li>start()才是真正启动一个线程，而如果直接调用run()，那么run()只是一个普通的方法而已，和线程的生命周期没有任何关系</li></ul><br><br><br><h1 id="第5章-核心3：线程停止、中断之最佳实践【填“坑”式教学，从错误到正确】"><a href="#第5章-核心3：线程停止、中断之最佳实践【填“坑”式教学，从错误到正确】" class="headerlink" title="第5章 核心3：线程停止、中断之最佳实践【填“坑”式教学，从错误到正确】"></a>第5章 核心3：线程停止、中断之最佳实践【填“坑”式教学，从错误到正确】</h1><ul><li>这一节的内容有点难，需要继续学习</li></ul><br><br><br><h1 id="学习延伸"><a href="#学习延伸" class="headerlink" title="学习延伸"></a>学习延伸</h1><h2 id="学习编程知识的优质途径"><a href="#学习编程知识的优质途径" class="headerlink" title="学习编程知识的优质途径"></a>学习编程知识的优质途径</h2><h3 id="宏观上"><a href="#宏观上" class="headerlink" title="宏观上"></a>宏观上</h3><ul><li>并不是靠工作年限，有的人工作了5年技术却还是只懂皮毛</li><li>要有强大的责任心，不放过任何bug，找到原因并去解决，这就是提高</li><li>主动:永远不会觉得自己的时间多余，重构、优化、学习、总结等。</li><li>敢于承担:虽然这个技术难题以前没碰到过，但是在一定的了解调研后，敢于承担技术难题，让工作充满挑战，这一次次攻克难关的过程中，进步是飞速的</li><li>关心产品，关心业务，而不只是写代码</li></ul><br><h3 id="微观上（系统性学习）"><a href="#微观上（系统性学习）" class="headerlink" title="微观上（系统性学习）"></a>微观上（系统性学习）</h3><ul><li>看经典书籍(指外国人写的经典的中国译本，比如说Java并发编程实战、自页向下计算机网络)</li><li>看官方文档</li><li>英文搜google和stackoverflow</li><li>自己动手写，实践写demo，尝试用到项目里</li><li>不理解的参考该领域的多个书本，综合判断</li><li>学习开源项目，分析源码(学习synchronized原理，反编译看cpp代码)</li></ul><br><h2 id="如何了解技术领域的最新动态"><a href="#如何了解技术领域的最新动态" class="headerlink" title="如何了解技术领域的最新动态"></a>如何了解技术领域的最新动态</h2><ul><li>高质量固定途径:ohmyrss.com(信息源筛选，为我所用)</li><li>订阅技术网址的邮件 :InfoQ(每周都看 )</li><li>公众号不推荐作为技术知识来源，质量无法保证</li></ul><br><h2 id="如何在业务开发中成长"><a href="#如何在业务开发中成长" class="headerlink" title="如何在业务开发中成长"></a>如何在业务开发中成长</h2><ul><li>偏业务方向</li><li>偏技术方向</li><li>两个25%理论</li></ul><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">red</span>&gt;</span><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><img src="" width="70%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;第1章-开宗明义&quot;&gt;&lt;a href=&quot;#第1章-开宗明义&quot; class=&quot;headerlink&quot; title=&quot;第1章 开宗明义&quot;&gt;&lt;/a&gt;第1章 开宗明义&lt;/h1&gt;&lt;h2 id=&quot;为什么要学习并发编程&quot;&gt;&lt;a href=&quot;#为什么要学习并发编程&quot; class=&quot;</summary>
      
    
    
    
    <category term="Java" scheme="https://ratears.github.io/dev.ratears.life/Categories/Java/"/>
    
    <category term="Concurrency" scheme="https://ratears.github.io/dev.ratears.life/Categories/Java/Concurrency/"/>
    
    
    <category term="Concurrency" scheme="https://ratears.github.io/dev.ratears.life/Tags/Concurrency/"/>
    
    <category term="Java" scheme="https://ratears.github.io/dev.ratears.life/Tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>《MongoDB快速上手》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8AMongoDB%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8AMongoDB%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E3%80%8Bstudy-notes/</id>
    <published>2022-12-03T22:14:34.000Z</published>
    <updated>2022-12-03T22:14:34.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><ul><li>理解MongoDB的业务场景、熟悉MongoDB的简介、特点和体系结构、数据类型等</li><li>能够在Windows和Linux下安装和启动MongoDB、图形化管理界面Compass的安装使用</li><li>掌握MongoDB基本常用命令实现数据的CRUD</li><li>掌握MongoDB的索引类型、索引管理、执行计划</li><li>使用Spring Data MongoDB完成文章评论业务的开发</li></ul><br><br><br><h1 id="MongoDB相关概念"><a href="#MongoDB相关概念" class="headerlink" title="MongoDB相关概念"></a>MongoDB相关概念</h1><h2 id="业务应用场景"><a href="#业务应用场景" class="headerlink" title="业务应用场景"></a>业务应用场景</h2><ul><li>传统的关系型数据库（如MySQL），在数据操作的“三高”需求以及应对Web2.0的网站需求面前，显得力不从心。</li></ul><blockquote><ul><li>“三高”需求：<ul><li>High performance - 对数据库高并发读写的需求。</li><li>Huge Storage - 对海量数据的高效率存储和访问的需求。</li><li> High Scalability &amp;&amp; High Availability- 对数据库的高可扩展性和高可用性的需求</li></ul></li></ul></blockquote><ul><li><p><strong>而MongoDB可应对“三高”需求</strong></p></li><li><p>具体的应用场景如：</p></li></ul><blockquote><p>1）社交场景，使用 MongoDB 存储存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引实现附近的人、地点等功能。</p><p>2）游戏场景，使用 MongoDB 存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存储，方便查询、高效率存储和访问。</p><p>3）物流场景，使用 MongoDB 存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB 内嵌数组的形式来存储，一次查询就能将订单所有的变更读取出来。</p><p>4）物联网场景，使用 MongoDB 存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这些信息进行多维度的分析。</p><p>5）视频直播，使用 MongoDB 存储用户信息、点赞互动信息等。</p></blockquote><ul><li>这些应用场景中，数据操作方面的共同特点是：<ul><li>（1）数据量大</li><li>（2）写入操作频繁（读写都很频繁）</li><li>（3）价值较低的数据，对事务性要求不高</li></ul></li></ul><blockquote><p>对于这样的数据，我们更适合使用MongoDB来实现数据的存储。</p></blockquote><br><h2 id="什么时候选择MongoDB"><a href="#什么时候选择MongoDB" class="headerlink" title="什么时候选择MongoDB"></a>什么时候选择MongoDB</h2><ul><li>应用不需要事务及复杂 join 支持</li><li>新应用，需求会变，数据模型无法确定，想快速迭代开发</li><li>应用需要2000-3000以上的读写QPS（更高也可以）</li><li>应用需要TB甚至 PB 级别数据存储</li><li>应用发展迅速，需要能快速水平扩展</li><li>应用要求存储的数据不丢失</li><li>应用需要99.999%高可用</li><li>应用需要大量的地理位置查询、文本查询</li></ul><blockquote><p>如果上述有1个符合，可以考虑 MongoDB，2个及以上的符合，选择 MongoDB 绝不会后悔</p></blockquote><ul><li><strong>相对MySQL，可以以更低的成本解决问题（包括学习、开发、运维等成本）</strong></li></ul><br><h2 id="MongoDB简介"><a href="#MongoDB简介" class="headerlink" title="MongoDB简介"></a>MongoDB简介</h2><ul><li>MongoDB是一个开源、高性能、无模式的文档型数据库，当初的设计就是用于简化开发和方便扩展，是NoSQL数据库产品中的一种。是最像关系型数据库（MySQL）的非关系型数据库。</li><li>它支持的数据结构非常松散，是一种类似于 JSON 的 格式叫BSON，所以它既可以存储比较复杂的数据类型，又相当的灵活。</li><li>MongoDB中的记录是一个文档，它是一个由字段和值对（field:value）组成的数据结构。MongoDB文档类似于JSON对象，即一个文档认为就是一个对象。字段的数据类型是字符型，它的值除了使用基本的一些类型外，还可以包括其他文档、普通数组和文档数组。</li></ul><br><h2 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h2><h3 id="MySQL和MongoDB对比"><a href="#MySQL和MongoDB对比" class="headerlink" title="MySQL和MongoDB对比"></a>MySQL和MongoDB对比</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.yanmy0ggv5s.webp" width="60%"><br><table><thead><tr><th align="center">SQL术语/概念</th><th align="center">MongoDB术语/概念</th><th align="center">解释/说明</th></tr></thead><tbody><tr><td align="center">database</td><td align="center">database</td><td align="center">数据库</td></tr><tr><td align="center">table</td><td align="center">collection</td><td align="center">数据库表/集合</td></tr><tr><td align="center">row</td><td align="center">document</td><td align="center">数据记录行/文档</td></tr><tr><td align="center">column</td><td align="center">field</td><td align="center">数据字段/域</td></tr><tr><td align="center">index</td><td align="center">index</td><td align="center">索引</td></tr><tr><td align="center">table joins</td><td align="center"></td><td align="center">表连接,MongoDB不支持</td></tr><tr><td align="center"></td><td align="center">嵌入文档</td><td align="center">MongoDB通过嵌入式文档来替代多表连接</td></tr><tr><td align="center">primary key</td><td align="center">primary key</td><td align="center">主键,MongoDB自动将_id字段设置为主键</td></tr></tbody></table><br><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul><li><p>MongoDB的最小存储单位就是文档(document)对象。文档(document)对象对应于关系型数据库的行。数据在MongoDB中以<br>BSON（Binary-JSON）文档的格式存储在磁盘上</p></li><li><p>BSON（Binary Serialized Document Format）是一种类json的一种二进制形式的存储格式，简称Binary JSON。BSON和JSON一样，支持内嵌的文档对象和数组对象，但是BSON有JSON没有的一些数据类型，如Date和BinData类型。</p></li><li><p>BSON采用了类似于 C 语言结构体的名称、对表示方法，支持内嵌的文档对象和数组对象，具有轻量性、可遍历性、高效性的三个特点，可以有效描述非结构化数据和结构化数据。这种格式的优点是灵活性高，但它的缺点是空间利用率不是很理想。</p></li><li><p>Bson中，除了基本的JSON类型：string,integer,boolean,double,null,array和object，mongo还使用了特殊的数据类型。这些类型包括date,object id,binary data,regular expression 和code。每一个驱动都以特定语言的方式实现了这些类型，查看你的驱动的文档来获取详细信息。</p></li></ul><br><h3 id="BSON数据类型参考列表"><a href="#BSON数据类型参考列表" class="headerlink" title="BSON数据类型参考列表"></a>BSON数据类型参考列表</h3><table><thead><tr><th align="left">数据类型</th><th>描述</th><th>举例</th></tr></thead><tbody><tr><td align="left">字符串</td><td>UTF-8字符串都可表示为字符串类型的数据</td><td>{“x” : “foobar”}</td></tr><tr><td align="left">对象id</td><td>对象id是文档的12字节的唯一 ID</td><td>{“X” :ObjectId() }</td></tr><tr><td align="left">布尔值</td><td>真或者假：true或者false</td><td>{“x”:true}+</td></tr><tr><td align="left">数组</td><td>值的集合或者列表可以表示成数组</td><td>{“x” ： [“a”, “b”, “c”]}</td></tr><tr><td align="left">32位整数</td><td>类型不可用。JavaScript仅支持64位浮点数，所以32位整数会被自动转换。</td><td>shell是不支持该类型的，shell中默认会转换成64位浮点数</td></tr><tr><td align="left">64位整数</td><td>不支持这个类型。shell会使用一个特殊的内嵌文档来显示64位整数</td><td>shell是不支持该类型的，shell中默认会转换成64位浮点数</td></tr><tr><td align="left">64位浮点数</td><td>shell中的数字就是这一种类型</td><td>{“x”：3.14159，”y”：3}</td></tr><tr><td align="left">null</td><td>表示空值或者未定义的对象</td><td>{“x”:null}</td></tr><tr><td align="left">undefined</td><td>文档中也可以使用未定义类型</td><td>{“x”:undefined}</td></tr><tr><td align="left">符号</td><td>shell不支持，shell会将数据库中的符号类型的数据自动转换成字符串</td><td></td></tr><tr><td align="left">正则表达式</td><td>文档中可以包含正则表达式，采用JavaScript的正则表达式语法</td><td>{“x” ： /foobar/i}</td></tr><tr><td align="left">代码</td><td>文档中还可以包含JavaScript代码</td><td>{“x” ： function() { /* …… */ }}</td></tr><tr><td align="left">二进制数据</td><td>二进制数据可以由任意字节的串组成，不过shell中无法使用</td><td></td></tr><tr><td align="left">最大值/最小值</td><td>BSON包括一个特殊类型，表示可能的最大值。shell中没有这个类型。</td><td></td></tr></tbody></table><blockquote><p>shell默认使用64位浮点型数值。{“x”：3.14}或{“x”：3}。对于整型值，可以使用NumberInt（4字节符号整数）或NumberLong（8字节符号整数），{“x”:NumberInt(“3”)}{“x”:NumberLong(“3”)}</p></blockquote><br><h2 id="MongoDB的特点"><a href="#MongoDB的特点" class="headerlink" title="MongoDB的特点"></a>MongoDB的特点</h2><ul><li>MongoDB主要有如下特点：</li></ul><ul><li>（1）高性能：</li></ul><blockquote><p>MongoDB提供高性能的数据持久性。特别是,对嵌入式数据模型的支持减少了数据库系统上的I/O活动。</p><p>索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。（文本索引解决搜索的需求、TTL索引解决历史数据自动过期的需求、地理位置索引可用于构建各种 O2O 应用）</p><p>mmapv1、wiredtiger、mongorocks（rocksdb）、in-memory 等多引擎支持满足各种场景需求</p><p>Gridfs解决文件存储的需求</p></blockquote><ul><li>（2）高可用性：</li></ul><blockquote><p>MongoDB的复制工具称为副本集（replica set），它可提供自动故障转移和数据冗余。</p></blockquote><ul><li>（3）高扩展性：</li></ul><blockquote><p>MongoDB提供了水平可扩展性作为其核心功能的一部分。</p><p>分片将数据分布在一组集群的机器上。（海量数据存储，服务能力水平扩展）</p><p>从3.4开始，MongoDB支持基于片键创建数据区域。在一个平衡的集群中，MongoDB将一个区域所覆盖的读写只定向到该区域内的那些片。</p></blockquote><ul><li>（4）丰富的查询支持：</li></ul><blockquote><p>MongoDB支持丰富的查询语言，支持读和写操作(CRUD)，比如数据聚合、文本搜索和地理空间查询等。</p></blockquote><ul><li>（5）其他特点：如无模式（动态模式）、灵活的文档模型</li></ul><br><br><br><h1 id="单机部署"><a href="#单机部署" class="headerlink" title="单机部署"></a>单机部署</h1><h2 id="Linux系统中的安装启动和连接"><a href="#Linux系统中的安装启动和连接" class="headerlink" title="Linux系统中的安装启动和连接"></a>Linux系统中的安装启动和连接</h2><h3 id="版本的选择"><a href="#版本的选择" class="headerlink" title="版本的选择"></a>版本的选择</h3><ul><li>MongoDB的版本命名规范如：x.y.z；<ul><li>y为奇数时表示当前版本为开发版，如：1.5.2、4.1.13；</li><li>y为偶数时表示当前版本为稳定版，如：1.6.3、4.0.10；</li><li>z是修正版本号，数字越大越好。</li></ul></li></ul><br><h2 id="下载安装启动"><a href="#下载安装启动" class="headerlink" title="下载安装启动"></a>下载安装启动</h2><p>（1）先到官网下载压缩包 mongodb-linux-x86_64-rhel70-4.0.28.tgz 。</p><p>（2）上传压缩包到Linux中，解压到 <code>/usr/local</code></p><p>（3）创建软连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s mongodb-linux-x86_64-rhel70-4.0.28/ mongodb</span><br></pre></td></tr></table></figure><p>（4）新建几个目录，分别用来存储数据和日志：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据存储目录</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /mongodb/single/data/db</span><br><span class="line"><span class="comment">#日志存储目录</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /mongodb/single/log</span><br></pre></td></tr></table></figure><p>（5）新建并修改配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /mongodb/single/mongod.conf</span><br></pre></td></tr></table></figure><ul><li>配置文件的内容如下：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">数据库路径</span></span><br><span class="line">dbpath=/mongodb/single/data/db</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">日志输出文件路径</span></span><br><span class="line">logpath=/mongodb/single/log/mongod.log</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">错误日志采用追加模式</span></span><br><span class="line">logappend=true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">启用日志文件，默认启用</span></span><br><span class="line">journal=true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为<span class="literal">false</span></span></span><br><span class="line">quiet=true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">端口号 默认为27017</span></span><br><span class="line">port=27017</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">允许远程访问（你的服务器局域网ip）</span></span><br><span class="line">bind_ip=192.168.146.136,localhost</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">开启子进程</span></span><br><span class="line">fork=true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">开启认证，必选先添加用户，先不开启（不用验证账号密码）</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">auth=<span class="literal">true</span></span></span><br></pre></td></tr></table></figure><p>（6）启动MongoDB服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost <span class="built_in">local</span>]<span class="comment"># /usr/local/mongodb/bin/mongod -f /mongodb/single/mongod.conf</span></span><br><span class="line">about to fork child process, waiting until server is ready <span class="keyword">for</span> connections.</span><br><span class="line">forked process: 18809</span><br><span class="line">child process started successfully, parent exiting</span><br></pre></td></tr></table></figure><p>通过进程来查看服务是否启动了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost <span class="built_in">local</span>]<span class="comment"># ps -ef |grep mongod</span></span><br><span class="line">root      18809      1  2 00:40 ?        00:00:00 /usr/local/mongodb/bin/mongod -f /mongodb/single/mongod.conf</span><br><span class="line">root      18844   8794  0 00:41 pts/1    00:00:00 grep --color=auto mongod</span><br></pre></td></tr></table></figure><p>（7）分别使用mongo命令和compass工具来连接测试。</p><ul><li>需要配置防火墙放行，或直接关闭linux防火墙</li></ul><p>（8）停止关闭服务</p><ul><li>（一）快速关闭方法（快速，简单，数据可能会出错）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 目标：通过系统的kill命令直接杀死进程：杀完要检查一下，避免有的没有杀掉。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#通过进程编号关闭节点</span></span><br><span class="line"><span class="built_in">kill</span> -2 54410</span><br></pre></td></tr></table></figure><p>【补充】</p><p>如果一旦是因为数据损坏，则需要进行如下操作（了解）：</p><p>1）删除lock文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -f /mongodb/single/data/db/*.lock</span><br></pre></td></tr></table></figure><p>2）修复数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/mongdb/bin/mongod --repair --dbpath=/mongodb/single/data/db</span><br></pre></td></tr></table></figure><p>（二）标准的关闭方法（数据不容易出错，但麻烦）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 目标：通过mongo客户端中的shutdownServer命令来关闭服务</span></span><br><span class="line"><span class="comment"># 主要的操作步骤参考如下：</span></span><br><span class="line"></span><br><span class="line">//客户端登录服务，注意，这里通过localhost登录，如果需要远程登录，必须先登录认证才行。</span><br><span class="line">mongo --port 27017</span><br><span class="line">//<span class="comment">#切换到admin库</span></span><br><span class="line">use admin</span><br><span class="line">//关闭服务</span><br><span class="line">db.shutdownServer()</span><br></pre></td></tr></table></figure><br><br><br><h1 id="基本常用命令"><a href="#基本常用命令" class="headerlink" title="基本常用命令"></a>基本常用命令</h1><h2 id="案例需求"><a href="#案例需求" class="headerlink" title="案例需求"></a>案例需求</h2><ul><li>存放文章评论的数据存放到MongoDB中，数据结构参考如下：<ul><li>数据库：articledb</li></ul></li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4cm5w9rgfkw0.webp" width="80%"><br><h2 id="数据库操作"><a href="#数据库操作" class="headerlink" title="数据库操作"></a>数据库操作</h2><h3 id="选择和创建数据库"><a href="#选择和创建数据库" class="headerlink" title="选择和创建数据库"></a>选择和创建数据库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择和创建数据库的语法格式：</span></span><br><span class="line">use 数据库名称</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果数据库不存在则自动创建，例如，以下语句创建 articledb 数据库：</span></span><br><span class="line">use articledb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看有权限查看的所有的数据库命令</span></span><br><span class="line">show dbs</span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line">show databases</span><br></pre></td></tr></table></figure><blockquote><p>注意: 在 MongoDB 中，集合只有在内容插入后才会创建! 就是说，创建集合(数据表)后要再插入一个文档(记录)，集合才会真正创建。</p></blockquote><ul><li>查看当前正在使用的数据库命令</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db</span><br></pre></td></tr></table></figure><br><br><br><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><ol><li>课件中的某些内容已经过时了或有问题，后续再深入了解一下。目前先熟悉使用再说</li></ol></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="60%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;目标&quot;&gt;&lt;a href=&quot;#目标&quot; class=&quot;headerlink&quot; title=&quot;目标&quot;&gt;&lt;/a&gt;目标&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;理解MongoDB的业务场景、熟悉MongoDB的简介、特点和体系结构、数据类型等&lt;/li&gt;
&lt;li&gt;能够在Windows和Li</summary>
      
    
    
    
    <category term="Database" scheme="https://ratears.github.io/dev.ratears.life/Categories/Database/"/>
    
    <category term="NoSQL" scheme="https://ratears.github.io/dev.ratears.life/Categories/Database/NoSQL/"/>
    
    <category term="MongoDB" scheme="https://ratears.github.io/dev.ratears.life/Categories/Database/NoSQL/MongoDB/"/>
    
    
    <category term="MongoDB" scheme="https://ratears.github.io/dev.ratears.life/Tags/MongoDB/"/>
    
    <category term="NoSQL" scheme="https://ratears.github.io/dev.ratears.life/Tags/NoSQL/"/>
    
    <category term="Database" scheme="https://ratears.github.io/dev.ratears.life/Tags/Database/"/>
    
  </entry>
  
  <entry>
    <title>《一站式学习Redis-从入门到高可用分布式实践》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8A%E4%B8%80%E7%AB%99%E5%BC%8F%E5%AD%A6%E4%B9%A0Redis-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E9%AB%98%E5%8F%AF%E7%94%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E8%B7%B5%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8A%E4%B8%80%E7%AB%99%E5%BC%8F%E5%AD%A6%E4%B9%A0Redis-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E9%AB%98%E5%8F%AF%E7%94%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E8%B7%B5%E3%80%8Bstudy-notes/</id>
    <published>2022-12-01T14:31:29.000Z</published>
    <updated>2022-12-01T14:31:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="API的理解和使用"><a href="#API的理解和使用" class="headerlink" title="API的理解和使用"></a>API的理解和使用</h1><br><br><h2 id="单线程"><a href="#单线程" class="headerlink" title="单线程"></a>单线程</h2><h3 id="单线程为什么这么快"><a href="#单线程为什么这么快" class="headerlink" title="单线程为什么这么快"></a>单线程为什么这么快</h3><ul><li>纯内存（主要原因）</li><li>非阻塞IO（epoll，io多路复用）</li><li>避免线程切换和竞态消耗</li></ul><br><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ol><li></li></ol><br><h2 id="String（字符串）"><a href="#String（字符串）" class="headerlink" title="String（字符串）"></a>String（字符串）</h2><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><ul><li>可以是真的字符串，同时也可以是数字，二进制数字等等。大小限制 512MB</li></ul><img src ="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/4c36c4ac53ae6df147284b21e0fa921.lo8tp31mfhs.webp" width="70%" /><br><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><ul><li>缓存</li><li>计数器</li><li>分布式锁</li><li>……</li></ul><br><h3 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h3><table><thead><tr><th align="center">命令</th><th align="center">举例</th><th align="center">时间复杂度</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">set</td><td align="center">set hello word</td><td align="center">O(1)</td><td align="center">不管key是否存在，都设置。成功返回ok</td></tr><tr><td align="center">setnx</td><td align="center">setnx k v</td><td align="center">O(1)</td><td align="center">key不存在才设置</td></tr><tr><td align="center">set xx</td><td align="center">set k v xx</td><td align="center">O(1)</td><td align="center">key存在才设置。不存在返回nil</td></tr><tr><td align="center">mset</td><td align="center">mset k1 v1 k2 v2</td><td align="center">O(n)</td><td align="center">批量设置key-value，原子操作</td></tr><tr><td align="center">del</td><td align="center">del hello</td><td align="center">O(1)</td><td align="center">成功返回1,失败返回0</td></tr><tr><td align="center">get</td><td align="center">get hello</td><td align="center">O(1)</td><td align="center">成功返回的value，失败返回nil</td></tr><tr><td align="center">mget</td><td align="center">mget k1 k2</td><td align="center">O(n)</td><td align="center">批量获取key-value，原子操作</td></tr><tr><td align="center">incr</td><td align="center">incr counter</td><td align="center">O(1)</td><td align="center">自增1，并返回自增后的value值。如果key不存在，自增后get(key) = 1</td></tr><tr><td align="center">decr</td><td align="center">decr counter</td><td align="center">O(1)</td><td align="center">自减1，并返回自减后的value值。如果key不存在，自减后get(key) = -1</td></tr><tr><td align="center">incrby</td><td align="center">incrby view k</td><td align="center">O(1)</td><td align="center">自增k，并返回自增k后的value值。如果key不存在，自增后get(key) = k</td></tr><tr><td align="center">decrby</td><td align="center">decrby view k</td><td align="center">O(1)</td><td align="center">自减k，并返回自减后的value值。如果key不存在，自减后get(key) = -k</td></tr><tr><td align="center">getset</td><td align="center">getset k newvalue</td><td align="center">O(1)</td><td align="center">set key newValue，并返回旧的value</td></tr><tr><td align="center">apend</td><td align="center">apend k v</td><td align="center">O(1)</td><td align="center">将value追加到旧的value</td></tr><tr><td align="center">strlen</td><td align="center">strlen k</td><td align="center">O(1)</td><td align="center">返回字符串的长度[字节]（utf-8 中文占 2个字节）</td></tr><tr><td align="center">incrbyfloat</td><td align="center">incrbyfloat k v</td><td align="center">O(1)</td><td align="center">增加指定的浮点数</td></tr><tr><td align="center">getrange</td><td align="center">getrange k start end</td><td align="center">O(1)</td><td align="center">获取字符串指定下标所有的值</td></tr><tr><td align="center">setrange</td><td align="center">setrange k index value</td><td align="center">O(1)</td><td align="center">设置指定下标对应的值</td></tr></tbody></table><br><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><ol><li>记录网站每个用户的个人主页访问量</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">单线程：无竞争（并发不会出现计错数的情况）</span></span><br><span class="line">incr userId:pageView</span><br></pre></td></tr></table></figure><ol start="2"><li>缓存视频的基本信息（数据源在MySQL中）</li></ol><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2nspuoc7ly60.webp" width="70%" /><br><ol start="3"><li>分布式id生成器</li></ol><br><h3 id="查漏补缺"><a href="#查漏补缺" class="headerlink" title="查漏补缺"></a>查漏补缺</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/1d121aa9afdb06c7451e0fb8bb2d560.kias448eqho.webp" width="70%" /><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/4c1ea9bb24f88ec70a3aacc637a9183.4xykrj7thuw0.webp" width="70%" /><h2 id="hash（哈希）"><a href="#hash（哈希）" class="headerlink" title="hash（哈希）"></a>hash（哈希）</h2><br><h1 id="Redis客户端"><a href="#Redis客户端" class="headerlink" title="Redis客户端"></a>Redis客户端</h1><h2 id="Java客户端Jedis"><a href="#Java客户端Jedis" class="headerlink" title="Java客户端Jedis"></a>Java客户端Jedis</h2><h3 id="Jedis简单使用"><a href="#Jedis简单使用" class="headerlink" title="Jedis简单使用"></a>Jedis简单使用</h3><ul><li>maven依赖</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>Jedis直连</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.1l6p9hnls4rk.webp" width="70%"/><br><h3 id="JedisPool简单使用"><a href="#JedisPool简单使用" class="headerlink" title="JedisPool简单使用"></a>JedisPool简单使用</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4ehexcty0j20.webp" width = "70%"/><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3r9cudbxdi00.webp" width = "70%"/><br><h3 id="Jedis-与-JedisPool比较"><a href="#Jedis-与-JedisPool比较" class="headerlink" title="Jedis 与 JedisPool比较"></a>Jedis 与 JedisPool比较</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/97b459332ea53d7e42b90bd2743dcda.396pfset03e0.webp" width="60%" /><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/7e5d97f719abbfe9b363126e682f86d.3g21qh3ltu20.webp" width="60%" /><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/41e863e25d7ae1dc0c3cebe8444b9c5.2tj6g97vyck.webp" width="60%" /><br><h3 id="Jedis配置优化"><a href="#Jedis配置优化" class="headerlink" title="Jedis配置优化"></a>Jedis配置优化</h3><h4 id="pool配置-资源数控制"><a href="#pool配置-资源数控制" class="headerlink" title="pool配置 - 资源数控制"></a>pool配置 - 资源数控制</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.21oqgp1jyxnk.webp" width="60%" /><br><h4 id="pool配置-借还参数"><a href="#pool配置-借还参数" class="headerlink" title="pool配置 - 借还参数"></a>pool配置 - 借还参数</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.7cwnd55qd1s0.webp" width="70%" /><br><h4 id="适合的-maxTotal"><a href="#适合的-maxTotal" class="headerlink" title="适合的 maxTotal"></a>适合的 maxTotal</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2mma31ou5nw0.webp" width="60%" /><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.6sejm8evfwc.webp" width="60%" /><br><h4 id="适合的maxIdle和minIdle"><a href="#适合的maxIdle和minIdle" class="headerlink" title="适合的maxIdle和minIdle"></a>适合的maxIdle和minIdle</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.6lhcm72l9bo0.webp" width="60%" /><br><h3 id="常见问题和解决思路"><a href="#常见问题和解决思路" class="headerlink" title="常见问题和解决思路"></a>常见问题和解决思路</h3><ul><li>常见问题</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.75d32k2l47g0.webp" width="60%" /><br><ul><li>解决思路</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.41af9urqt6a0.webp" width="60%" /><br><ul><li>错误示例</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.31pwe9jqbig0.webp" width="60%" /><br><ul><li>推荐写法</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.69xc8p0s24o0.webp" width="60%" /><br><h1 id="Redis持久化的取舍和选择"><a href="#Redis持久化的取舍和选择" class="headerlink" title="Redis持久化的取舍和选择"></a>Redis持久化的取舍和选择</h1><h2 id="持久化的作用"><a href="#持久化的作用" class="headerlink" title="持久化的作用"></a>持久化的作用</h2><ol><li>什么是持久化</li></ol><blockquote><p>redis所有的数据保存在内存中，对数据的更新将异步的保存在磁盘上</p></blockquote><p>内存 =》（持久化）=》磁盘</p><p>内存 《=（恢复）《= 磁盘</p><ol start="2"><li>持久化的方式</li></ol><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.urjf6b58j5c.webp" width="60%" /><br><h2 id="RDB（Redis-DataBase）"><a href="#RDB（Redis-DataBase）" class="headerlink" title="RDB（Redis DataBase）"></a>RDB（Redis DataBase）</h2><h3 id="什么是RDB"><a href="#什么是RDB" class="headerlink" title="什么是RDB"></a>什么是RDB</h3><ul><li>RDB：在不同的时间点，将 redis 存储的数据生成快照并存储到磁盘等介质上</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.xtthna1x3gg.webp" width="60%" /><br><h3 id="RDB触发机制的三种方式"><a href="#RDB触发机制的三种方式" class="headerlink" title="RDB触发机制的三种方式"></a>RDB触发机制的三种方式</h3><h4 id="save（同步）"><a href="#save（同步）" class="headerlink" title="save（同步）"></a>save（同步）</h4><ul><li>可能会造成阻塞</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.1mmseu4fo9og.webp" width="60%" /><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6380&gt;  save</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><ul><li>文件策略：生成临时的rdb文件，当save执行完后。如果存在老的rdb文件，临时文件变成新文件替换老文件</li><li>复杂度：O(n)</li></ul><br><h4 id="bgsave（异步）"><a href="#bgsave（异步）" class="headerlink" title="bgsave（异步）"></a>bgsave（异步）</h4><ul><li>客户端执行 <code>bgsave</code> redis会使用linux的 <code>fork()</code> 函数生成一个redis的子进程，由该子进程生成RDB文件</li><li>一般情况下， <code>bgsave</code> 不会阻塞到redis</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.1nkd5mhwgzcw.webp" width="60%" /><br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6380&gt; bgsave</span><br><span class="line">Background saving started</span><br></pre></td></tr></table></figure><ul><li>文件策略：生成临时的rdb文件，当save执行完后。如果存在老的rdb文件，临时文件变成新文件替换老文件</li><li>复杂度：O(n)</li></ul><br><h4 id="save-与-bgsave比较"><a href="#save-与-bgsave比较" class="headerlink" title="save 与 bgsave比较"></a>save 与 bgsave比较</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.7z4y2ta7f2w.webp" width="65%" /><br><h4 id="自动"><a href="#自动" class="headerlink" title="自动"></a>自动</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.42jf7bw3rfe0.webp" width="70%" /><br><ul><li>说明：在 60s 中改变了10000 条数据（set，del），会自动做rdb的生成</li></ul><br><h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul><li>数据写入量无法控制，生成规则无法控制。如果文件非常大，或很频繁的做这样的操作，会对硬盘造成一定压力</li></ul><br><h5 id="默认配置"><a href="#默认配置" class="headerlink" title="默认配置"></a>默认配置</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">############################### 快照  #################################</span></span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Save the DB on disk:保存数据库到磁盘</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  save &lt;秒&gt; &lt;更新&gt;</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  如果指定的秒数和数据库写操作次数都满足了就将数据库保存。</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  下面是保存操作的实例：</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化）</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化）</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化）</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  注释：注释掉“save”这一行配置项就可以让保存数据库功能失效。</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  你也可以通过增加一个只有一个空字符串的配置项（如下面的实例）来去掉前面的“save”配置。</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">  save <span class="string">&quot;&quot;</span></span>  </span><br><span class="line">  </span><br><span class="line">save 900 1  </span><br><span class="line">save 300 10  </span><br><span class="line">save 60 10000  </span><br><span class="line"><span class="meta prompt_">  </span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">在默认情况下，如果RDB快照持久化操作被激活（至少一个条件被激活）并且持久化操作失败，Redis则会停止接受更新操作。</span>  </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">这样会让用户了解到数据没有被正确的存储到磁盘上。否则没人会注意到这个问题，可能会造成灾难。</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果后台存储（持久化）操作进程再次工作，Redis会自动允许更新操作。</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">然而，如果你已经恰当的配置了对Redis服务器的监视和备份，你也许想关掉这项功能。</span>  </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如此一来即使后台保存操作出错,redis也仍然可以继续像平常一样工作。</span>  </span><br><span class="line">stop-writes-on-bgsave-error yes  </span><br><span class="line"><span class="meta prompt_">  </span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否在导出.rdb数据库文件的时候采用LZF压缩字符串和对象？</span>  </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">默认情况下总是设置成‘<span class="built_in">yes</span>’， 他看起来是一把双刃剑。</span>  </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果你想在存储的子进程中节省一些CPU就设置成<span class="string">&#x27;no&#x27;</span>，</span>  </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">但是这样如果你的kye/value是可压缩的，你的到处数据接就会很大。</span>  </span><br><span class="line">rdbcompression yes  </span><br><span class="line"><span class="meta prompt_">  </span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">从版本RDB版本5开始，一个CRC64的校验就被放在了文件末尾。</span>  </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">这会让格式更加耐攻击，但是当存储或者加载rbd文件的时候会有一个10%左右的性能下降，</span>  </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">所以，为了达到性能的最大化，你可以关掉这个配置项。</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">没有校验的RDB文件会有一个0校验位，来告诉加载代码跳过校验检查。</span>  </span><br><span class="line">rdbchecksum yes  </span><br><span class="line"><span class="meta prompt_">  </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">导出数据库的文件名称</span>  </span><br><span class="line">dbfilename dump.rdb  </span><br><span class="line"><span class="meta prompt_">  </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">工作目录</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">导出的数据库会被写入这个目录，文件名就是上面<span class="string">&#x27;dbfilename&#x27;</span>配置项指定的文件名。</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">只增的文件也会在这个目录创建（这句话没看明白）</span>  </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意你一定要在这个配置一个工作目录，而不是文件名称。</span>  </span><br><span class="line">dir ./  </span><br></pre></td></tr></table></figure><br><h5 id="最佳配置"><a href="#最佳配置" class="headerlink" title="最佳配置"></a>最佳配置</h5><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.23rdcl2poqrk.webp" width="70%" /><br><ul><li>关闭自动配置</li></ul><h3 id="触发机制-不容忽略方式"><a href="#触发机制-不容忽略方式" class="headerlink" title="触发机制 - 不容忽略方式"></a>触发机制 - 不容忽略方式</h3><ol><li>全量复制（主从复制时候，主会自动生成RDB）</li><li>debug reload（相当于不会将内存清空的重启，也会生成RDB）</li><li>shutdown</li></ol><br><h3 id="RDB现存问题"><a href="#RDB现存问题" class="headerlink" title="RDB现存问题"></a>RDB现存问题</h3><ul><li>耗时耗性能</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.b2ax18993q0.webp" width="50%" /><br><ul><li>不可控，丢失数据</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2hq85j7f4ni0.webp" width="50%" /><br><h2 id="AOF（Append-Only-File）"><a href="#AOF（Append-Only-File）" class="headerlink" title="AOF（Append Only File）"></a>AOF（Append Only File）</h2><ul><li>将 redis 执行过的所有写指令记录下来（它的写入是实时的），在下次 redis 重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了</li></ul><h3 id="AOF运行原理"><a href="#AOF运行原理" class="headerlink" title="AOF运行原理"></a>AOF运行原理</h3><ul><li>创建</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.1i410l2830jk.webp" width="50%" /><br><ul><li>恢复</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2ode8n5q6b80.webp" width="60%" /><br><h3 id="AOF的三种策略"><a href="#AOF的三种策略" class="headerlink" title="AOF的三种策略"></a>AOF的三种策略</h3><h4 id="always"><a href="#always" class="headerlink" title="always"></a>always</h4><ul><li>写入数据不会丢失</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.1nz1bf5i1ojk.webp" width="50%" /><br><h4 id="everysec"><a href="#everysec" class="headerlink" title="everysec"></a>everysec</h4><ul><li>是redis的配置默认值</li><li>可能会丢失1s的数据</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5uvzghtr78s0.webp" width="50%" /><br><h4 id="no"><a href="#no" class="headerlink" title="no"></a>no</h4><ul><li>根据操作系统决定</li></ul><br><h3 id="AOF的三种策略对比"><a href="#AOF的三种策略对比" class="headerlink" title="AOF的三种策略对比"></a>AOF的三种策略对比</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.7ezkvv0o0bg0.webp" width="50%" /><br><h3 id="AOF重写"><a href="#AOF重写" class="headerlink" title="AOF重写"></a>AOF重写</h3><ul><li>减少磁盘占用量</li><li>加速恢复速度</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3hr6crymmo0.webp" width="50%" /><br><h4 id="AOF重写的两种方式"><a href="#AOF重写的两种方式" class="headerlink" title="AOF重写的两种方式"></a>AOF重写的两种方式</h4><ul><li>BGREWRITEAOF （类似rdb的bgsave）<ul><li>将Redis中的数据进行回溯， 回溯成AOF文件</li></ul></li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5j30ijjpor40.webp" width="50%" /><br><ul><li>AOF重写配置</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.72n439aom900.webp" width="50%" /><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5wl4pwfy7ds0.webp" width="50%" /><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.yskrqzxtakw.webp" width="50%" /><br><h4 id="AOF重写流程"><a href="#AOF重写流程" class="headerlink" title="AOF重写流程"></a>AOF重写流程</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2b1z2py9ols0.webp" width="50%" /><br><h2 id="RDB与AOF的抉择"><a href="#RDB与AOF的抉择" class="headerlink" title="RDB与AOF的抉择"></a>RDB与AOF的抉择</h2><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2got5zb1qs20.webp" width="50%" /><br><h3 id="RDB最佳策略"><a href="#RDB最佳策略" class="headerlink" title="RDB最佳策略"></a>RDB最佳策略</h3><ul><li>RDB</li></ul><ol><li>”关闭“</li><li>集中管理</li><li>主从，从开</li></ol><h3 id="AOF最佳策略"><a href="#AOF最佳策略" class="headerlink" title="AOF最佳策略"></a>AOF最佳策略</h3><ol><li>”开“：缓存和存储</li><li>AOF集中管理</li><li>everysec</li></ol><h3 id="最佳策略"><a href="#最佳策略" class="headerlink" title="最佳策略"></a>最佳策略</h3><ol><li>小分片</li><li>缓存或存储</li><li>监控（硬盘、内存、负载、网络）</li><li>足够的内存</li></ol><br><h1 id="常见的持久化开发运维问题"><a href="#常见的持久化开发运维问题" class="headerlink" title="常见的持久化开发运维问题"></a>常见的持久化开发运维问题</h1><h2 id="fork操作"><a href="#fork操作" class="headerlink" title="fork操作"></a>fork操作</h2><ul><li></li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3ofn5wyto2w0.webp" width="50%" /><br><ul><li>fork改善</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.25vvl1tdwgu8.webp" width="50%" /><br><h2 id="子进程开销和优化"><a href="#子进程开销和优化" class="headerlink" title="子进程开销和优化"></a>子进程开销和优化</h2><ul><li></li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5u5w40mtg9s0.webp" width="50%" /><br><h2 id="硬盘优化"><a href="#硬盘优化" class="headerlink" title="硬盘优化"></a>硬盘优化</h2><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5lnrmjt1hw40.webp" width="50%" /><br><h2 id="AOF追加阻塞"><a href="#AOF追加阻塞" class="headerlink" title="AOF追加阻塞"></a>AOF追加阻塞</h2><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.6v89xx5ytl00.webp" width="50%" /><br><h2 id="AOF阻塞定位"><a href="#AOF阻塞定位" class="headerlink" title="AOF阻塞定位"></a>AOF阻塞定位</h2><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3t06d4zqkpo0.webp" width="50%" /><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3qdujdqyup60.webp" width="50%" /><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.60mk8wrt4lk0.webp" width="50%" /><br><h1 id="Redis复制的原理与优化"><a href="#Redis复制的原理与优化" class="headerlink" title="Redis复制的原理与优化"></a>Redis复制的原理与优化</h1><h2 id="什么是主从复制"><a href="#什么是主从复制" class="headerlink" title="什么是主从复制"></a>什么是主从复制</h2><ul><li>一个master可以有多个slave，但一个slave只能有一个master</li><li>数据流向必须是单向的。master -&gt; slave</li><li>变成从节点前会把数据清楚</li></ul><h2 id="主从复制作用"><a href="#主从复制作用" class="headerlink" title="主从复制作用"></a>主从复制作用</h2><ul><li>一个数据提供了多个副本（成为高可用、分布式的基础）</li><li>扩展读性能（读写分离）</li></ul><h2 id="主从复制实现"><a href="#主从复制实现" class="headerlink" title="主从复制实现"></a>主从复制实现</h2><h3 id="slaveof-命令"><a href="#slaveof-命令" class="headerlink" title="slaveof 命令"></a>slaveof 命令</h3><ul><li>复制（slaveof 这个命令是异步的）</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2pa32y5jfz80.webp" width="60%"/><br><ul><li>取消复制</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.7jnus8oq23k0.webp" width="60%"/><br><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slaveof ip port</span><br><span class="line">slave-read-only yes</span><br></pre></td></tr></table></figure><h3 id="主从复制-命令和配置的比较"><a href="#主从复制-命令和配置的比较" class="headerlink" title="主从复制-命令和配置的比较"></a>主从复制-命令和配置的比较</h3><table><thead><tr><th align="center">方式</th><th align="center">命令</th><th align="center">配置</th></tr></thead><tbody><tr><td align="center">优点</td><td align="center">无需重启</td><td align="center">统一配置</td></tr><tr><td align="center">缺点</td><td align="center">不便于管理</td><td align="center">需要管理</td></tr></tbody></table><h3 id="主从配置操作"><a href="#主从配置操作" class="headerlink" title="主从配置操作"></a>主从配置操作</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">info replication</span><br></pre></td></tr></table></figure><h2 id="主从复制原理"><a href="#主从复制原理" class="headerlink" title="主从复制原理"></a>主从复制原理</h2><h3 id="全量复制过程原理"><a href="#全量复制过程原理" class="headerlink" title="全量复制过程原理"></a>全量复制过程原理</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.312gr8tguvm0.webp" width="50%" /><br><h3 id="全量复制开销"><a href="#全量复制开销" class="headerlink" title="全量复制开销"></a>全量复制开销</h3><ol><li>bgsave时间</li><li>RDB文件网络传输时间</li><li>从节点清空数据时间</li><li>从节点加载RDB时间</li><li>可能的AOF重写时间</li></ol><h3 id="部分复制过程原理"><a href="#部分复制过程原理" class="headerlink" title="部分复制过程原理"></a>部分复制过程原理</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3vhs1nc1dzi0.webp" width="50%" /><br><h2 id="主从复制中的故障处理与常见问题"><a href="#主从复制中的故障处理与常见问题" class="headerlink" title="主从复制中的故障处理与常见问题"></a>主从复制中的故障处理与常见问题</h2><ul><li>故障不可避免</li><li>自动故障转移</li><li>故障分为master故障和slave故障</li></ul><h3 id="读写分离问题"><a href="#读写分离问题" class="headerlink" title="读写分离问题"></a>读写分离问题</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.a738ve0k3y8.webp" width="50%" /><br><h3 id="配置不一致"><a href="#配置不一致" class="headerlink" title="配置不一致"></a>配置不一致</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.nl2kmy53a0w.webp" width="50%" /><br><h3 id="规避全量复制"><a href="#规避全量复制" class="headerlink" title="规避全量复制"></a>规避全量复制</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.6pe5jkk3nm80.webp" width="50%" /><br><h3 id="规避复制风暴"><a href="#规避复制风暴" class="headerlink" title="规避复制风暴"></a>规避复制风暴</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.361o49e7h2i0.webp" width="50%" /><br><h1 id="Redis-Sentinel"><a href="#Redis-Sentinel" class="headerlink" title="Redis Sentinel"></a>Redis Sentinel</h1><h1 id="第9章-初识Redis-Cluster"><a href="#第9章-初识Redis-Cluster" class="headerlink" title="第9章 初识Redis Cluster"></a>第9章 初识Redis Cluster</h1><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><ol><li>jedis 需要熟悉,有些代码还要手动过一遍才是</li><li>生产环境普通用户后台启动redis</li><li>部分图片内容是否应该转化为代码呢？</li><li>bitmap不太懂，还需要深入理解。还包括 hyperloglog、geo</li><li>RDB和AOF的恢复原理和过程是怎么样子的？</li><li>主从复制操作虽然简单，但是最好是实践一下</li></ol></blockquote><img src="" width="50%" /><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;API的理解和使用&quot;&gt;&lt;a href=&quot;#API的理解和使用&quot; class=&quot;headerlink&quot; title=&quot;API的理解和使用&quot;&gt;&lt;/a&gt;API的理解和使用&lt;/h1&gt;&lt;br&gt;







&lt;br&gt;

&lt;h2 id=&quot;单线程&quot;&gt;&lt;a href=&quot;#单线程&quot;</summary>
      
    
    
    
    <category term="Database" scheme="https://ratears.github.io/dev.ratears.life/Categories/Database/"/>
    
    <category term="NoSQL" scheme="https://ratears.github.io/dev.ratears.life/Categories/Database/NoSQL/"/>
    
    <category term="Redis" scheme="https://ratears.github.io/dev.ratears.life/Categories/Database/NoSQL/Redis/"/>
    
    
    <category term="NoSQL" scheme="https://ratears.github.io/dev.ratears.life/Tags/NoSQL/"/>
    
    <category term="Database" scheme="https://ratears.github.io/dev.ratears.life/Tags/Database/"/>
    
    <category term="Redis" scheme="https://ratears.github.io/dev.ratears.life/Tags/Redis/"/>
    
    <category term="Cache" scheme="https://ratears.github.io/dev.ratears.life/Tags/Cache/"/>
    
  </entry>
  
  <entry>
    <title>Redis study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/Redis-study-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/Redis-study-notes/</id>
    <published>2022-12-01T14:31:29.000Z</published>
    <updated>2022-12-01T14:31:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="学习前言"><a href="#学习前言" class="headerlink" title="学习前言"></a>学习前言</h1><ul><li>这个学习笔记，详尽的记录了Redis的核心技术与实战技能。是我学习和使用Redis技术过程的一个笔记。用于复习和查漏补缺</li><li>学习Redis应该着重掌握以下这几个方面内容：<ul><li>技术适用场景（解决了什么问题、同类技术对比、特性与优缺点）</li><li>技术的发展脉络（起源、历史版本差异、未来前瞻）</li><li>开发、运维、监控（Demo、API理解和使用、开发规范、运维监控技术[安装部署]、故障排查与解决）</li><li>底层技术与核心原理（底层算法、数据结构、技术、原理）</li><li>企业级最佳实战（实战案例、高可用、分布式[集群]、高性能[调优]、架构设计[架构方案设计、优化]）</li><li>避坑（故障排查与解决）</li><li>八股文（常见的八股文问题能够知晓、可以独立架构设计）</li></ul></li></ul><br><br><br><h1 id="Redis-起步"><a href="#Redis-起步" class="headerlink" title="Redis 起步"></a>Redis 起步</h1><h2 id="NoSQL-简介"><a href="#NoSQL-简介" class="headerlink" title="NoSQL 简介"></a>NoSQL 简介</h2><ul><li>NoSQL（“non-relational”， “Not Only SQL”），泛指非关系型的数据库。随着互联网 web2.0网站的兴起，传统的关系数据库在处理 web2.0 网站，特别是超大规模和高并发的 SNS 类型的 web2.0 纯动态网站已经显得力不从心，出现了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。<strong>NoSQL 数据库的产生就是为了解决大规模数据集合多重数据种类带来的挑战，特别是大数据应用难题。</strong></li></ul><p>（1）键值存储数据库</p><ul><li>就像 Map 一样的 key-value 对。典型代表就是 Redis。</li></ul><p>（2）列存储数据库</p><ul><li>关系型数据库是典型的行存储数据库。其存在的问题是，按行存储的数据在物理层面占用的是连续存储空间，不适合海量数据存储。而按列存储则可实现分布式存储，适合海量存储。典型代表是 HBase。</li></ul><p>（3）文档型数据库</p><ul><li>其是 NoSQL 与关系型数据的结合，最像关系型数据库的 NoSQL。典型代表是 MongoDB。</li></ul><p>（4）图形(Graph)数据库</p><ul><li>用于存放一个节点关系的数据库，例如描述不同人间的关系。典型代表是 Neo4J。</li></ul><br><h2 id="Redis-简介"><a href="#Redis-简介" class="headerlink" title="Redis 简介"></a>Redis 简介</h2><h3 id="Redis-起源"><a href="#Redis-起源" class="headerlink" title="Redis 起源"></a>Redis 起源</h3><ul><li>Redis 这个名字的意思是 Remote Dictionary Server。Redis 项目始于 Salvatore Sanfilippo（绰号<em>antirez</em>），Redis 的原始开发人员试图提高其意大利初创公司的可扩展性，开发了一个实时Web 日志分析器。在使用传统数据库系统扩展某些类型的工作负载时遇到重大问题后，Sanfilippo 于 2009 年开始在Tcl中制作第一个 Redis 概念验证版本的原型。后来 Sanfilippo 将该原型翻译成 C 语言并实现了第一种数据类型，即列表。在内部成功使用该项目几周后，Sanfilippo 决定将其开源</li></ul><br><h3 id="Redis-是什么"><a href="#Redis-是什么" class="headerlink" title="Redis 是什么"></a>Redis 是什么</h3><ul><li>Redis，Remote Dictionary Server，远程字典服务，由意大利人 Salvatore Sanfilippo（又名 Antirez）开发，是一个使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、NoSQL 开源内存数据库，其提供多种语言的 API。从 2010 年 3 月 15 日起，Redis 的开发工作由 VMware 主持。从2013 年 5 月开始，Redis 的开发由 Pivotal 赞助。</li></ul><blockquote><p>Redis 之所以称之为字典服务，是因为 Redis 是一个 key-value 存储系统。支持存储的 value类型很多，包括 String(字符串)、List(链表)、Set(集合)、Zset(sorted set –有序集合)和 Hash（哈希类型）等。</p></blockquote><blockquote><p><strong>开源、基于 key-value 存储系统、支持多种数据结构、高性能、功能丰富</strong></p></blockquote><br><h3 id="Redis-的用途"><a href="#Redis-的用途" class="headerlink" title="Redis 的用途"></a>Redis 的用途</h3><ul><li>Redis 在生产中使用最多的场景就是做数据缓存。即客户端从 DBMS 中查询出的数据首先写入到 Redis 中，后续无论哪个客户端再需要访问该数据，直接读取 Redis 中的即可，不仅减小了 RT，而且降低了 DBMS 的压力。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.cdgu076yuww.webp" width="60%"><br><ul><li>根据 Redis 缓存的数据与 DBMS 中数据的同步性划分，缓存一般可划分为两类：<strong>实时同步缓存</strong>，与<strong>阶段性同步缓存</strong>。</li></ul><blockquote><p>实时同步缓存是指，DBMS 中数据更新后，Redis 缓存中的存放的相关数据会被立即清除，以促使再有对该数据的访问请求到来时，必须先从 DBMS 中查询获取到最新数据，然后再写入到 Redis。</p></blockquote><blockquote><p>阶段性同步缓存是指，Redis 缓存中的数据允许在一段时间内与 DBMS 中的数据不完全一致。而这个时间段就是这个缓存数据的过期时间。</p></blockquote><br><h3 id="Redis-特性"><a href="#Redis-特性" class="headerlink" title="Redis 特性"></a>Redis 特性</h3><blockquote><p><font color=red>能够做缓存的技术、中间件很多，例如，MyBatis 自带的二级缓存、Memched 等。只所以在生产中做缓存的产品几乎无一例外的会选择 Redis，是因为它有很多其它产品所不具备的特性。</font></p></blockquote><ul><li><strong>性能极高</strong>：Redis 读的速度可以达到 11w 次/s，写的速度可以达到 8w 次/s。之所以具有这么高的性能，因为以下几点原因：<ul><li>（1）Redis 的所有操作都是在内存中发生的。（性能高的主要原因）</li><li>（2）Redis 是用 C 语言开发的。</li><li>（3）单线程</li><li>（4）Redis 源码非常精细（集性能与优雅于一身）。</li></ul></li><li><strong>简单稳定</strong>：Redis 源码很少，不依赖外部库，单线程模型。早期版本只有 2w 行左右。从 3.0 版本开始，增加了集群功能，代码变为了 5w 行左右。</li><li><strong>持久化</strong>：Redis的所有数据保存在内存中，对数据的更新异步的保存在磁盘上。（Redis 内存中的数据可以进行持久化，其有两种方式：RDB 与 AOF。）</li><li><strong>高可用、分布式</strong>：Redis 提供了高可用的主从集群功能，可以确保系统的安全性。</li><li><strong>丰富的数据类型</strong>：Redis 是一个 key-value 存储系统。支持存储的 value 类型很多，包括String(字符串)、List(链表)、Set(集合)、Zset(sorted set –有序集合)和 Hash（哈希类型）等，还有 BitMap、HyperLogLog、Geospatial 类型。<ul><li>BitMap：一般用于大数据量的二值性统计。</li><li>HyperLogLog：其是 Hyperlog Log，用于对数据量超级庞大的日志做去重统计。</li><li>Geospatial：地理空间，其主要用于地理位置相关的计算。</li></ul></li><li><strong>功能丰富</strong>：Redis 提供了数据过期功能、发布/订阅功能、简单事务功能，还支持 Lua脚本扩展功能。</li><li><strong>支持多种客户端语言</strong>：Redis 提供了简单的 TCP 通信协议，编程语言可以方便地的接入 Redis。所以，有很多的开源社区、大公司等开发出了很多语言的 Redis 客户端。</li><li><strong>支持 ACL 权限控制</strong>：之前的权限控制非常笨拙。从 Redis6 开始引入了 ACL 模块，可以为不同用户定制不同的用户权限。</li></ul><blockquote><p>ACL，Access Control List，访问控制列表，是一种细粒度的权限管理策略，可以针对任意用户与组进行权限控制。目前大多数 Unix 系统与 Linux 2.6 版本已经支持 ACL 了。Zookeeper 早已支持 ACL 了。</p><p>Unix 与 Linux 系统默认使用是 UGO（User、Group、Other）权限控制策略，其是一种粗粒度的权限管理策略。</p></blockquote><ul><li><strong>支持多线程 IO 模型</strong>：Redis 之前版本采用的是单线程模型，从 6.0 版本开始支持了多线程模型。</li></ul><br><h3 id="Redis-典型使用场景"><a href="#Redis-典型使用场景" class="headerlink" title="Redis 典型使用场景"></a>Redis 典型使用场景</h3><ul><li>缓存系统</li><li>计数器</li><li>消息队列</li><li>排行榜</li><li>社交网络</li><li>实时系统</li></ul><br><h2 id="Redis-的安装与启动"><a href="#Redis-的安装与启动" class="headerlink" title="Redis 的安装与启动"></a>Redis 的安装与启动</h2><h3 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h3><p>（1）下载需要的依赖</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install gcc gcc-c++ kernel-devel</span><br></pre></td></tr></table></figure><blockquote><p>由于 Redis 是由 C/C++语言编写的，而从官网下载的 Redis 安装包是需要编译后才可安装的，所以对其进行编译就必须要使用相关编译器。对于 C/C++语言的编译器，使用最多的是gcc 与 gcc-c++，而这两款编译器在 CentOS7 中是没有安装的，所以首先要安装这两款编译器。</p><p>GCC，GNU Compiler Collection，GNU 编译器集合。</p></blockquote><p>（2）下载Redis安装包，并解压</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf redis-7.0.5.tar.gz -C /install/</span><br></pre></td></tr></table></figure><p>（3）编译</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入到解压目录中，然后执行编译命令 make</span></span><br><span class="line"><span class="comment"># 编译过程是根据 Makefile 文件进行的，而 Redis 解压包中已经存在该文件了。所以可以直接进行编译了。</span></span><br><span class="line">make</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果直接 make 会失败报错 原因：建立redis时系统默认使用jemalloc作为内存管理工具，但是当前无可用jemalloc，则切换为标准内存管理工具libc问题解决</span></span><br><span class="line">make MALLOC=libc</span><br></pre></td></tr></table></figure><p>（4）安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在 Linux 中对于编译过的安装包执行 make install 进行安装。</span></span><br><span class="line"></span><br><span class="line">[root@localhost redis-7.0.5]<span class="comment"># make install</span></span><br><span class="line"><span class="built_in">cd</span> src &amp;&amp; make install</span><br><span class="line"><span class="built_in">which</span>: no python3 <span class="keyword">in</span> (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)</span><br><span class="line">make[1]: Entering directory `/install/redis-7.0.5/src<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    CC Makefile.dep</span></span><br><span class="line"><span class="string">make[1]: Leaving directory `/install/redis-7.0.5/src&#x27;</span></span><br><span class="line"><span class="built_in">which</span>: no python3 <span class="keyword">in</span> (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)</span><br><span class="line">make[1]: Entering directory `/install/redis-7.0.5/src<span class="string">&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Hint: It&#x27;</span>s a good idea to run <span class="string">&#x27;make test&#x27;</span> ;)</span><br><span class="line"></span><br><span class="line">    INSTALL redis-server</span><br><span class="line">    INSTALL redis-benchmark</span><br><span class="line">    INSTALL redis-cli</span><br><span class="line">make[1]: Leaving directory `/install/redis-7.0.5/src<span class="string">&#x27;</span></span><br><span class="line"><span class="string">[root@localhost redis-7.0.5]#</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 可以看到，共安装了三个组件：redis 服务器、客户端、一个性能测试工具 benchmark。</span></span><br></pre></td></tr></table></figure><br><h3 id="Redis-可执行文件说明"><a href="#Redis-可执行文件说明" class="headerlink" title="Redis 可执行文件说明"></a>Redis 可执行文件说明</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装完成后，在 /usr/local/bin 目录，可以看到出现了很多的redis可执行文件。</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ll /usr/local/bin/</span></span><br><span class="line">total 21500</span><br><span class="line">-rwxr-xr-x. 1 root root  5197848 Nov 15 00:20 redis-benchmark</span><br><span class="line">lrwxrwxrwx. 1 root root       12 Nov 15 00:20 redis-check-aof -&gt; redis-server</span><br><span class="line">lrwxrwxrwx. 1 root root       12 Nov 15 00:20 redis-check-rdb -&gt; redis-server</span><br><span class="line">-rwxr-xr-x. 1 root root  5411048 Nov 15 00:20 redis-cli</span><br><span class="line">lrwxrwxrwx. 1 root root       12 Nov 15 00:20 redis-sentinel -&gt; redis-server</span><br><span class="line">-rwxr-xr-x. 1 root root 11398056 Nov 15 00:20 redis-server</span><br></pre></td></tr></table></figure><ul><li>redis-server    -    redis服务器</li><li>redis-cli    -    redis命令行客户端</li><li>redis-benchmark    -    redis性能测试工具</li><li>redis-check-aof    -    AOF文件修复工具</li><li>redis-check-dump    -    RDB文件检查工具</li><li>redis-sentinel    -    Sentinel服务器（2.8之后）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过 echo $PATH 可以看到，/usr/local/bin 目录是存在于该系统变量中的，这样这些命令就可以在任意目录中执行了。</span></span><br><span class="line">[root@localhost ~]<span class="comment"># echo $PATH</span></span><br><span class="line">/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin</span><br></pre></td></tr></table></figure><br><h3 id="Redis-的启动"><a href="#Redis-的启动" class="headerlink" title="Redis 的启动"></a>Redis 的启动</h3><h4 id="前台启动"><a href="#前台启动" class="headerlink" title="前台启动"></a>前台启动</h4><h5 id="最简启动-前台启动"><a href="#最简启动-前台启动" class="headerlink" title="最简启动/前台启动"></a>最简启动/前台启动</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在任意目录执行 redis-server 命令即可启动 Redis。这种启动方式使用默认配置启动。且会占用当前命令行窗口。</span></span><br><span class="line">redis-server</span><br></pre></td></tr></table></figure><br><h5 id="动态参数启动"><a href="#动态参数启动" class="headerlink" title="动态参数启动"></a>动态参数启动</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server --port [port]</span><br></pre></td></tr></table></figure><br><h4 id="后台启动"><a href="#后台启动" class="headerlink" title="后台启动"></a>后台启动</h4><h5 id="命令式后台启动"><a href="#命令式后台启动" class="headerlink" title="命令式后台启动"></a>命令式后台启动</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># nohup redis-server &amp;</span></span><br><span class="line">[1] 35057</span><br><span class="line">[root@localhost ~]<span class="comment"># nohup: ignoring input and appending output to ‘nohup.out’</span></span><br><span class="line"></span><br><span class="line">[root@localhost ~]<span class="comment"># ll</span></span><br><span class="line">total 8</span><br><span class="line">-rw-------. 1 root root 1259 Nov 14 23:52 anaconda-ks.cfg</span><br><span class="line">-rw-------. 1 root root 1195 Nov 15 00:48 nohup.out</span><br><span class="line">[root@localhost ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><blockquote><p>使用 nohup 命令，最后再添加一个&amp;符，可以使要启动的程序在后台以守护进程方式运行。这样的好处是，进程启动后不会占用一个会话窗口，且其还会在当前目录，即运行启动命令的当前目录中创建一个 nohup.out 文件用于记录 Redis 的操作日志。</p></blockquote><blockquote><p>使用 nohup 命令可以使 Redis 后台启动，但每次都要键入 nohup 与&amp;符，比较麻烦。可以通过修改 Linux 中 Redis 的核心配置文件 redis.conf 达到后台启动的目的。redis.conf 文件在Redis 的安装目录根下。</p></blockquote><br><h5 id="配置文件式后台启动（推荐）"><a href="#配置文件式后台启动（推荐）" class="headerlink" title="配置文件式后台启动（推荐）"></a>配置文件式后台启动（推荐）</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server [configPath]</span><br></pre></td></tr></table></figure><ul><li><font color=red><strong>生产环境选择配置文件方式启动，因为我们的配置参数很多，需要（便于）集中化管理。且单机多实例配置文件可以用端口区分开</strong></font></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# cd /usr/local/bin/</span><br><span class="line">[root@localhost bin]# mkdir config</span><br><span class="line">[root@localhost bin]# cp /install/redis-7.0.5/redis.conf config/</span><br><span class="line"></span><br><span class="line">[root@localhost bin]# vim config/redis.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将 daemonize 属性值由 no 改为 <span class="built_in">yes</span>，使 Redis 进程以守护进程方式运行。</span></span><br><span class="line">daemonize yes</span><br><span class="line"></span><br><span class="line">[root@localhost bin]# redis-server /usr/local/bin/config/redis.conf</span><br></pre></td></tr></table></figure><ul><li>修改配置文件后再启动 Redis，就无需再键入 nohup 与&amp;符了，但必须要指定启动所使用的 Redis配置文件。</li></ul><blockquote><p>使用 nohup redis-server &amp;命令启动 Redis 时，启动项中已经设置好了 Redis 各个参数的默认值，Redis 会按照这些设置的参数进行启动。但这些参数是可以在配置文件中进行修改的，修改后，需要在启动命令中指定要加载的配置文件，这样，配置文件中的参数值将覆盖原默认值。</p></blockquote><blockquote><p>Redis 已经给我们提供好了配置文件模板，是 Redis 安装目录的根目录下的 redis.conf 文件。由于刚刚对 redis.conf 配置文件做了修改，所以在开启 Redis 时需要显示指出要加载的配置文件。配置文件应紧跟在 redis-server 的后面。</p></blockquote><br><h3 id="Redis服务验证-（查看服务正常启动）"><a href="#Redis服务验证-（查看服务正常启动）" class="headerlink" title="Redis服务验证 （查看服务正常启动）"></a>Redis服务验证 （查看服务正常启动）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ps -ef |grep redis</span><br><span class="line"></span><br><span class="line">netstat -antpl grep redis</span><br><span class="line"></span><br><span class="line">redis-cli -h [ip] -p [port] ping </span><br></pre></td></tr></table></figure><br><h3 id="Redis-的停止"><a href="#Redis-的停止" class="headerlink" title="Redis 的停止"></a>Redis 的停止</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli shutdown</span><br><span class="line"></span><br><span class="line">redis-cli -a [redis_password] shutdown</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill -9 [redis_pid]</span><br></pre></td></tr></table></figure><br><h2 id="Redis-的客户端"><a href="#Redis-的客户端" class="headerlink" title="Redis 的客户端"></a>Redis 的客户端</h2><h3 id="连接前的配置"><a href="#连接前的配置" class="headerlink" title="连接前的配置"></a>连接前的配置</h3><ul><li>若要使远程主机上的客户端能够连接并访问到服务端的 Redis，则服务端首先要做如下配置。</li></ul><h4 id="绑定客户端-IP"><a href="#绑定客户端-IP" class="headerlink" title="绑定客户端 IP"></a>绑定客户端 IP</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Redis 通过修改配置文件来限定可以访问自己的客户端 IP。</span></span><br><span class="line"><span class="comment"># 默认配置如下，只允许当前主机访问当前的 Redis，其它主机均不可访问。所以，如果不想限定访问的客户端，只需要将该行注释掉即可。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># bind 127.0.0.1 -::1</span></span><br></pre></td></tr></table></figure><br><h4 id="关闭保护模式"><a href="#关闭保护模式" class="headerlink" title="关闭保护模式"></a>关闭保护模式</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 默认保护模式是开启的。其只允许本机的客户端访问，即只允许自己访问自己。但生产中应该关闭，以确保其它客户端可以连接 Redis。</span></span><br><span class="line"></span><br><span class="line">protected-mode no</span><br></pre></td></tr></table></figure><br><h4 id="设置访问密码"><a href="#设置访问密码" class="headerlink" title="设置访问密码"></a>设置访问密码</h4><ul><li>为 Redis 设置访问密码，可以对要读/写 Redis 的用户进行身份验证。没有密码的用户可以登录 Redis，但无法访问。</li></ul><p>（1）密码设置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 访问密码的设置位置在 redis.conf 配置文件中。默认是被注释掉的，没有密码。修改后需要重启redis生效</span></span><br><span class="line"></span><br><span class="line">requirepass redis@2022</span><br></pre></td></tr></table></figure><p>（2）使用密码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; auth redis@2022</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -a redis@2022</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -a redis@2022 shutdown</span><br></pre></td></tr></table></figure><br><h4 id="重启redis"><a href="#重启redis" class="headerlink" title="重启redis"></a>重启redis</h4><ul><li>修改相关配置后，需要重启redis，使其配置生效</li></ul><br><h3 id="Redis-客户端分类"><a href="#Redis-客户端分类" class="headerlink" title="Redis 客户端分类"></a>Redis 客户端分类</h3><h4 id="命令行客户端"><a href="#命令行客户端" class="headerlink" title="命令行客户端"></a>命令行客户端</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -h：指定要连接的 Redis 服务器的 IP</span></span><br><span class="line"><span class="comment"># -p：指定要连接的 Redis 的端口号</span></span><br><span class="line"><span class="comment"># 若连接的是本机 Redis，且端口号没有改变，保持默认的 6379，则-h 与-p 选项可以省略不写</span></span><br><span class="line"></span><br><span class="line">redis-cli -h 127.0.0.1 -p 6379</span><br></pre></td></tr></table></figure><br><h4 id="图形界面客户端"><a href="#图形界面客户端" class="headerlink" title="图形界面客户端"></a>图形界面客户端</h4><ul><li>Redis Desktop Manager<ul><li>官网为：<a class="link"   href="https://resp.app/%EF%BC%88%E5%8E%9F%E6%9D%A5%E6%98%AF" >https://resp.app/（原来是<i class="fas fa-external-link-alt"></i></a> <a class="link"   href="http://redisdesktop.com)./" >http://redisdesktop.com）。<i class="fas fa-external-link-alt"></i></a></li><li>Redis 的图形界面客户端很多，其中较出名的是 Redis Desktop Manager 的客户端。不过，该软件原来是免费软件，从 0.8.8 版本后变为了商业化收费软件。</li></ul></li><li>RedisPlus<ul><li>RedisPlus 的官网地址为 <a class="link"   href="https://gitee.com/MaxBill/RedisPlus%E3%80%82" >https://gitee.com/MaxBill/RedisPlus。<i class="fas fa-external-link-alt"></i></a></li></ul></li></ul><br><h4 id="Java-代码客户端"><a href="#Java-代码客户端" class="headerlink" title="Java 代码客户端"></a>Java 代码客户端</h4><ul><li>所谓 Java 代码客户端就是一套操作 Redis 的 API，其作用就像 JDBC 一样，所以 Java 代码客户端其实就是一个或多个 Jar 包，提供了对 Redis 的操作接口。</li><li>对 Redis 操作的 API 很多，例如 jdbc-redis、jredis 等，但最常用也是最有名的是 Jedis。</li></ul><br><br><br><h1 id="Redis-API-的使用和理解"><a href="#Redis-API-的使用和理解" class="headerlink" title="Redis API 的使用和理解"></a>Redis API 的使用和理解</h1><h2 id="Redis-命令"><a href="#Redis-命令" class="headerlink" title="Redis 命令"></a>Redis 命令</h2><h3 id="Redis-命令分类概述"><a href="#Redis-命令分类概述" class="headerlink" title="Redis 命令分类概述"></a>Redis 命令分类概述</h3><ul><li><p>Redis 根据命令所操作对象的不同，可以分为三大类：</p><ul><li><p><strong>对 Redis 进行基础性操作的命令</strong></p></li><li><p><strong>对 Key 的操作命令</strong>（包含通用key操作命令和对特定类型的key操作命令）</p></li><li><p><strong>对 Value 的操作命令</strong></p></li></ul></li></ul><br><h3 id="Redis-基础命令"><a href="#Redis-基础命令" class="headerlink" title="Redis 基础命令"></a>Redis 基础命令</h3><table><thead><tr><th align="center">操作命令/示例</th><th align="left">功能/说明</th></tr></thead><tbody><tr><td align="center">redis-cli -a redis@2022</td><td align="left">进入Redis命令行客户端</td></tr><tr><td align="center">ping</td><td align="left">键入 ping 命令，会看到 PONG 响应，则说明该客户端与 Redis 的连接是正常的。该命令亦称为心跳命令。</td></tr><tr><td align="center">set hello word</td><td align="left">set key value 会将指定 key-value 写入到 DB。</td></tr><tr><td align="center">get hello</td><td align="left">get key 则会读取指定 key 的 value 值。</td></tr><tr><td align="center">select 3</td><td align="left">Redis 默认有 16 个数据库。默认使用的是 0 号 DB，可以通过 select db 索引来切换 DB。</td></tr><tr><td align="center">dbsize</td><td align="left">dbsize 命令可以查看<strong>当前数据库中</strong> key 的数量。时间复杂度是O(1)，因其内部维护了一个计数器</td></tr><tr><td align="center">flushdb</td><td align="left">flushdb 命令仅仅删除的是当前数据库中的数据，不影响其它库。<br>如果使用了 禁止/重命名命令 则需要注意</td></tr><tr><td align="center">flushall</td><td align="left">flushall 命令可以删除所有库中的所有数据。所以该命令的使用一定要慎重。<br>如果使用了 禁止/重命名命令 则需要注意</td></tr><tr><td align="center">exit/quit</td><td align="left">使用 exit 或 quit 命令均可退出 Redis 命令行客户端。</td></tr></tbody></table><br><h3 id="Key-通用操作命令"><a href="#Key-通用操作命令" class="headerlink" title="Key 通用操作命令"></a>Key 通用操作命令</h3><ul><li>Redis 中存储的数据整体是一个 Map，其 key 为 String 类型，而 value 则可以是 String、Hash 表、List、Set 等类型。</li></ul><table><thead><tr><th>Key 操作命令</th><th align="left">格式</th><th align="left">功能</th><th align="left">说明</th></tr></thead><tbody><tr><td>keys</td><td align="left">KEYS pattern</td><td align="left">查找所有符合给定模式 pattern 的 key，pattern 为正则表达式</td><td align="left">KEYS 的速度非常快，但在一个大的数据库中使用它可能会阻塞当前服务器的服务。所以生产环境中一般不使用该命令，而使用 <code>scan</code> 命令代替</td></tr><tr><td>exists</td><td align="left">EXISTS key</td><td align="left">检查给定 key 是否存在</td><td align="left">若 key 存在，返回 1 ，否则返回 0</td></tr><tr><td>del</td><td align="left">DEL key [key …]</td><td align="left">删除给定的一个或多个 key 。不存在的 key 会被忽略</td><td align="left">返回被删除 key 的数量</td></tr><tr><td>rename</td><td align="left">RENAME key newkey</td><td align="left">将 key 改名为 newkey</td><td align="left">当 key 和 newkey 相同，或者 key 不存在时，返回一个错误。当 newkey 已经存在时， RENAME 命令将覆盖旧值。改名成功时提示 OK ，失败时候返回一个错误</td></tr><tr><td>move</td><td align="left">MOVE key db</td><td align="left">将当前数据库的 key 移动到给定的数据库 db 当中</td><td align="left">如果当前数据库(源数据库)和给定数据库(目标数据库)有相同名字的给定 key ，或者 key 不存在于当前数据库，那么 MOVE 没有任何效果。移动成功返回 1 ，失败则返回 0 。</td></tr><tr><td>type</td><td align="left">TYPE key</td><td align="left">返回 key 所储存的值的类型</td><td align="left">返回值有以下六种<br/>none (key 不存在)<br/> string (字符串)<br/> list (列表)<br/> set (集合)<br/> zset (有序集)<br/> hash (哈希表)</td></tr><tr><td>expire 与 pexpire</td><td align="left">EXPIRE key seconds</td><td align="left">为给定 key 设置生存时间。当 key 过期时(生存时间为 0)，它会被自动删除。expire 的时间单位为秒，pexpire 的时间单位为毫秒。在 Redis 中，带有生存时间的 key被称为“易失的”(volatile)。</td><td align="left">生存时间设置成功返回 1。若 key 不存在时返回 0 。rename 操作不会改变 key的生存时间。</td></tr><tr><td>ttl 与 pttl</td><td align="left">TTL key</td><td align="left">TTL, time to live，返回给定 key 的剩余生存时间</td><td align="left">其返回值存在三种可能：<br/>（1）当 key 不存在时，返回 -2 。<br/>（2）当 key 存在但没有设置剩余生存时间时，返回 -1 。<br/>（3）否则，返回 key 的剩余生存时间。ttl 命令返回的时间单位为秒，而 pttl 命令返回的时间单位为毫秒。</td></tr><tr><td>persist</td><td align="left">PERSIST key</td><td align="left">去除给定 key 的生存时间，将这个 key 从“易失的”转换成“持久的”</td><td align="left">当生存时间移除成功时，返回 1；若 key 不存在或 key 没有设置生存时间，则返回 0。</td></tr><tr><td>randomkey</td><td align="left">RANDOMKEY</td><td align="left">从当前数据库中随机返回(不删除)一个 key。</td><td align="left">当数据库不为空时，返回一个 key。当数据库为空时，返回 nil</td></tr></tbody></table><ul><li><strong>scan</strong><ul><li>格式：SCAN cursor [MATCH pattern] [COUNT count] [TYPE type]</li><li>功能：用于迭代数据库中的数据库键。其各个选项的意义为：<ul><li>cursor：本次迭代开始的游标。</li><li>pattern ：本次迭代要匹配的 key 的模式。 </li><li>count ：本次迭代要从数据集里返回多少元素，默认值为 10 。</li><li>type：本次迭代要返回的 value 的类型，默认为所有类型。</li></ul></li></ul></li></ul><blockquote><p>SCAN 命令是一个基于游标 cursor 的迭代器：SCAN 命令每次被调用之后，都会向用户返回返回一个包含两个元素的数组， 第一个元素是用于进行下一次迭代的新游标，而第二个元素则是一个数组， 这个数组中包含了所有被迭代的元素。用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数，以此来延续之前的迭代过程。当SCAN 命令的游标参数被设置为 0 时，服务器将开始一次新的迭代。如果新游标返回 0表示迭代已结束。</p></blockquote><ul><li><p>说明：</p><ul><li>使用间断的、负数、超出范围或者其他非正常的游标来执行增量式迭代不会造成服务器崩溃。</li><li>当数据量很大时，count 的数量的指定可能会不起作用，Redis 会自动调整每次的遍历数目。由于 scan 命令每次执行都只会返回少量元素，所以该命令可以用于生产环境，而不会出现像 KEYS 命令带来的服务器阻塞问题。</li><li>增量式迭代命令所使用的算法只保证在数集的大小有界的情况下迭代才会停止，换句话说，如果被迭代数据集的大小不断地增长的话，增量式迭代命令可能永远也无法<br>完成一次完整迭代。即当一个数据集不断地变大时，想要访问这个数据集中的所有元素就需要做越来越多的工作， 能否结束一个迭代取决于用户执行迭代的速度是否比数据集增长的速度更快。</li></ul></li><li><p>相关命令：另外还有 3 个 scan 命令用于对三种类型的 value 进行遍历。</p><ul><li>hscan：属于 Hash 型 Value 操作命令集合，用于遍历当前 db 中指定 Hash 表的所有 field-value 对。</li><li>sscan：属于 Set 型 Value 操作命令集合，用于遍历当前 db 中指定 set 集合的所有元素</li><li>zscan：属于 ZSet 型 Value 操作命令集合，用于遍历当前 db 中指定有序集合的所有元素（数值与元素值）</li></ul></li></ul><br><h3 id="String-型-Value-操作命令"><a href="#String-型-Value-操作命令" class="headerlink" title="String 型 Value 操作命令"></a>String 型 Value 操作命令</h3><h2 id="Redis-Java-客户端"><a href="#Redis-Java-客户端" class="headerlink" title="Redis Java 客户端"></a>Redis Java 客户端</h2><h3 id="Jedis"><a href="#Jedis" class="headerlink" title="Jedis"></a>Jedis</h3><h4 id="Jedis-简介"><a href="#Jedis-简介" class="headerlink" title="Jedis 简介"></a>Jedis 简介</h4><ul><li>Jedis 是一个基于 java 的 Redis 客户端连接工具，旨在提升性能与易用性。其 github 上的官网地址为：<a class="link"   href="https://github.com/redis/jedis%E3%80%82" >https://github.com/redis/jedis。<i class="fas fa-external-link-alt"></i></a></li></ul><br><h4 id="Jedis-实战"><a href="#Jedis-实战" class="headerlink" title="Jedis 实战"></a>Jedis 实战</h4><h5 id="（1）引入-maven-依赖"><a href="#（1）引入-maven-依赖" class="headerlink" title="（1）引入 maven 依赖"></a>（1）引入 maven 依赖</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--jedis 依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="（2）Jedis直连"><a href="#（2）Jedis直连" class="headerlink" title="（2）Jedis直连"></a>（2）Jedis直连</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.生成一个Jedis对象，这个对象负责和指定Redis节点进行通信</span></span><br><span class="line">      <span class="type">Jedis</span> <span class="variable">jedis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Jedis</span>(<span class="string">&quot;192.168.146.135&quot;</span>,<span class="number">6379</span>);</span><br><span class="line">      <span class="comment">// 设置连接密码</span></span><br><span class="line">      jedis.auth(<span class="string">&quot;redis@2022&quot;</span>);</span><br><span class="line">      <span class="comment">// 2.jedis执行set操作</span></span><br><span class="line">      jedis.set(<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>);</span><br><span class="line">      <span class="comment">//3.jedis执行get操作,value=&quot;world</span></span><br><span class="line">      <span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> jedis.get(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">      System.out.println(value);</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Jedis(String host, <span class="type">int</span> port, <span class="type">int</span> connectionTimeout, <span class="type">int</span> soTimeout) </span><br><span class="line"><span class="comment">// host:Redis节点的所在机器的IP</span></span><br><span class="line"><span class="comment">// port : Redis节点的端口</span></span><br><span class="line"><span class="comment">// connectionTimeout:客户端连接超时时间</span></span><br><span class="line"><span class="comment">// soTimeout:客户端读写超时时间</span></span><br></pre></td></tr></table></figure><br><h5 id="（3）JedisPool简单使用"><a href="#（3）JedisPool简单使用" class="headerlink" title="（3）JedisPool简单使用"></a>（3）JedisPool简单使用</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始化Jedis连接池，通常来讲JedisPool是单例的。</span></span><br><span class="line">       <span class="type">GenericObjectPoolConfig</span> <span class="variable">poolConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GenericObjectPoolConfig</span>();</span><br><span class="line">       <span class="type">JedisPool</span> <span class="variable">jedisPool</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JedisPool</span>(poolConfig,<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">6379</span>);</span><br><span class="line"></span><br><span class="line">       <span class="type">Jedis</span> <span class="variable">jedis</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="comment">// 1.从连接池获取jedis对象</span></span><br><span class="line">           jedis = jedisPool.getResource();</span><br><span class="line">           <span class="comment">// 2. 执行操作</span></span><br><span class="line">           jedis.set(<span class="string">&quot;java&quot;</span>,<span class="string">&quot;spring&quot;</span>);</span><br><span class="line">           System.out.println(jedis.get(<span class="string">&quot;java&quot;</span>));</span><br><span class="line">       &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">           <span class="comment">// 如果使用JedisPool,close操作不是关闭连接，代表归还连接池</span></span><br><span class="line">           <span class="keyword">if</span> (jedis != <span class="literal">null</span>)&#123;</span><br><span class="line">               jedis.close();</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><br><h4 id="Jedis-与-JedisPool比较"><a href="#Jedis-与-JedisPool比较" class="headerlink" title="Jedis 与 JedisPool比较"></a>Jedis 与 JedisPool比较</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/97b459332ea53d7e42b90bd2743dcda.396pfset03e0.webp" width="50%" /><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/7e5d97f719abbfe9b363126e682f86d.3g21qh3ltu20.webp" width="50%" /><br><table><thead><tr><th align="center"></th><th align="left">优点</th><th align="left">缺点</th></tr></thead><tbody><tr><td align="center">直连</td><td align="left">简单方便<br>适用于少量长期连接的场景</td><td align="left">存在每次新建/关闭TCP开销<br>资源无法控制,存在连接泄露的可能<br>Jedis对象线程不安全</td></tr><tr><td align="center">连接池</td><td align="left">Jedis预先生成，降低开销使用<br/>连接池的形式保护和控制资源的使用</td><td align="left">相对于直连，使用相对麻烦尤其在资源的管理上需要很多参数来保证，一旦规划不合理也会出现问题。</td></tr></tbody></table><br><h4 id="JedisPool-配置优化"><a href="#JedisPool-配置优化" class="headerlink" title="JedisPool 配置优化"></a>JedisPool 配置优化</h4><h5 id="JedisPool-配置-资源数控制"><a href="#JedisPool-配置-资源数控制" class="headerlink" title="JedisPool 配置 - 资源数控制"></a>JedisPool 配置 - 资源数控制</h5><table><thead><tr><th align="center">参数名</th><th align="left">含义</th><th align="center">默认值</th></tr></thead><tbody><tr><td align="center">maxTotal</td><td align="left">资源池最大连接数</td><td align="center">8</td></tr><tr><td align="center">maxIdle</td><td align="left">资源允许最大空闲连接数</td><td align="center">0</td></tr><tr><td align="center">minIdle</td><td align="left">资源池确保最少空闲连接数</td><td align="center">0</td></tr><tr><td align="center">jmxEnabled</td><td align="left">是否开启jmx监控，可用于监控</td><td align="center">true</td></tr></tbody></table><br><h5 id="JedisPool-配置-借还参数"><a href="#JedisPool-配置-借还参数" class="headerlink" title="JedisPool 配置 - 借还参数"></a>JedisPool 配置 - 借还参数</h5><table><thead><tr><th align="center">参数名</th><th>含义</th><th align="center">默认值</th><th align="center">使用建议</th></tr></thead><tbody><tr><td align="center">blockWhenExhausted</td><td>当资源池用尽后，调用者是否要等待。只有当为true时，下面的maxWaitMillis才会生效</td><td align="center">true</td><td align="center">建议使用默认值</td></tr><tr><td align="center">maxWaitMillis</td><td>当资源池连接用尽后，调用者的最大等待时间(单位为毫秒)</td><td align="center">-1:表示永不超时</td><td align="center">不建议使用默认值</td></tr><tr><td align="center">testOnBorrow</td><td>向资源池借用连接时是否做连接有效性检测(ping)，无效连接会被移除</td><td align="center">false</td><td align="center">建议false</td></tr><tr><td align="center">testOnReturn</td><td>向资源池归还连接时是否做连接有效性检测(ping)，无效连接会被移除</td><td align="center">false</td><td align="center">建议false</td></tr></tbody></table><br><h5 id="JedisPool-配置建议-适合的-maxTotal"><a href="#JedisPool-配置建议-适合的-maxTotal" class="headerlink" title="JedisPool 配置建议 - 适合的 maxTotal"></a>JedisPool 配置建议 - 适合的 maxTotal</h5><ul><li>比较难确定，举个例子</li></ul><blockquote><ol><li>命令平均执行时间011ms = 0.001s</li><li>业务需要50000 QPS</li><li>maxTotal理论值 = 0.001 * 50000 = 50 。实际值要偏大一些</li></ol></blockquote><blockquote><ol><li>业务希望Redis并发量</li><li>客户端执行命令时间</li><li>Redis资源:例如nodes(例如应用个数)*maxTotal 是不能超过redis的最大连接数。((config get maxclients)</li><li>资源开销:例如虽然希望控制空闲连接，但是不希望因为连接池的频繁释放创建连接造成不必靠开销</li></ol></blockquote><br><h5 id="JedisPool-配置建议-适合的maxIdle和minIdle"><a href="#JedisPool-配置建议-适合的maxIdle和minIdle" class="headerlink" title="JedisPool 配置建议 - 适合的maxIdle和minIdle"></a>JedisPool 配置建议 - 适合的maxIdle和minIdle</h5><ul><li>建议 maxIdle = maxTotal</li></ul><blockquote><p>减少创建新连接的开销</p></blockquote><ul><li>建议预热minIdle</li></ul><blockquote><p>减少第一次启动后的新连接开销</p></blockquote><br><h4 id="常见问题和解决思路"><a href="#常见问题和解决思路" class="headerlink" title="常见问题和解决思路"></a>常见问题和解决思路</h4><ul><li>常见问题</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.75d32k2l47g0.webp" width="60%" /><br><ul><li>解决思路</li></ul><ol><li>慢查询阻塞:池子连接都被hang住</li><li>资源池参数不合理:例如QPS高、池子小。</li><li>连接泄露(没有close0):此类问题比较难定位，例如client list、netstat等，最重要的是代码</li><li>DNS异常等</li></ol><br><ul><li>错误示例</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.31pwe9jqbig0.webp" width="60%" /><br><ul><li>推荐写法</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.69xc8p0s24o0.webp" width="60%" /><br><h2 id="Redis-的数据结构和内部编码"><a href="#Redis-的数据结构和内部编码" class="headerlink" title="Redis 的数据结构和内部编码"></a>Redis 的数据结构和内部编码</h2><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3scu9pvrtk80.webp" width="45%" /><br><ul><li>Redis Object</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.69a05a18h8s0.webp" width="75%"/><br><h2 id="Redis-的-IO-模型"><a href="#Redis-的-IO-模型" class="headerlink" title="Redis 的 IO 模型"></a>Redis 的 IO 模型</h2><ul><li>Redis 处理客户端请求所采用的处理架构，称为 Redis 的 IO 模型。不同版本的 Redis 采用的 IO 模型是不同的。</li></ul><br><h3 id="单线程模型"><a href="#单线程模型" class="headerlink" title="单线程模型"></a>单线程模型</h3><ul><li>对于 Redis 3.0 及其以前版本，Redis 的 IO 模型采用的是<font color=red>纯粹的单线程模型</font>。即所有客户端的请求全部由一个线程处理。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.72e1zah9knw0.webp" width="75%"><br><ul><li>Redis 的单线程模型采用了<font color=red>多路复用技术</font>。</li></ul><blockquote><p>对于多路复用器的<font color=red>多路选择算法</font>常见的有三种：select 模型、poll 模型、epoll 模型。</p><ul><li>poll 模型的选择算法：采用的是轮询算法。该模型对客户端的就绪处理是有延迟的。</li><li>epoll 模型的选择算法：采用的是回调方式。根据就绪事件发生后的处理方式的不同，又可分为 LT 模型与 ET 模型。</li></ul></blockquote><blockquote><p>每个客户端若要向 Redis 提交请求，都需要与 Redis 建立一个 socket 连接，并向事件分发器注册一个事件。一旦该事件发生就表明该连接已经就绪。而一旦连接就绪，事件分发器就会感知到，然后获取客户端通过该连接发送的请求，并将由该事件分发器所绑定的这个唯一的线程来处理。如果该线程还在处理多个任务，则将该任务写入到任务队列等待线程处理。</p><p>只所以称为事件分发器，是因为它会根据不同的就绪事件，将任务交由不同的事件处理器去处理。</p></blockquote><br><h3 id="混合线程模型"><a href="#混合线程模型" class="headerlink" title="混合线程模型"></a>混合线程模型</h3><ul><li>从 Redis 4.0 版本开始，Redis 中就开始加入了多线程元素。处理客户端请求的仍是单线程模型，但对于一些比较耗时但又不影响对客户端的响应的操作，就由后台其它线程来处理。例如，持久化、对 AOF 的 rewrite、对失效连接的清理等。</li></ul><br><h3 id="多线程模型"><a href="#多线程模型" class="headerlink" title="多线程模型"></a>多线程模型</h3><ul><li>Redis 6.0 版本，才是真正意义上的多线程模型。因为其对于客户端请求的处理采用的是多线程模型。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.8h232my5ero.webp" width="75%"><br><ul><li>多线程 IO 模型中的“多线程”仅用于接受、解析客户端的请求，然后将解析出的请求写入到任务队列。而对具体任务（命令）的处理，仍是由主线程处理。这样做使得用户无需考虑线程安全问题，无需考虑事务控制，无需考虑像 LPUSH/LPOP 等命令的执行顺序问题。</li></ul><br><h3 id="Redis-线程模型的优缺点总结"><a href="#Redis-线程模型的优缺点总结" class="headerlink" title="Redis 线程模型的优缺点总结"></a>Redis 线程模型的优缺点总结</h3><h4 id="单线程模型-1"><a href="#单线程模型-1" class="headerlink" title="单线程模型"></a>单线程模型</h4><ul><li><p>优点：可维护性高，性能高。不存在并发读写情况，所以也就不存在执行顺序的不确定性，不存在线程切换开销，不存在死锁问题，不存在为了数据安全而进行的加锁/解锁开销。</p></li><li><p>缺点：性能会受到影响，且由于单线程只能使用一个处理器，所以会形成处理器浪费。</p></li></ul><br><h4 id="多线程模型-1"><a href="#多线程模型-1" class="headerlink" title="多线程模型"></a>多线程模型</h4><ul><li>优点：其结合了多线程与单线程的优点，避开了它们的所有不足</li><li>缺点：该模型没有显示不足。如果非要找其不足的话就是，其并非是一个真正意义上的“多线程”，因为真正处理“任务”的线程仍是单线程。所以，其对性能也是有些影响的。</li></ul><br><h3 id="Redis-的单线程详解"><a href="#Redis-的单线程详解" class="headerlink" title="Redis 的单线程详解"></a>Redis 的单线程详解</h3><h4 id="单线程为什么这么快"><a href="#单线程为什么这么快" class="headerlink" title="单线程为什么这么快"></a>单线程为什么这么快</h4><ul><li>纯内存（主要原因）</li><li>非阻塞IO（epoll，io多路复用）</li><li>避免线程切换和竞态消耗</li></ul><br><h4 id="Redis-单线程使用注意事项"><a href="#Redis-单线程使用注意事项" class="headerlink" title="Redis 单线程使用注意事项"></a>Redis 单线程使用注意事项</h4><ol><li>一次只运行一条命令</li><li>拒绝长（慢）命命令：<code>keys</code> <code>flushall</code> <code>flushdb</code> <code>slow lua script</code> <code>mutil/exec</code> <code>operate big value(collection)</code></li><li>Redis 其实不是单线程：<code>fysnc file descriptor</code> <code>close file descriptor</code></li></ol><br><h2 id="Redis其他功能"><a href="#Redis其他功能" class="headerlink" title="Redis其他功能"></a>Redis其他功能</h2><h3 id="slowlog（慢查询）"><a href="#slowlog（慢查询）" class="headerlink" title="slowlog（慢查询）"></a>slowlog（慢查询）</h3><ul><li>慢查询可以帮助我们找到系统的一个瓶颈的命令</li></ul><br><h4 id="命令生命周期"><a href="#命令生命周期" class="headerlink" title="命令生命周期"></a>命令生命周期</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.62sxaflbj9s.webp" width="50%" /><br><ul><li>说明<ul><li><strong>（1）慢查询发生在第3阶段</strong></li><li><strong>（2）客户端超时不一定是慢查询，但慢查询是客户端超时的一个可能因素</strong></li></ul></li></ul><br><h4 id="慢查询的两个配置"><a href="#慢查询的两个配置" class="headerlink" title="慢查询的两个配置"></a>慢查询的两个配置</h4><h5 id="slowlog-max-len"><a href="#slowlog-max-len" class="headerlink" title="slowlog-max-len"></a>slowlog-max-len</h5><ol><li><p><code>slowlog-max-len</code> 表示慢查询队列长度</p></li><li><p>慢查询是一个先进先出的队列；如果在第3步执行过程中，被列入慢查询的范围内，就会进入一个队列（用redis的列表实现的）</p></li><li><p>慢查询队列是固定长度的</p></li><li><p>慢查询队列数据保存在内存中（重启会消失）</p></li></ol><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.44yrctjcttc0.webp" width="60%" /><br><h5 id="slowlog-log-slower-than"><a href="#slowlog-log-slower-than" class="headerlink" title="slowlog-log-slower-than"></a>slowlog-log-slower-than</h5><ol><li><p><code>slowlog-log-slower-than</code> 表示慢查询命令执行时间阈值（单位：微秒，1ms=1000微秒），超过阈值会被加入慢查询队列中</p></li><li><p><code>slowlog-log-slower-than = 0</code> ，记录所有命令</p></li><li><p><code>slowlog-log-slower-than &lt; 0</code> ，不记录任何命令</p><br></li></ol><ul><li>默认值</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6380&gt; config get slowlog-max-len</span><br><span class="line">1) &quot;slowlog-max-len&quot;</span><br><span class="line">2) &quot;128&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">10000微秒 =》 10ms</span></span><br><span class="line">127.0.0.1:6380&gt; config get slowlog-log-slower-than</span><br><span class="line">1) &quot;slowlog-log-slower-than&quot;</span><br><span class="line">2) &quot;10000&quot;</span><br></pre></td></tr></table></figure><br><h5 id="配置方法"><a href="#配置方法" class="headerlink" title="配置方法"></a>配置方法</h5><ol><li><p>方法一：修改配置文件重启（一般在第一次启动redis前进行配置。但如果redis正在运行中，不推荐此方式）</p></li><li><p>方法二：动态配置</p></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">config set slowlog-max-len 1000</span><br><span class="line">config set slowlog-log-slower-than 1000</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 以上的改动仅仅是在缓存中，如果我们想将其改到配置文件中，需要使用以下命令</span></span></span><br><span class="line">config rewrite</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">操作示例</span></span><br><span class="line">127.0.0.1:6380&gt; config set slowlog-max-len 1000</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6380&gt; config set slowlog-log-slower-than 1000</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6380&gt; config get slowlog-max-len</span><br><span class="line">1) &quot;slowlog-max-len&quot;</span><br><span class="line">2) &quot;1000&quot;</span><br><span class="line">127.0.0.1:6380&gt; config get slowlog-log-slower-than</span><br><span class="line">1) &quot;slowlog-log-slower-than&quot;</span><br><span class="line">2) &quot;1000&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 以上的改动仅仅是在缓存中，如果我们想将其改到配置文件中，需要使用以下命令</span></span></span><br><span class="line">127.0.0.1:6379&gt; config rewrite</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><br><h4 id="慢查询命令"><a href="#慢查询命令" class="headerlink" title="慢查询命令"></a>慢查询命令</h4><table><thead><tr><th align="center">慢查询命令</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">slowlog get [n]</td><td align="center">获取慢查询队列指定条数</td></tr><tr><td align="center">slowlog len</td><td align="center">获取慢查询队列长度</td></tr><tr><td align="center">slowlog reset</td><td align="center">清空慢查询队列</td></tr></tbody></table><br><h4 id="运维经验"><a href="#运维经验" class="headerlink" title="运维经验"></a>运维经验</h4><ol><li>slowlog-max-len 不要设置过小，通常设置1000左右 </li><li>slowlog-log-slower-than 不要设置过大。默认10ms，通常设置1ms（实际情况要根据QPS来决定阈值大小，有可能1ms就已经对我们的QPS产生影响了）</li><li>理解命令生命周期，理解慢查询处于命令生命周期的位置。便于我们排错和优化（慢查询、阻塞、网络都可能成为客户端超时的原因）</li><li><strong>定期持久化慢查询（因为慢查询是存在内存中的，且当慢查询数量逐步增多，早前的慢查询就会丢掉。做好持久化，可以分析历史的慢查询问题）。可以通过其它手段或开源软件实现这个功能</strong></li></ol><br><h3 id="pipeline（流水线）"><a href="#pipeline（流水线）" class="headerlink" title="pipeline（流水线）"></a>pipeline（流水线）</h3><ul><li>提高客户端的效率</li></ul><h4 id="网络命令通信模型"><a href="#网络命令通信模型" class="headerlink" title="网络命令通信模型"></a>网络命令通信模型</h4><h5 id="1次网络命令通信模型"><a href="#1次网络命令通信模型" class="headerlink" title="1次网络命令通信模型"></a>1次网络命令通信模型</h5><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.10peiok08sk0.webp" width="40%" /><br><h5 id="批量网络命令通信模型"><a href="#批量网络命令通信模型" class="headerlink" title="批量网络命令通信模型"></a>批量网络命令通信模型</h5><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.yo8sxod81o0.webp" width="40%" /><br><h4 id="什么是pipeline（流水线）"><a href="#什么是pipeline（流水线）" class="headerlink" title="什么是pipeline（流水线）"></a>什么是pipeline（流水线）</h4><ul><li>我们知道redis的命令执行是很快的，但是网络时间却不一定。使用pipeline可以帮我们节约大量网络时间</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.v0w62a1vlc0.webp" width="40%" /><br><h4 id="pipeline的作用"><a href="#pipeline的作用" class="headerlink" title="pipeline的作用"></a>pipeline的作用</h4><table><thead><tr><th align="center">命令</th><th align="center">N个命令操作</th><th align="center">1次pipeline（N个命令）</th></tr></thead><tbody><tr><td align="center">时间</td><td align="center">n次网络+n次命令</td><td align="center">1次网络时间+n次命令</td></tr><tr><td align="center">数量</td><td align="center">1条命令</td><td align="center">n条命令</td></tr></tbody></table><ul><li>注意</li></ul><ol><li>Redis的命令时间是微秒级别</li><li>pipeline每次条数要控制（网络）</li></ol><ul><li>举例</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2sv2n6wunz20.webp" width="60%" /><br><h3 id="pipeline的jedis实现"><a href="#pipeline的jedis实现" class="headerlink" title="pipeline的jedis实现"></a>pipeline的jedis实现</h3><ul><li>添加maven依赖</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>没有pipe-line</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2cxbniglxcys.webp" width="70%" /><br><ul><li>使用pipeline</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.41hpky36m4a0.webp" width="60%" /><br><h3 id="pipeline与mget-mset操作的对比"><a href="#pipeline与mget-mset操作的对比" class="headerlink" title="pipeline与mget/mset操作的对比"></a>pipeline与mget/mset操作的对比</h3><ul><li>原生M操作</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.6m3lpwqzxqs0.webp" width="60%" /><br><ul><li>pipeline</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.7b0lz2zro400.webp" width="60%" /><br><p><strong>pipeline命令可拆分</strong></p><br><h3 id="pipeline使用建议"><a href="#pipeline使用建议" class="headerlink" title="pipeline使用建议"></a>pipeline使用建议</h3><ul><li><strong>注意每次pipeline携带数量</strong></li><li><strong>pipeline每次只能作用在一个Redis节点上</strong></li><li><strong>注意pipeline与M操作的区别</strong></li></ul><h2 id="发布订阅"><a href="#发布订阅" class="headerlink" title="发布订阅"></a>发布订阅</h2><ul><li>实现发布订阅功能</li></ul><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><ul><li>发布者（publisher）</li><li>订阅者（subscriber）</li><li>频道（channel）</li></ul><br><h3 id="发布订阅模型"><a href="#发布订阅模型" class="headerlink" title="发布订阅模型"></a>发布订阅模型</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5u5skel4tjk0.webp" width="60%" /><br><ul><li><strong>新的订阅者订阅了一个频道，是无法收到之前的消息</strong>（因为无法做消息堆积，因为redis不是一个真正的消息队列这样一个工具）</li></ul><br><h3 id="发布订阅API"><a href="#发布订阅API" class="headerlink" title="发布订阅API"></a>发布订阅API</h3><h4 id="publish"><a href="#publish" class="headerlink" title="publish"></a>publish</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">向频道发布消息</span></span><br><span class="line">PUBLISH [channel_name] [message]</span><br><span class="line"></span><br><span class="line">127.0.0.1:6380&gt; publish sohu:tv &quot;hello world&quot;</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6380&gt; publish sohu:auto &quot;taxi&quot;</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><br><h4 id="subscribe"><a href="#subscribe" class="headerlink" title="subscribe"></a>subscribe</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">订阅一个或多个频道</span></span><br><span class="line">SUBSCRIBE [channel_name]...</span><br><span class="line"></span><br><span class="line">127.0.0.1:6380&gt; subscribe sohu:tv</span><br><span class="line">Reading messages... (press Ctrl-C to quit)</span><br><span class="line">1) &quot;subscribe&quot;</span><br><span class="line">2) &quot;sohu:tv&quot;</span><br><span class="line">3) (integer) 1</span><br></pre></td></tr></table></figure><br><h4 id="unsubscribe"><a href="#unsubscribe" class="headerlink" title="unsubscribe"></a>unsubscribe</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">订阅一个或多个频道</span></span><br><span class="line">UNSUBSCRIBE [channel_name]...</span><br><span class="line"></span><br><span class="line">127.0.0.1:6380&gt; UNSUBSCRIBE sohu:tv</span><br><span class="line">1) &quot;unsubscribe&quot;</span><br><span class="line">2) &quot;sohu:tv&quot;</span><br><span class="line">3) (integer) 0</span><br></pre></td></tr></table></figure><br><h4 id="其它API"><a href="#其它API" class="headerlink" title="其它API"></a>其它API</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.j7q4w7w0f5c.webp"  width="65%"/><br><h4 id="发布订阅与消息队列"><a href="#发布订阅与消息队列" class="headerlink" title="发布订阅与消息队列"></a>发布订阅与消息队列</h4><ul><li>Redis可以实现消息队列，消息队列是抢的模式</li><li>注意二者的区别与使用场景</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.33zfet508q00.webp" width="65%" /><br><h2 id="BItmap（位图）"><a href="#BItmap（位图）" class="headerlink" title="BItmap（位图）"></a>BItmap（位图）</h2><h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><ul><li>Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的（基于HyperLogLog算法：极小空间完成独立数量统计）</li><li>本质还是字符串</li></ul><br><h3 id="API（命令）"><a href="#API（命令）" class="headerlink" title="API（命令）"></a>API（命令）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Pfadd 命令将所有元素参数添加到 HyperLogLog 数据结构中</span></span><br><span class="line">redis 127.0.0.1:6379&gt; PFADD key element [element ...]</span><br><span class="line"></span><br><span class="line">redis 127.0.0.1:6379&gt; PFADD mykey a b c d e f g h i j</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379&gt; PFCOUNT mykey</span><br><span class="line">(integer) 10</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Pfcount 命令返回给定 HyperLogLog 的基数估算值</span></span><br><span class="line">redis 127.0.0.1:6379&gt; PFCOUNT key [key ...]</span><br><span class="line"></span><br><span class="line">redis 127.0.0.1:6379&gt; PFADD hll foo bar zap</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379&gt; PFADD hll zap zap zap</span><br><span class="line">(integer) 0</span><br><span class="line">redis 127.0.0.1:6379&gt; PFADD hll foo bar</span><br><span class="line">(integer) 0</span><br><span class="line">redis 127.0.0.1:6379&gt; PFCOUNT hll</span><br><span class="line">(integer) 3</span><br><span class="line">redis 127.0.0.1:6379&gt; PFADD some-other-hll 1 2 3</span><br><span class="line">(integer) 1</span><br><span class="line">redis 127.0.0.1:6379&gt; PFCOUNT hll some-other-hll</span><br><span class="line">(integer) 6</span><br><span class="line"><span class="meta prompt_">redis&gt; </span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> PFMERGE 命令将多个 HyperLogLog 合并为一个 HyperLogLog ，合并后的 HyperLogLog 的基数估算值是通过对所有 给定 HyperLogLog 进行并集计算得出的</span></span><br><span class="line">PFMERGE destkey sourcekey [sourcekey ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">redis&gt; </span><span class="language-bash">PFADD hll1 foo bar zap a</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_">redis&gt; </span><span class="language-bash">PFADD hll2 a b c foo</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_">redis&gt; </span><span class="language-bash">PFMERGE hll3 hll1 hll2</span></span><br><span class="line">&quot;OK&quot;</span><br><span class="line"><span class="meta prompt_">redis&gt; </span><span class="language-bash">PFCOUNT hll3</span></span><br><span class="line">(integer) 6</span><br><span class="line"><span class="meta prompt_">redis&gt; </span><span class="language-bash"> </span></span><br></pre></td></tr></table></figure><br><h3 id="示例（百万独立用户-内存消耗）"><a href="#示例（百万独立用户-内存消耗）" class="headerlink" title="示例（百万独立用户-内存消耗）"></a>示例（百万独立用户-内存消耗）</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.540yx2nmmgw0.webp" width="60%" /><br><h3 id="使用经验"><a href="#使用经验" class="headerlink" title="使用经验"></a>使用经验</h3><ul><li>是否能容忍错误？（错误率：0.81%）</li><li>是否需要单条数据？</li></ul><br><h1 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h1><ul><li>Redis GEO 主要用于存储地理位置信息，并对存储的信息进行操作（存储经纬度，计算两地距离，范围计算等）</li><li>底层使用 zset 实现</li></ul><br><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>类似微信摇一摇（计算指定范围类的用户）</li><li>根据距离计算周围的酒店餐馆等</li></ul><br><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><ul><li>geoadd：添加地理位置的坐标。</li><li>geopos：获取地理位置的坐标。</li><li>geodist：计算两个位置之间的距离。</li><li>georadius：根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。</li><li>georadiusbymember：根据储存在位置集合里面的某个地点获取指定范围内的地理位置集合。</li><li>geohash：返回一个或多个位置对象的 geohash 值。</li></ul><br><br><h1 id="Redis-配置文件详解"><a href="#Redis-配置文件详解" class="headerlink" title="* Redis 配置文件详解"></a>* Redis 配置文件详解</h1><br><br><br><h1 id="Redis-的持久化"><a href="#Redis-的持久化" class="headerlink" title="Redis 的持久化"></a>Redis 的持久化</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul><li>Redis 是一个内存数据库，所以其运行效率非常高。但也存在一个问题：内存中的数据是不持久的，若主机宕机或 Redis 关机重启，则内存中的数据全部丢失。当然，这是不允许的。Redis 具有持久化功能，其会按照设置以快照或操作日志的形式将数据持久化到磁盘。</li><li>根据持久化使用技术的不同，Redis 的持久化分为两种：RDB 与 AOF。</li></ul><br><h2 id="持久化基本原理"><a href="#持久化基本原理" class="headerlink" title="持久化基本原理"></a>持久化基本原理</h2><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/1669979940444.ex1epa9vjog.webp" width="70%"><br><ul><li><p>Redis 持久化也称为钝化，是指将内存中数据库的状态描述信息保存到磁盘中。只不过是不同的持久化技术，对数据的状态描述信息是不同的，生成的持久化文件也是不同的。但它们的作用都是相同的：避免数据意外丢失。</p></li><li><p>通过手动方式，或自动定时方式，或自动条件触发方式，将内存中数据库的状态描述信息写入到指定的持久化文件中。当系统重新启动时，自动加载持久化文件，并根据文件中数据库状态描述信息将数据恢复到内存中，这个数据恢复过程也称为激活。这个钝化与激活的过程就是 Redis 持久化的基本原理。</p></li><li><p>对于 Redis 单机状态下，无论是手动方式，还是定时方式或条件触发方式，都存在数据丢失问题：在尚未手动/自动保存时发生了 Redis 宕机状况，那么从上次保存到宕机期间产生的数据就会丢失。不同的持久化方式，其数据的丢失率也是不同的。</p></li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/1669980154363.74thoe883o80.webp" width="70%"><br><ul><li>RDB 是默认持久化方式，但 Redis 允许 RDB 与 AOF 两种持久化技术同时开启，此时系统会使用 AOF 方式做持久化，即 AOF 持久化技术的优先级要更高。同样的道理，两种技术同时开启状态下，系统启动时若两种持久化文件同时存在，则优先加载 AOF持久化文件。</li></ul><br><h2 id="RDB-持久化"><a href="#RDB-持久化" class="headerlink" title="RDB 持久化"></a>RDB 持久化</h2><ul><li><p><strong>RDB，Redis DataBase，是指将内存中某一时刻的数据快照全量写入到指定的 rdb 文件的持久化技术。</strong></p></li><li><p>RDB 持久化默认是开启的。当 Redis 启动时会自动读取 RDB 快照文件，将数据从硬盘载入到内存，以恢复 Redis 关机前的数据库状态。</p></li></ul><br><h3 id="持久化的执行"><a href="#持久化的执行" class="headerlink" title="持久化的执行"></a>持久化的执行</h3><ul><li><strong>RDB 持久化的执行有三种方式：手动 save 命令、手动 bgsave 命令，与自动条件触发。</strong></li></ul><br><h4 id="手动-save-命令"><a href="#手动-save-命令" class="headerlink" title="手动 save 命令"></a>手动 save 命令</h4><ul><li>通过在 redis-cli 客户端中执行 save 命令可立即进行一次持久化保存。save 命令在执行期间会阻塞 redis-server 进程，直至持久化过程完毕。而在 redis-server 进程阻塞期间，Redis不能处理任何读写请求，无法对外提供服务。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379[2]&gt; save</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><br><h4 id="手动-bgsave-命令"><a href="#手动-bgsave-命令" class="headerlink" title="手动 bgsave 命令"></a>手动 bgsave 命令</h4><ul><li>通过在 redis-cli 客户端中执行 bgsave 命令可立即进行一次持久化保存。不同于 save 命令的是，正如该命令的名称一样，background save，后台运行 save。bgsave 命令会使服务器进程 redis-server 生成一个子进程，由该子进程负责完成保存过程。在子进程进行保存过程中，不会阻塞 redis-server 进程对客户端读写请求的处理。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bgsave</span><br><span class="line">Background saving started</span><br></pre></td></tr></table></figure><br><h4 id="自动条件触发"><a href="#自动条件触发" class="headerlink" title="自动条件触发"></a>自动条件触发</h4><ul><li>自动条件触发的本质仍是 bgsave 命令的执行。只不过是用户通过在配置文件中做相应的设置后，Redis 会根据设置信息自动调用 bgsave 命令执行</li></ul><br><h4 id="查看持久化时间"><a href="#查看持久化时间" class="headerlink" title="查看持久化时间"></a>查看持久化时间</h4><ul><li>通过 lastsave 命令可以查看最近一次执行持久化的时间，其返回的是一个 Unix 时间戳。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lastsave</span><br><span class="line">(<span class="built_in">integer</span>) 1668522087</span><br></pre></td></tr></table></figure><br><h3 id="RDB-优化配置"><a href="#RDB-优化配置" class="headerlink" title="RDB 优化配置"></a>RDB 优化配置</h3><ul><li>RDB 相关的配置在 redis.conf 文件的 SNAPSHOTTING 部分。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5ip89bu9rsk0.webp" width="60%"><br><h4 id="save"><a href="#save" class="headerlink" title="save"></a>save</h4><ul><li>该配置用于设置快照的自动保存触发条件，即 save point，保存点。该触发条件是在指定时间段内发生了指定次数的写操作。除非另有规定，默认情况下持久化条件为 save 3600 1300 100 60 10000。其等价于以下三条<ul><li>save 3600 1 # 在 3600 秒(1 小时)内发生 1 次写操作</li><li>save 300 100 # 在 300 秒(5 分钟)内发生 100 次写操作</li><li>save 60 10000 # 在 60 秒(1 分钟)内发生 1 万次写操作</li></ul></li><li>如果不启用 RDB 持久化，只需设置 save 的参数为空串即可：save “”。</li></ul><br><h4 id="stop-write-on-bgsave-error"><a href="#stop-write-on-bgsave-error" class="headerlink" title="stop-write-on-bgsave-error"></a>stop-write-on-bgsave-error</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-writes-on-bgsave-error yes</span><br></pre></td></tr></table></figure><ul><li>默认情况下，如果 RDB 快照已启用（至少一个保存点），且最近的 bgsave 命令失败，Redis将停止接受写入。这样设置是为了让用户意识到数据没有正确地保存到磁盘上，否则很可能没有人会注意到，并会发生一些灾难。当然，如果 bgsave 命令后来可以正常工作了，Redis将自动允许再次写入</li></ul><br><h4 id="rdbcompression"><a href="#rdbcompression" class="headerlink" title="rdbcompression"></a>rdbcompression</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdbcompression yes</span><br></pre></td></tr></table></figure><ul><li>当进行持久化时启用 LZF 压缩字符串对象。虽然压缩 RDB 文件会消耗系统资源，降低性能，但可大幅降低文件的大小，方便保存到磁盘，加速主从集群中从节点的数据同步。</li></ul><br><h4 id="rdbchecksum"><a href="#rdbchecksum" class="headerlink" title="rdbchecksum"></a>rdbchecksum</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdbchecksum yes</span><br></pre></td></tr></table></figure><ul><li>从 RDB5 开始，RDB 文件的 CRC64 校验和就被放置在了文件末尾。这使格式更能抵抗 RDB文件的损坏，但在保存和加载 RDB 文件时，性能会受到影响（约 10%），因此可以设置为 no禁用校验和以获得最大性能。在禁用校验和的情况下创建的 RDB 文件的校验和为零，这将告诉加载代码跳过校验检查。默认为 yes，开启了校验功能</li></ul><br><h4 id="sanitize-dump-payload"><a href="#sanitize-dump-payload" class="headerlink" title="sanitize-dump-payload"></a>sanitize-dump-payload</h4><ul><li>该配置用于设置在加载 RDB 文件或进行持久化时是否开启对 zipList、listPack 等数据的全面安全检测。该检测可以降低命令处理时发生系统崩溃的可能。其可设置的值有三种选择：<ul><li>no：不检测</li><li>yes：总是检测</li><li>clients：只有当客户端连接时检测。排除了加载 RDB 文件与进行持久化时的检测</li></ul></li><li><strong>默认值本应该是 clients，但其会影响 Redis 集群的工作，所以默认值为 no，不检测</strong></li></ul><br><h4 id="dbfilename"><a href="#dbfilename" class="headerlink" title="dbfilename"></a>dbfilename</h4><ul><li>指定 RDB 文件的默认名称，默认为 dump.rdb</li></ul><br><h4 id="rdb-del-sync-files"><a href="#rdb-del-sync-files" class="headerlink" title="rdb-del-sync-files"></a>rdb-del-sync-files</h4><ul><li>主从复制时，是否删除用于同步的从机上的 RDB 文件。默认是 no，不删除。不过需要。<strong>注意，只有当从机的 RDB 和 AOF 持久化功能都未开启时才生效。</strong></li></ul><br><h4 id="dir"><a href="#dir" class="headerlink" title="dir"></a>dir</h4><ul><li>指定 RDB 与 AOF 文件的生成目录。默认为 Redis 安装根目录</li></ul><br><h3 id="RDB-文件结构"><a href="#RDB-文件结构" class="headerlink" title="RDB 文件结构"></a>RDB 文件结构</h3><ul><li>RDB 持久化文件 dump.rdb 整体上有五部分构成：</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.11ghbcn60heo.webp" width="70%"><br><h4 id="SOF"><a href="#SOF" class="headerlink" title="SOF"></a>SOF</h4><ul><li>SOF 是一个常量，一个字符串 REDIS，仅包含这五个字符，其长度为 5。用于标识 RDB文件的开始，以便在加载 RDB 文件时可以迅速判断出文件是否是 RDB 文件。</li></ul><br><h4 id="rdb-version"><a href="#rdb-version" class="headerlink" title="rdb_version"></a>rdb_version</h4><ul><li>一个整数，长度为 4 字节，表示 RDB 文件的版本号</li></ul><br><h4 id="EOF"><a href="#EOF" class="headerlink" title="EOF"></a>EOF</h4><ul><li>EOF 是一个常量，占 1 个字节，用于标识 RDB 数据的结束，校验和的开始</li></ul><br><h4 id="check-sum"><a href="#check-sum" class="headerlink" title="check_sum"></a>check_sum</h4><ul><li>校验和 check_sum 用于判断 RDB 文件中的内容是否出现数据异常。其采用的是 CRC 校验算法。</li><li>CRC 校验算法：</li></ul><blockquote><ul><li><p>在持久化时，先将 SOF、rdb_version 及内存数据库中的数据快照这三者的二进制数据拼接起来，形成一个二进制数（假设称为数 a），然后再使用这个 a 除以校验和 check_sum，此时可获取到一个余数 b，然后再将这个 b 拼接到 a 的后面，形成 databases。</p></li><li><p>在加载时，需要先使用 check_sum 对 RDB 文件进行数据损坏验证。验证过程：只需将RDB 文件中除 EOF 与 check_sum 外的数据除以 check_sum。只要除得的余数不是 0，就说明文件发生损坏。当然，如果余数是 0，也不能肯定文件没有损坏。</p></li><li><p>这种验证算法，是数据损坏校验，而不是数据没有损坏的校验。</p></li></ul></blockquote><br><h4 id="databases"><a href="#databases" class="headerlink" title="databases"></a>databases</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.65mcvofo1ik0.webp" width="80%"><br><ul><li>databases 部分是 RDB 文件中最重要的数据部分，其可以包含任意多个非空数据库。而每个 database 又是由三部分构成：<ul><li>SODB：是一个常量，占 1 个字节，用于标识一个数据库的开始。</li><li>db_number：数据库编号。</li><li>key_value_pairs：当前数据库中的键值对数据。（每个 key_value_pairs 又由很多个用于描述键值对的数据构成。）<ul><li>VALUE_TYPE：是一个常量，占 1 个字节，用于标识该键值对中 value 的类型。</li><li>EXPIRETIME_UNIT：是一个常量，占 1 个字节，用于标识过期时间的单位是秒还是毫秒。</li><li>time：当前 key-value 的过期时间。</li></ul></li></ul></li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.fn8asgxhol4.webp" width="100%"><br><h3 id="RDB-持久化过程"><a href="#RDB-持久化过程" class="headerlink" title="RDB 持久化过程"></a>RDB 持久化过程</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2c0fq381m9xc.webp" width="70%"><br><ul><li><p>对于 Redis 默认的 RDB 持久化，在进行 bgsave 持久化时，redis-server 进程会 fork 出一个 bgsave 子进程，由该子进程以<font color=red>异步方式</font>负责完成持久化。而在持久化过程中，redis-server进程不会阻塞，其会继续接收并处理用户的读写请求。</p></li><li><p>bgsave 子进程的详细工作原理如下：</p></li></ul><blockquote><p>由于子进程可以继承父进程的所有资源，且父进程不能拒绝子进程的继承权。所以，bgsave 子进程有权读取到 redis-server 进程写入到内存中的用户数据，使得将内存数据持久化到 dump.rdb 成为可能。</p><p>bgsave 子进程在持久化时首先会将内存中的全量数据 copy 到磁盘中的一个 RDB 临时文件，copy 结束后，再将该文件 rename 为 dump.rdb，替换掉原来的同名文件。</p><p>不过，在进行持久化过程中，如果 redis-server 进程接收到了用户写请求，则系统会将内存中发生数据修改的物理块 copy 出一个副本。等内存中的全量数据 copy 结束后，会再将副本中的数据 copy 到 RDB 临时文件。这个副本的生成是由于 Linux 系统的写时复制技术（Copy-On-Write）实现的。</p></blockquote><img src="" width="60%"><br><blockquote><p><strong>写时复制技术是 Linux 系统的一种进程管理技术。</strong></p><p>原本在 Unix 系统中，当一个主进程通过 fork()系统调用创建子进程后，内核进程会复制主进程的整个内存空间中的数据，然后分配给子进程。这种方式存在的问题有以下几点：</p><ul><li>这个过程非常耗时</li><li>这个过程降低了系统性能</li><li>如果主进程修改了其内存数据，子进程副本中的数据是没有修改的。即出现了数据冗余，而冗余数据最大的问题是数据一致性无法保证。而写时复制则是在任何一方需要写入数据到共享内存时都会出现异常，此时内核进程就会将需要写入的数据 copy 出一个副本写入到另外一块非共享内存区域</li></ul></blockquote><br><h2 id="AOF-持久化"><a href="#AOF-持久化" class="headerlink" title="AOF 持久化"></a>AOF 持久化</h2><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><ul><li>AOF，Append Only File，是指 Redis 将每一次的写操作都以日志的形式记录到一个 AOF文件中的持久化技术。当需要恢复内存数据时，将这些写操作重新执行一次，便会恢复到之前的内存数据状态。</li></ul><br><h3 id="AOF-基础配置"><a href="#AOF-基础配置" class="headerlink" title="AOF 基础配置"></a>AOF 基础配置</h3><h4 id="AOF-的开启"><a href="#AOF-的开启" class="headerlink" title="AOF 的开启"></a>AOF 的开启</h4><ul><li>默认情况下 AOF 持久化是没有开启的，通过修改配置文件中的 appendonly 属性为 yes 可以开启。</li></ul><br><h4 id="文件名配置"><a href="#文件名配置" class="headerlink" title="文件名配置"></a>文件名配置</h4><ul><li>Redis 7 在这里发生了重大变化。原来只有一个 appendonly.aof 文件，现在具有了三类多个文件：<ul><li>基本文件：可以是 RDF 格式也可以是 AOF 格式。其存放的内容是由 RDB 转为 AOF 当时内存的快照数据。该文件可以有多个。</li><li>增量文件：以操作日志形式记录转为 AOF 后的写入操作。该文件可以有多个。</li><li>清单文件：用于维护 AOF 文件的创建顺序，保障激活时的应用顺序。该文件只有一个。</li></ul></li></ul><br><h4 id="混合式持久化开启"><a href="#混合式持久化开启" class="headerlink" title="混合式持久化开启"></a>混合式持久化开启</h4><ul><li>对于基本文件可以是 RDF 格式也可以是 AOF 格式。通过 aof-use-rdb-preamble 属性可以选择。其默认值为 yes，即默认 AOF 持久化的基本文件为 rdb 格式文件，也就是默认采用混合式持久化。</li></ul><br><h4 id="AOF-文件目录配置"><a href="#AOF-文件目录配置" class="headerlink" title="AOF 文件目录配置"></a>AOF 文件目录配置</h4><ul><li>为了方便管理，可以专门为 AOF 持久化文件指定存放目录。目录名由 appenddirname属性指定，存放在 redis.conf 配置文件的 dir 属性指定的目录，默认为 Redis 安装目录。</li></ul><br><h3 id="AOF-文件格式"><a href="#AOF-文件格式" class="headerlink" title="AOF 文件格式"></a>AOF 文件格式</h3><ul><li>AOF 文件包含三类文件：基本文件、增量文件与清单文件。其中基本文件一般为 rdb 格式，在前面已经研究过了。</li></ul><br><h4 id="Redis-协议"><a href="#Redis-协议" class="headerlink" title="Redis 协议"></a>Redis 协议</h4><ul><li>增量文件扩展名为.aof，采用 AOF 格式。AOF 格式其实就是 Redis 通讯协议格式，AOF持久化文件的本质就是基于 Redis 通讯协议的文本，将命令以纯文本的方式写入到文件中。</li><li>Redis 协议规定，Redis 文本是以行来划分，每行以\r\n 行结束。每一行都有一个消息头，以表示消息类型。消息头由六种不同的符号表示，其意义如下：<ul><li>(+) 表示一个正确的状态信息</li><li>(-) 表示一个错误信息</li><li>(*) 表示消息体总共有多少行，不包括当前行</li><li>($) 表示下一行消息数据的长度，不包括换行符长度\r\n</li><li>(空) 表示一个消息数据</li><li>(:) 表示返回一个数值</li></ul></li></ul><br><h4 id="查看-AOF-文件"><a href="#查看-AOF-文件" class="headerlink" title="查看 AOF 文件"></a>查看 AOF 文件</h4><p>打开 appendonly.aof.1.incr.aof 文件，可以看到如下格式内容。</p><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5w0csfakr4k0.webp" width="40%"><br><ul><li>以上内容中框起来的是三条命令。一条数据库切换命令 SELECT 0，两条 set 命令。它们的意义如下：</li></ul><blockquote><p>*2 – 表示当前命令包含 2 个参数<br>$6 – 表示第 1 个参数包含 6 个字符<br>SELECT – 第 1 个参数<br>$1 – 表示第 2 个参数包含 1 个字符<br>0 – 第 2 个参数<br>*3 –表示当前命令包含 3 个参数<br>$3 – 表示第 1 个参数包含 3 个字符<br>set – 第 1 个参数<br>$3 – 表示第 2 个参数包含 3 个字符<br>k11 – 第 2 个参数<br>$3 – 表示第 3 个参数包含 2 个字符<br>v11 – 第 3 个参数<br>*3</p></blockquote><br><h4 id="清单文件"><a href="#清单文件" class="headerlink" title="清单文件"></a>清单文件</h4><ul><li>打开清单文件 appendonly.aof.manifest，查看其内容如下：</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2uuk3oh389k0.webp" width="60%"><br><ul><li><p>该文件首先会按照 seq 序号列举出所有基本文件，基本文件 type 类型为 b，然后再按照seq 序号再列举出所有增量文件，增量文件 type 类型为 i。</p></li><li><p>对于 Redis 启动时的数据恢复，也会按照该文件由上到下依次加载它们中的数据。</p></li></ul><br><h3 id="Rewrite-机制"><a href="#Rewrite-机制" class="headerlink" title="Rewrite 机制"></a>Rewrite 机制</h3><ul><li>随着使用时间的推移，AOF 文件会越来越大。为了防止 AOF 文件由于太大而占用大量的磁盘空间，降低性能，Redis 引入了 Rewrite 机制来对 AOF 文件进行压缩。</li></ul><br><h4 id="何为-rewrite"><a href="#何为-rewrite" class="headerlink" title="何为 rewrite"></a>何为 rewrite</h4><ul><li>所谓 Rewrite 其实就是对 AOF 文件进行重写整理。当 Rewrite 开启后，主进程 redis-server创建出一个子进程 bgrewriteaof，由该子进程完成 rewrite 过程。其首先对现有 aof 文件进行rewrite 计算，将计算结果写入到一个临时文件，写入完毕后，再 rename 该临时文件为原 aof文件名，覆盖原有文件。</li></ul><br><h4 id="rewrite-计算"><a href="#rewrite-计算" class="headerlink" title="rewrite 计算"></a>rewrite 计算</h4><ul><li>rewrite 计算也称为 rewrite 策略。rewrite 计算遵循以下策略：<ul><li>读操作命令不写入文件</li><li>无效命令不写入文件</li><li>过期数据不写入文件</li><li>多条命令合并写入文件</li></ul></li></ul><br><h4 id="手动开启-rewrite"><a href="#手动开启-rewrite" class="headerlink" title="手动开启 rewrite"></a>手动开启 rewrite</h4><ul><li>Rewrite 过程的执行有两种方式。一种是通过 bgrewriteaof 命令手动开启，一种是通过设置条件自动开启。</li></ul><p>以下是手动开启方式：</p><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5hbstfr9bgw0.webp" width="70%"><br><ul><li>该命令会使主进程 redis-server 创建出一个子进程 bgrewriteaof，由该子进程完成 rewrite过程。而在 rewrite 期间，redis-server 仍是可以对外提供读写服务的。</li></ul><br><h4 id="自动开启-rewrite"><a href="#自动开启-rewrite" class="headerlink" title="自动开启 rewrite"></a>自动开启 rewrite</h4><ul><li>手动方式需要人办干预，所以一般采用自动方式。由于 Rewrite 过程是一个计算过程，需要消耗大量系统资源，会降低系统性能。所以，Rewrite 过程并不是随时随地任意开启的，而是通过设置一些条件，当满足条件后才会启动，以降低对性能的影响。</li><li><strong>auto-aof-rewrite-percentage</strong>：开启 rewrite 的增大比例，默认 100%。指定为 0，表示禁用自动 rewrite。</li><li><strong>auto-aof-rewrite-min-size</strong>：开启 rewrite 的 AOF 文件最小值，默认 64M。该值的设置主要是为了防止小 AOF 文件被 rewrite，从而导致性能下降。</li></ul><blockquote><p>自动重写 AOF 文件。当 AOF 日志文件大小增长到指定的百分比时，Redis 主进程redis-server 会 fork 出一个子进程 bgrewriteaof 来完成 rewrite 过程。</p><p>其工作原理如下：Redis 会记住最新 rewrite 后的 AOF 文件大小作为基本大小，如果从主机启动后就没有发生过重写，则基本大小就使用启动时 AOF 的大小。</p><p>如果当前 AOF 文件大于基本大小的配置文件中指定的百分比阈值，且当前 AOF 文件大<br>于配置文件中指定的最小阈值，则会触发 rewrite。</p></blockquote><br><h2 id="AOF-优化配置"><a href="#AOF-优化配置" class="headerlink" title="AOF 优化配置"></a>AOF 优化配置</h2><h3 id="appendfsync"><a href="#appendfsync" class="headerlink" title="appendfsync"></a>appendfsync</h3><ul><li>当客户端提交写操作命令后，该命令就会写入到 aof_buf 中，而 aof_buf 中的数据持久化到磁盘 AOF 文件的过程称为数据同步。</li><li>何时将 aof_buf 中的数据同步到 AOF 文件？采用不同的数据同步策略，同时的时机是不同的，有三种策略：<ul><li>always：写操作命令写入 aof_buf 后会立即调用 fsync()系统函数，将其追加到 AOF 文件。该策略效率较低，但相对比较安全，不会丢失太多数据。最多就是刚刚执行过的写操作在尚未同步时出现宕机或重启，将这一操作丢失。</li><li>no：写操作命令写入 aof_buf 后什么也不做，不会调用 fsync()函数。而将 aof_buf 中的数据同步磁盘的操作由操作系统负责。Linux 系统默认同步周期为 30 秒。效率较高。</li><li>everysec：默认策略。写操作命令写入 aof_buf 后并不直接调用 fsync()，而是每秒调用一次 fsync()系统函数来完成同步。该策略兼顾到了性能与安全，是一种折中方案。</li></ul></li></ul><br><h3 id="no-appendfsync-on-rewrite"><a href="#no-appendfsync-on-rewrite" class="headerlink" title="no-appendfsync-on-rewrite"></a>no-appendfsync-on-rewrite</h3><ul><li>该属性用于指定，当 AOF fsync 策略设置为 always 或 everysec，当主进程创建了子进程正在执行 bgsave 或 bgrewriteaof 时，主进程是否不调用 fsync()来做数据同步。设置为 no，双重否定即肯定，主进程会调用 fsync()做同步。而 yes 则不会调用 fsync()做数据同步</li><li>如果调用 fsync()，在需要同步的数据量非常大时，会阻塞主进程对外提供服务，即会存在延迟问题。如果不调用 fsync()，则 AOF fsync 策略相当于设置为了 no，可能会存在 30 秒数据丢失的风险。</li></ul><br><h3 id="aof-rewrite-incremental-fsync"><a href="#aof-rewrite-incremental-fsync" class="headerlink" title="aof-rewrite-incremental-fsync"></a>aof-rewrite-incremental-fsync</h3><ul><li>当 bgrewriteaof 在执行过程也是先将 rewrite 计算的结果写入到了 aof_rewrite_buf 缓存中，然后当缓存中数据达到一定量后就会调用 fsync()进行刷盘操作，即数据同步，将数据写入到临时文件。该属性用于控制 fsync()每次刷盘的数据量最大不超过 4MB。这样可以避免由于单次刷盘量过大而引发长时间阻塞</li></ul><br><h3 id="aof-load-truncated"><a href="#aof-load-truncated" class="headerlink" title="aof-load-truncated"></a>aof-load-truncated</h3><ul><li>在进行 AOF 持久化过程中可能会出现系统突然宕机的情况，此时写入到 AOF 文件中的最后一条数据可能会不完整。当主机启动后，Redis 在 AOF 文件不完整的情况下是否可以启动，取决于属性 aof-load-truncated 的设置。其值为：<ul><li>yes：AOF 文件最后不完整的数据直接从 AOF 文件中截断删除，不影响 Redis 的启动。</li><li>no：AOF 文件最后不完整的数据不可以被截断删除，Redis 无法启动。</li></ul></li></ul><br><h3 id="aof-timestamp-enabeld"><a href="#aof-timestamp-enabeld" class="headerlink" title="aof-timestamp-enabeld"></a>aof-timestamp-enabeld</h3><ul><li>该属性设置为 yes 则会开启在 AOF 文件中增加时间戳的显示功能，可方便按照时间对数据进行恢复。但该方式可能会与 AOF 解析器不兼容，所以默认值为 no，不开启。</li></ul><br><h2 id="AOF-持久化过程"><a href="#AOF-持久化过程" class="headerlink" title="AOF 持久化过程"></a>AOF 持久化过程</h2><h3 id="AOF-详细的持久化过程如下："><a href="#AOF-详细的持久化过程如下：" class="headerlink" title="AOF 详细的持久化过程如下："></a>AOF 详细的持久化过程如下：</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.6cqgnli756w0.webp" width="90%"><br><ol><li><p>   Redis 接收到的写操作命令并不是直接追加到磁盘的 AOF 文件的，而是将每一条写命令按照 redis 通讯协议格式暂时添加到 AOF 缓冲区 aof_buf。</p></li><li><p>   根据设置的数据同步策略，当同步条件满足时，再将缓冲区中的数据一次性写入磁盘的AOF 文件，以减少磁盘 IO 次数，提高性能。</p></li><li><p>   当磁盘的 AOF 文件大小达到了 rewrite 条件时，redis-server 主进程会 fork 出一个子进程bgrewriteaof，由该子进程完成 rewrite 过程。</p></li><li><p>   子进程 bgrewriteaof 首先对该磁盘 AOF 文件进行 rewrite 计算，将计算结果写入到一个临时文件，全部写入完毕后，再 rename 该临时文件为磁盘文件的原名称，覆盖原文件。</p></li><li><p>   如果在 rewrite 过程中又有写操作命令追加，那么这些数据会暂时写入 aof_rewrite_buf缓冲区。等将全部 rewrite 计算结果写入临时文件后，会先将 aof_rewrite_buf 缓冲区中的数据写入临时文件，然后再 rename 为磁盘文件的原名称，覆盖原文件。</p></li></ol><br><h2 id="RDB-与-AOF-对比"><a href="#RDB-与-AOF-对比" class="headerlink" title="RDB 与 AOF 对比"></a>RDB 与 AOF 对比</h2><h3 id="RDB-优势与不足"><a href="#RDB-优势与不足" class="headerlink" title="RDB 优势与不足"></a>RDB 优势与不足</h3><h4 id="RDB-优势"><a href="#RDB-优势" class="headerlink" title="RDB 优势"></a>RDB 优势</h4><ul><li>RDB 文件较小</li><li>数据恢复较快</li></ul><br><h4 id="RDB-不足"><a href="#RDB-不足" class="headerlink" title="RDB 不足"></a>RDB 不足</h4><ul><li>数据安全性较差</li><li>写时复制会降低性能</li><li>RDB 文件可读性较差</li></ul><br><h3 id="AOF-优势与不足"><a href="#AOF-优势与不足" class="headerlink" title="AOF 优势与不足"></a>AOF 优势与不足</h3><h4 id="AOF-优势"><a href="#AOF-优势" class="headerlink" title="AOF 优势"></a>AOF 优势</h4><ul><li>数据安全性高</li><li>AOF 文件可读性强</li></ul><br><h4 id="AOF-不足"><a href="#AOF-不足" class="headerlink" title="AOF 不足"></a>AOF 不足</h4><ul><li>AOF 文件较大</li><li>写操作会影响性能</li><li>数据恢复较慢</li></ul><br><h2 id="持久化技术选型"><a href="#持久化技术选型" class="headerlink" title="持久化技术选型"></a>持久化技术选型</h2><ul><li>官方推荐使用 RDB 与 AOF 混合式持久化。</li><li>若对数据安全性要求不高，则推荐使用纯 RDB 持久化方式</li><li>不推荐使用纯 AOF 持久化方式。</li><li>若 Redis 仅用于缓存，则无需使用任何持久化技术。</li></ul><br><br><br><h1 id="第6章-Redis-主从集群"><a href="#第6章-Redis-主从集群" class="headerlink" title="第6章 Redis 主从集群"></a>第6章 Redis 主从集群</h1><h2 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h2><ul><li>为了避免 Redis 的单点故障问题，我们可以搭建一个 Redis 集群，将数据备份到集群中的其它节点上。若一个 Redis 节点宕机，则由集群中的其它节点顶上</li></ul><br><h2 id="主从集群搭建"><a href="#主从集群搭建" class="headerlink" title="主从集群搭建"></a>主从集群搭建</h2><ul><li>Redis 的主从集群是一个“一主多从”的读写分离集群。集群中的 Master 节点负责处理客户端的读写请求，而 Slave 节点仅能处理客户端的读请求。只所以要将集群搭建为读写分离模式，主要原因是，对于数据库集群，写操作压力一般都较小，压力大多数来自于读操作请求。所以，只有一个节点负责处理写操作请求即可。</li></ul><br><h2 id="伪集群搭建与配置"><a href="#伪集群搭建与配置" class="headerlink" title="伪集群搭建与配置"></a>伪集群搭建与配置</h2><ul><li>在采用单线程 IO 模型时，为了提高处理器的利用率，一般会在一个主机中安装多台 Redis，构建一个 Redis 主从伪集群。当然，搭建伪集群的另一个场景是，在学习 Redis，而学习用主机内存不足以创建多个虚拟机。</li><li>下面要搭建的读写分离伪集群包含一个 Master 与两个 Slave。它们的端口号分别是：6380、6381、6382。</li></ul><br><h3 id="复制-redis-conf"><a href="#复制-redis-conf" class="headerlink" title="复制 redis.conf"></a>复制 redis.conf</h3><ul><li>在 redis 安装目录中 mkdir 一个目录，名称随意。这里命名为 cluster。然后将 redis.conf文件复制到 cluster 目录中。该文件后面会被其它配置文件包含，所以该文件中需要设置每个 Redis 节点相同的公共的属性。</li></ul><br><h3 id="修改-redis-conf"><a href="#修改-redis-conf" class="headerlink" title="修改 redis.conf"></a>修改 redis.conf</h3><blockquote><p>在 redis.conf 中做如下几项修改：</p></blockquote><ul><li><strong>masterauth</strong></li></ul><blockquote><p>因为我们要搭建主从集群，且每个主机都有可能会是 Master，所以最好不要设置密码验证属性 requirepass。如果真需要设置，一定要每个主机的密码都设置为相同的。此时每个配置文件中都要设置两个完全相同的属性：requirepass 与 masterauth。其中 requirepass 用于指定当前主机的访问密码，而 masterauth 用于指定当前 slave 访问 master 时向 master 提交的访问密码，用于让 master 验证自己身份是否合法。</p></blockquote><ul><li><strong>repl-disable-tcp-nodelay</strong></li></ul><blockquote><p>该属性用于设置是否禁用 TCP 特性 tcp-nodelay。设置为 yes 则禁用 tcp-nodelay，此时master 与 slave 间的通信会产生延迟，但使用的 TCP 包数量会较少，占用的网络带宽会较小。相反，如果设置为 no，则网络延迟会变小，但使用的 TCP 包数量会较多，相应占用的网络带宽会大。</p></blockquote><blockquote><p>tcp-nodelay：为了充分复用网络带宽，TCP 总是希望发送尽可能大的数据块。为了达到该目的，TCP 中使用了一个名为 Nagle 的算法</p><p>Nagle 算法的工作原理是，网络在接收到要发送的数据后，并不直接发送，而是等待着数据量足够大（由 TCP 网络特性决定）时再一次性发送出去。这样，网络上传输的有效数据比例就得到了大大提升，无效数据传递量极大减少，于是就节省了网络带宽，缓解了网络压力。</p><p>tcp-nodelay 则是 TCP 协议中 Nagle 算法的开头。</p></blockquote><br><h3 id="新建-redis6380-conf"><a href="#新建-redis6380-conf" class="headerlink" title="新建 redis6380.conf"></a>新建 redis6380.conf</h3><ul><li>新建一个 redis 配置文件 redis6380.conf，该配置文件中的 Redis 端口号为 6380。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.7gbc2hre5u40.webp" width="60%"><br><h3 id="再复制出两个-conf-文件"><a href="#再复制出两个-conf-文件" class="headerlink" title="再复制出两个 conf 文件"></a>再复制出两个 conf 文件</h3><p>再使用 redis6380.conf 复制出两个 conf 文件：redis6381.conf 与 redis6382.conf。然后修改其中的内容。</p><ul><li>修改 redis6381.conf 的内容如下：</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.xffys58raao.webp" width="60%"><br><ul><li>修改 redis6382.conf 的内容如下：</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5e6keop3ns00.webp" width="60%"><br><h3 id="启动三台-Redis"><a href="#启动三台-Redis" class="headerlink" title="启动三台 Redis"></a>启动三台 Redis</h3><ul><li>分别使用 redis6380.conf、redis6381.conf 与 redis6382.conf 三个配置文件启动三台 Redis</li></ul><br><h3 id="设置主从关系"><a href="#设置主从关系" class="headerlink" title="设置主从关系"></a>设置主从关系</h3><ul><li>再打开三个会话框，分别使用客户端连接三台 Redis。然后通过 slaveof 命令，指定 6380的 Redis 为 Master。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4bf4uzhhovq0.webp" width="60%"><br><h3 id="查看状态信息"><a href="#查看状态信息" class="headerlink" title="查看状态信息"></a>查看状态信息</h3><ul><li>通过 info replication 命令可查看当前连接的 Redis 的状态信息</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5uupdo5hec00.webp" width="60%"><br><h2 id="分级管理"><a href="#分级管理" class="headerlink" title="分级管理"></a>分级管理</h2><ul><li>若 Redis 主从集群中的 Slave 较多时，它们的数据同步过程会对 Master 形成较大的性能压力。此时可以对这些 Slave 进行分级管理。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2mzrpmmhd3q0.webp" width="70%"><br><ul><li>设置方式很简单，只需要让低级别 Slave 指定其 slaveof 的主机为其上一级 Slave 即可。不过，上一级 Slave 的状态仍为 Slave，只不过，其是更上一级的 Slave。</li><li>例如，指定 6382 主机为 6381 主机的 Slave，而 6381 主机仍为真正的 Master 的 Slave。</li><li>此时会发现，Master 的 Slave 只有 6381 一个主机</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.jtz8pen64f4.webp" width="70%"><br><h2 id="容灾冷处理"><a href="#容灾冷处理" class="headerlink" title="容灾冷处理"></a>容灾冷处理</h2><ul><li><p>在 Master/Slave 的 Redis 集群中，若 Master 出现宕机怎么办呢？有两种处理方式，一种是通过手工角色调整，使 Slave 晋升为 Master 的冷处理；一种是使用哨兵模式，实现 Redis集群的高可用 HA，即热处理。</p></li><li><p>无论 Master 是否宕机，Slave 都可通过 slaveof no one 将自己由 Slave 晋升为 Master。如果其原本就有下一级的 Slave，那么，其就直接变为了这些 Slave 的真正的 Master 了。而原来的 Master 也会失去这个原来的 Slave。</p></li></ul><img src="" width="60%"><br><h2 id="主从复制原理"><a href="#主从复制原理" class="headerlink" title="主从复制原理"></a>主从复制原理</h2><h3 id="主从复制过程"><a href="#主从复制过程" class="headerlink" title="主从复制过程"></a>主从复制过程</h3><ul><li>当一个 Redis 节点（slave 节点）接收到类似 slaveof 127.0.0.1 6380 的指令后直至其可以从 master 持续复制数据，大体经历了如下几个过程：</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/dd571f3f00e4d6950ede0c9190c73ef.5uuiaga2r2g0.webp" width="80%"><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/731d169b0deeb64901d4cc82ec49558.1c8izssggrz4.webp" width="80%"><br><br><br><br><h1 id="第7章-Redis-分布式系统"><a href="#第7章-Redis-分布式系统" class="headerlink" title="第7章 Redis 分布式系统"></a>第7章 Redis 分布式系统</h1><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><ol><li><strong>scan</strong> 还需要深入理解一下</li></ol></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">red</span>&gt;</span><span class="tag">&lt;/<span class="name">font</span>&gt;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="60%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;学习前言&quot;&gt;&lt;a href=&quot;#学习前言&quot; class=&quot;headerlink&quot; title=&quot;学习前言&quot;&gt;&lt;/a&gt;学习前言&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;这个学习笔记，详尽的记录了Redis的核心技术与实战技能。是我学习和使用Redis技术过程的一个笔记。用于复习和</summary>
      
    
    
    
    <category term="Database" scheme="https://ratears.github.io/dev.ratears.life/Categories/Database/"/>
    
    <category term="NoSQL" scheme="https://ratears.github.io/dev.ratears.life/Categories/Database/NoSQL/"/>
    
    <category term="Redis" scheme="https://ratears.github.io/dev.ratears.life/Categories/Database/NoSQL/Redis/"/>
    
    
    <category term="NoSQL" scheme="https://ratears.github.io/dev.ratears.life/Tags/NoSQL/"/>
    
    <category term="Database" scheme="https://ratears.github.io/dev.ratears.life/Tags/Database/"/>
    
    <category term="Redis" scheme="https://ratears.github.io/dev.ratears.life/Tags/Redis/"/>
    
    <category term="Cache" scheme="https://ratears.github.io/dev.ratears.life/Tags/Cache/"/>
    
  </entry>
  
  <entry>
    <title>jvm</title>
    <link href="https://ratears.github.io/dev.ratears.life/jvm/"/>
    <id>https://ratears.github.io/dev.ratears.life/jvm/</id>
    <published>2022-12-01T09:12:30.000Z</published>
    <updated>2022-12-01T09:12:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="JVM与Java体系结构"><a href="#JVM与Java体系结构" class="headerlink" title="JVM与Java体系结构"></a>JVM与Java体系结构</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="作为java工程师可能经常会遇到的问题"><a href="#作为java工程师可能经常会遇到的问题" class="headerlink" title="作为java工程师可能经常会遇到的问题"></a><strong>作为java工程师可能经常会遇到的问题</strong></h3><ul><li>运行着的线上系统突然卡死，系统无法访问，甚至直接OOM</li><li>想解决线上JVM GC问题，但却无从下手</li><li>新项目上线，对各种JVM参数设置一脸茫然，直接默认吧然后就JJ了</li><li>每次面试之前都要重新背一遍JVM的一些原理概念性的东西，然而面试官却经常问你在实际项目中如何调优VM参数，如何解决GC、OOM等问题，一脸懵逼</li></ul><blockquote><p>大部分Java开发人员，除会在项目中使用到与Java平台相关的各种高精尖技术，对于Java技术的核心Java虚拟机了解甚少。</p></blockquote><br><h3 id="开发人员如何看待上层框架"><a href="#开发人员如何看待上层框架" class="headerlink" title="开发人员如何看待上层框架"></a><strong>开发人员如何看待上层框架</strong></h3><ul><li>Java虚拟机的知识就好比公式的推导过程</li></ul><blockquote><p>计算机系统体系对我们来说越来越远，在不了解底层实现方式的前提下，通过高级语言很容易编写程序代码。但事实上计算机并不认识高级语言</p></blockquote><br><h3 id="我们为什么要学习JVM？"><a href="#我们为什么要学习JVM？" class="headerlink" title="我们为什么要学习JVM？"></a><strong>我们为什么要学习JVM？</strong></h3><ul><li>面试的需要（BATJ、TMD，PKQ等面试都爱问）</li><li>中高级程序员必备技能<ul><li>项目管理、调优的需求</li></ul></li><li>追求极客的精神<ul><li>比如：垃圾回收算法、JIT、底层原理</li></ul></li></ul><br><h3 id="Java-vs-C"><a href="#Java-vs-C" class="headerlink" title="Java vs C++"></a><strong>Java vs C++</strong></h3><ul><li>垃圾收集机制为我们打理了很多繁琐的工作，大大提高了开发的效率，但是，垃圾收集也不是万能的，懂得JVM内部的内存结构、工作机制，是设计高扩展性应用和诊断运行时问题的基础，也是Java工程师进阶的必备能力。</li></ul><br><h3 id="面向人群及参考书目"><a href="#面向人群及参考书目" class="headerlink" title="面向人群及参考书目"></a><strong>面向人群及参考书目</strong></h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.39wp8r5uj6m0.webp" width="70%"><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.1urwzyssik68.webp" width="70%"><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.20k9lclpjjts.webp    " width="70%"><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.bwj574rfetk.webp" width="70%"><br><br><h2 id="Java及JVM简介"><a href="#Java及JVM简介" class="headerlink" title="Java及JVM简介"></a>Java及JVM简介</h2><blockquote><p>世界上没有最好的编程语言，只有最适用于具体应用场景的编程语言</p></blockquote><br><h3 id="JVM：跨语言的平台"><a href="#JVM：跨语言的平台" class="headerlink" title="JVM：跨语言的平台"></a><strong>JVM：跨语言的平台</strong></h3><ul><li>Java是目前应用最为广泛的软件开发平台之一。随着Java以及Java社区的不断壮大Java 也早已不再是简简单单的一门计算机语言了，它更是一个平台、一种文化、一个社区。</li></ul><ul><li>作为一个平台，Java虚拟机扮演着举足轻重的作用<ul><li>Groovy、Scala、JRuby、Kotlin等都是Java平台的一部分</li></ul></li><li>作为一种文化，Java几乎成为了“开源”的代名词。<ul><li>第三方开源软件和框架。如Tomcat、Struts，MyBatis，Spring等。</li><li>就连JDK和JVM自身也有不少开源的实现，如openJDK、Harmony。</li></ul></li><li>作为一个社区，Java拥有全世界最多的技术拥护者和开源社区支持，有数不清的论坛和资料。从桌面应用软件、嵌入式开发到企业级应用、后台服务器、中间件，都可以看到Java的身影。其应用形式之复杂、参与人数之众多也令人咋舌。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5iwwquuo9ms0.webp" width="70%"><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.y3kf2h91gww.webp" width="70%"><br><blockquote><ul><li>随着Java7的正式发布，Java虚拟机的设计者们通过JSR-292规范基本实现在Java虚拟机平台上运行非Java语言编写的程序。</li><li>Java虚拟机根本不关心运行在其内部的程序到底是使用何种编程语言编写的，它只关心“字节码”文件。也就是说Java虚拟机拥有语言无关性，并不会单纯地与Java语言“终身绑定”，只要其他编程语言的编译结果满足并包含Java虚拟机的内部指令集、符号表以及其他的辅助信息，它就是一个有效的字节码文件，就能够被虚拟机所识别并装载运行。</li></ul></blockquote><br><h3 id="字节码"><a href="#字节码" class="headerlink" title="字节码"></a><strong>字节码</strong></h3><ul><li>我们平时说的java字节码，指的是用java语言编译成的字节码。准确的说任何能在jvm平台上执行的字节码格式都是一样的。所以应该统称为：jvm字节码。</li><li>不同的编译器，可以编译出相同的字节码文件，字节码文件也可以在不同的JVM上运行。</li><li>Java虚拟机与Java语言并没有必然的联系，它只与特定的二进制文件格式—Class文件格式所关联，Class文件中包含了Java虚拟机指令集（或者称为字节码、Bytecodes）和符号表，还有一些其他辅助信息。</li></ul><br><h3 id="多语言混合编程"><a href="#多语言混合编程" class="headerlink" title="多语言混合编程"></a><strong>多语言混合编程</strong></h3><ul><li>Java平台上的多语言混合编程正成为主流，通过特定领域的语言去解决特定领域的问题是当前软件开发应对日趋复杂的项目需求的一个方向。</li><li>试想一下，在一个项目之中，并行处理用Clojure语言编写，展示层使用JRuby/Rails，中间层则是Java，每个应用层都将使用不同的编程语言来完成，而且，接口对每一层的开发者都是透明的，各种语言之间的交互不存在任何困难，就像使用自己语言的原生API一样方便，因为它们最终都运行在一个虚拟机之上。</li><li>对这些运行于Java虚拟机之上、Java之外的语言，来自系统级的、底层的支持正在迅速增强，以JSR-292为核心的一系列项目和功能改进（如Da Vinci Machine项目、Nashorn引擎、InvokeDynamic指令、java.lang.invoke包等），推动Java虚拟机从“Java语言的虚拟机”向 “多语言虚拟机”的方向发展。</li></ul><br><h3 id="如何真正搞懂JVM？"><a href="#如何真正搞懂JVM？" class="headerlink" title="如何真正搞懂JVM？"></a><strong>如何真正搞懂JVM？</strong></h3><ul><li>Java虚拟机非常复杂，要想真正理解它的工作原理，最好的方式就是自己动手编写一个！</li></ul><br><br><h2 id="Java发展的重大事件"><a href="#Java发展的重大事件" class="headerlink" title="Java发展的重大事件"></a>Java发展的重大事件</h2><ul><li>1990年，在Sun计算机公司中，由Patrick Naughton、MikeSheridan及James Gosling领导的小组Green Team，开发出的新的程序语言，命名为oak，后期命名为Java</li><li>1995年，Sun正式发布Java和HotJava产品，Java首次公开亮相。</li><li>1996年1月23日，Sun Microsystems发布了JDK 1.0。</li><li>1998年，JDK1.2版本发布。同时，sun发布了JSP/Servlet、EJB规范，以及将Java分成了J2EE、J2SE和J2ME。这表明了Java开始向企业、桌面应用和移动设备应用3大领域挺进。</li><li>2000年，JDK1.3发布，Java HotSpot Virtual Machine正式发布，成为Java的默认虚拟机。</li><li></li></ul><br><br><br><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="60%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;JVM与Java体系结构&quot;&gt;&lt;a href=&quot;#JVM与Java体系结构&quot; class=&quot;headerlink&quot; title=&quot;JVM与Java体系结构&quot;&gt;&lt;/a&gt;JVM与Java体系结构&lt;/h1&gt;&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;</summary>
      
    
    
    
    <category term="jvm" scheme="https://ratears.github.io/dev.ratears.life/Categories/jvm/"/>
    
    
    <category term="jvm" scheme="https://ratears.github.io/dev.ratears.life/Tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>《深入拆解 Java 虚拟机》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8A%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3-Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8A%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3-Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8Bstudy-notes/</id>
    <published>2022-11-29T08:50:47.000Z</published>
    <updated>2022-11-29T08:50:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="开篇词-1讲"><a href="#开篇词-1讲" class="headerlink" title="开篇词 (1讲)"></a>开篇词 (1讲)</h1><h2 id="开篇词-为什么我们要学习Java虚拟机？"><a href="#开篇词-为什么我们要学习Java虚拟机？" class="headerlink" title="开篇词 | 为什么我们要学习Java虚拟机？"></a>开篇词 | 为什么我们要学习Java虚拟机？</h2><ul><li><strong>学习 Java 虚拟机的本质，更多是了解 Java 程序是如何被执行且优化的。</strong>(这样一来，才可以从内部入手，达到高效编程的目的。与此同时，也可以为学习更深层级、更为核心的 Java 技术打好基础。)</li></ul><ul><li>了解学习 Java 虚拟机有如下（但不限于）好处<ul><li>可以针对自己的应用，最优化匹配运行参数（Java 虚拟机提供了许多配置参数，用于满足不同应用场景下，对程序性能的需求。）</li><li>可以更好地规避它在使用中的 Bug，也可以更快地识别出 Java 虚拟机中的错误</li><li>Java 虚拟机发展到了今天，已经脱离 Java 语言，形成了一套相对独立的、高性能的执行方案。除了 Java 外，Scala、Clojure、Groovy，以及时下热门的 Kotlin，这些语言都可以运行在 Java 虚拟机之上</li></ul></li></ul><ul><li>整个专栏将分为四大模块<ul><li><strong>基本原理</strong>：剖析 Java 虚拟机的运行机制，逐一介绍 Java 虚拟机的设计决策以及工程实现；</li><li><strong>高效实现</strong>：探索 Java 编译器，以及内嵌于 Java 虚拟机中的即时编译器，帮助更好地理解 Java 语言特性，继而写出简洁高效的代码；</li><li><strong>代码优化</strong>：介绍如何利用工具定位并解决代码中的问题，以及在已有工具不适用的情况下，如何打造专属轮子；</li><li><strong>虚拟机黑科技</strong>：介绍甲骨文实验室近年来的前沿工作之一 GraalVM。包括如何在 JVM 上高效运行其他语言；如何混搭这些语言，实现 Polyglot；如何将这些语言事前编译（Ahead-Of-Time，AOT）成机器指令，单独运行甚至嵌入至数据库中运行。</li></ul></li></ul><ul><li>知识框架图</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3q88hqo431w0.webp" width="100%"><br><br><br><h1 id="模块一：Java虚拟机基本原理-12讲"><a href="#模块一：Java虚拟机基本原理-12讲" class="headerlink" title="模块一：Java虚拟机基本原理 (12讲)"></a>模块一：Java虚拟机基本原理 (12讲)</h1><h2 id="01-Java代码是怎么运行的？"><a href="#01-Java代码是怎么运行的？" class="headerlink" title="01 | Java代码是怎么运行的？"></a>01 | Java代码是怎么运行的？</h2><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="60%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;开篇词-1讲&quot;&gt;&lt;a href=&quot;#开篇词-1讲&quot; class=&quot;headerlink&quot; title=&quot;开篇词 (1讲)&quot;&gt;&lt;/a&gt;开篇词 (1讲)&lt;/h1&gt;&lt;h2 id=&quot;开篇词-为什么我们要学习Java虚拟机？&quot;&gt;&lt;a href=&quot;#开篇词-为什么我们要学习J</summary>
      
    
    
    
    <category term="Java" scheme="https://ratears.github.io/dev.ratears.life/Categories/Java/"/>
    
    <category term="jvm" scheme="https://ratears.github.io/dev.ratears.life/Categories/Java/jvm/"/>
    
    
    <category term="java" scheme="https://ratears.github.io/dev.ratears.life/Tags/java/"/>
    
    <category term="jvm" scheme="https://ratears.github.io/dev.ratears.life/Tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>《Kafka多维度系统精讲，从入门到熟练掌握》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8AKafka%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%B2%BE%E8%AE%B2%EF%BC%8C%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%86%9F%E7%BB%83%E6%8E%8C%E6%8F%A1%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8AKafka%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%B2%BE%E8%AE%B2%EF%BC%8C%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%86%9F%E7%BB%83%E6%8E%8C%E6%8F%A1%E3%80%8Bstudy-notes/</id>
    <published>2022-11-26T14:00:57.000Z</published>
    <updated>2022-11-26T14:00:57.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第1章-课程导学与学习指南"><a href="#第1章-课程导学与学习指南" class="headerlink" title="第1章 课程导学与学习指南"></a>第1章 课程导学与学习指南</h1><br><br><br><h1 id="第2章-Kafka入门——开发环境准备"><a href="#第2章-Kafka入门——开发环境准备" class="headerlink" title="第2章 Kafka入门——开发环境准备"></a>第2章 Kafka入门——开发环境准备</h1><br><br><br><h1 id="第3章-Kafka入门——Kafka基础操作"><a href="#第3章-Kafka入门——Kafka基础操作" class="headerlink" title="第3章 Kafka入门——Kafka基础操作"></a>第3章 Kafka入门——Kafka基础操作</h1><h2 id="Kafka介绍"><a href="#Kafka介绍" class="headerlink" title="Kafka介绍"></a>Kafka介绍</h2><ul><li>一个分布式流处理平台</li><li>Kafka是基于zookeeper的分布式消息系统</li><li>Kafka具有高吞吐率、高性能、实时及高可靠等特点</li></ul><br><h2 id="Kafka安装"><a href="#Kafka安装" class="headerlink" title="Kafka安装"></a>Kafka安装</h2><ul><li>安装准备<ul><li>jdk-8u181-linux-x64.tar.gz（因为Kafka是scala开发的，scala是基于jdk的，固需需要安装jdk）</li><li>apache-zookeeper-3.5.7-bin.tar.gz</li><li>kafka_2.11-2.4.0.tgz</li></ul></li></ul><br><h3 id="step1-安装jdk"><a href="#step1-安装jdk" class="headerlink" title="step1 安装jdk"></a>step1 安装jdk</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">准备jdk安装包，并解压到 /usr/local/ 目录下</span></span><br><span class="line">tar -zxvf jdk-8u181-linux-x64.tar.gz -C /usr/local/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建软连接</span></span><br><span class="line">ln -s jdk-8u181-linux-x64 jdk1.8</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置jdk环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">文档末尾追加如下内容</span></span><br><span class="line">export JAVA_HOME=/usr/local/jdk1.8</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证jdk环境</span></span><br><span class="line">java -version</span><br></pre></td></tr></table></figure><br><h3 id="step2-安装zookeeper"><a href="#step2-安装zookeeper" class="headerlink" title="step2 安装zookeeper"></a>step2 安装zookeeper</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">准备zookeeper安装包，并解压到 /usr/local/ 目录下</span></span><br><span class="line">tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /usr/local/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建软连接</span></span><br><span class="line">ln -s apache-zookeeper-3.5.7-bin zookeeper</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">准备配置文件</span></span><br><span class="line">cd /usr/local/zookeeper/conf/</span><br><span class="line"></span><br><span class="line">cp zoo_sample.cfg zoo.cfg</span><br><span class="line"></span><br><span class="line">vim zoo.cfg</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改 dataDir 然后保存（生产环境应该把dataDir设置成磁盘比较大的目录）</span></span><br><span class="line">dataDir=/usr/local/zookeeper/data</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建data目录</span></span><br><span class="line">mkdir -p /usr/local/zookeeper/data</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动zookeeper</span></span><br><span class="line">cd /usr/local/zookeeper/bin/</span><br><span class="line">./zkServer.sh start</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用zookeeper 自带的客户端连接 zookeeper</span></span><br><span class="line">cd /usr/local/zookeeper/bin/</span><br><span class="line">./zkCli.sh</span><br><span class="line"></span><br></pre></td></tr></table></figure><br><h3 id="step3-安装Kafka"><a href="#step3-安装Kafka" class="headerlink" title="step3 安装Kafka"></a>step3 安装Kafka</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">准备zookeeper安装包，并解压到 /usr/local/ 目录下</span></span><br><span class="line">tar -zxvf kafka_2.11-2.4.0.tar.gz -C /usr/local/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建软连接</span></span><br><span class="line">ln -s kafka_2.11-2.4.0 kafka</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改配置文件</span></span><br><span class="line">cd /usr/local/kafka/config/</span><br><span class="line"></span><br><span class="line">vim server.properties</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line">listeners=PLAINTEXT://192.168.146.135:9092</span><br><span class="line"></span><br><span class="line">advertised.listeners=PLAINTEXT://192.168.146.135:9092</span><br><span class="line"></span><br><span class="line">log.dirs=/usr/local/kafka/kafka-logs</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意生产环境该配置会变化，目前我们就使用如下配置，保持不变</span></span><br><span class="line">zookeeper.connect=localhost:2181</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">####################################################</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建logs目录</span></span><br><span class="line">mkdir -p /usr/local/kafka/kafka-logs</span><br></pre></td></tr></table></figure><br><h2 id="Kafka常用命令"><a href="#Kafka常用命令" class="headerlink" title="Kafka常用命令"></a>Kafka常用命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意执行命令需要在kafka的根目录下</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、启动Kafka</span></span><br><span class="line">bin/kafka-server-start.sh config/server.properties &amp;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、停止Kafka</span></span><br><span class="line">bin/kafka-server-stop.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3、创建Topic</span></span><br><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic jiangzh-topic</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4、查看已经创建的Topic信息</span></span><br><span class="line">bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">5、发送消息</span></span><br><span class="line">bin/kafka-console-producer.sh --broker-list 192.168.146.135:9092 --topic jiangzh-topic</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">6、接收消息</span></span><br><span class="line">bin/kafka-console-consumer.sh --bootstrap-server 192.168.146.135:9092 --topic jiangzh-topic --from-beginning</span><br></pre></td></tr></table></figure><br><h2 id="Kafka基本概念"><a href="#Kafka基本概念" class="headerlink" title="Kafka基本概念"></a>Kafka基本概念</h2><ul><li>Topic：一个虚拟的概念，由1到多个Partitions组成</li><li>Partition：实际消息存储单位</li><li>Producer：消息生产者</li><li>Consumer：消息消费者</li></ul><br><br><br><h1 id="第4章-Kafka核心API——Kafka客户端操作"><a href="#第4章-Kafka核心API——Kafka客户端操作" class="headerlink" title="第4章 Kafka核心API——Kafka客户端操作"></a>第4章 Kafka核心API——Kafka客户端操作</h1><h2 id="五类Kafka客户端-API"><a href="#五类Kafka客户端-API" class="headerlink" title="五类Kafka客户端 API"></a>五类Kafka客户端 API</h2><ul><li>Producer API: 向主题(一个或多个)发布消息；</li><li>Consumer API: 订阅主题(一个或多个)，拉取这些主题上发布的消息；</li><li>Stream API: 作为流处理器，从主题消费消息，向主题发布消息，把输出流转换为输入流；</li><li>Connect API: 作为下游或上游，把主题连接到应用程序或数据系统(比如关系数据库)，通常不需要直接使用这些API，而是使用 现成的连接器；</li><li>AdminClient API: 管理(或巡查) topic, brokers, 或其他 kafka 对象；</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.32hkgl5c6x20.webp" width="60%"><br><h2 id="AdminClient客户端建立"><a href="#AdminClient客户端建立" class="headerlink" title="AdminClient客户端建立"></a>AdminClient客户端建立</h2><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3dkg228f3zm0.webp" width="70%"><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AdminSimple</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">AdminClient</span> <span class="variable">adminClient</span> <span class="operator">=</span> adminClient();</span><br><span class="line">        System.out.println(<span class="string">&quot;adminClient:&quot;</span>+adminClient);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> AdminClient <span class="title function_">adminClient</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.setProperty(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;192.168.146.135:9092&quot;</span>);</span><br><span class="line">        <span class="type">AdminClient</span> <span class="variable">adminClient</span> <span class="operator">=</span> AdminClient.create(properties);</span><br><span class="line">        <span class="keyword">return</span> adminClient;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><h2 id="创建Topic演示"><a href="#创建Topic演示" class="headerlink" title="创建Topic演示"></a>创建Topic演示</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AdminSimple</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"><span class="comment">//        AdminClient adminClient = adminClient();</span></span><br><span class="line"><span class="comment">//        System.out.println(&quot;adminClient:&quot;+adminClient);</span></span><br><span class="line">        createTopic();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">createTopic</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">AdminClient</span> <span class="variable">adminClient</span> <span class="operator">=</span> adminClient();</span><br><span class="line">        <span class="type">short</span> <span class="variable">rs</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line">        <span class="type">NewTopic</span> <span class="variable">newTopic</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">NewTopic</span>(<span class="string">&quot;demo_topic&quot;</span>,<span class="number">10</span>,rs);</span><br><span class="line">        <span class="type">CreateTopicsResult</span> <span class="variable">topics</span> <span class="operator">=</span> adminClient.createTopics(Arrays.asList(newTopic));</span><br><span class="line">        System.out.println(<span class="string">&quot;CreateTopicsResult :&quot;</span>+topics.toString());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> AdminClient <span class="title function_">adminClient</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.setProperty(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;192.168.146.135:9092&quot;</span>);</span><br><span class="line">        <span class="type">AdminClient</span> <span class="variable">adminClient</span> <span class="operator">=</span> AdminClient.create(properties);</span><br><span class="line">        <span class="keyword">return</span> adminClient;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="60%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;第1章-课程导学与学习指南&quot;&gt;&lt;a href=&quot;#第1章-课程导学与学习指南&quot; class=&quot;headerlink&quot; title=&quot;第1章 课程导学与学习指南&quot;&gt;&lt;/a&gt;第1章 课程导学与学习指南&lt;/h1&gt;&lt;br&gt;

&lt;br&gt;

&lt;br&gt;

&lt;h1 id=&quot;第2章</summary>
      
    
    
    
    <category term="MQ" scheme="https://ratears.github.io/dev.ratears.life/Categories/MQ/"/>
    
    <category term="Kafka" scheme="https://ratears.github.io/dev.ratears.life/Categories/MQ/Kafka/"/>
    
    
    <category term="Kafka" scheme="https://ratears.github.io/dev.ratears.life/Tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>《Kafka 核心技术与实战》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8AKafka-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8AKafka-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/</id>
    <published>2022-11-26T14:00:57.000Z</published>
    <updated>2022-11-26T14:00:57.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="开篇词-1讲"><a href="#开篇词-1讲" class="headerlink" title="开篇词 (1讲)"></a>开篇词 (1讲)</h1><h2 id="开篇词-为什么要学习Kafka？"><a href="#开篇词-为什么要学习Kafka？" class="headerlink" title="开篇词 | 为什么要学习Kafka？"></a>开篇词 | 为什么要学习Kafka？</h2><ul><li><p>当下互联网行业最火的技术当属 ABC 了</p><ul><li>AI 人工智能</li><li>BigData 大数据</li><li>Cloud 云计算云平台</li></ul></li><li><p>对于数据密集型应用来说，如何应对数据量激增、数据复杂度增加以及数据变化速率变快，是彰显大数据工程师、架构师功力的最有效表征</p><ul><li>Kafka 在帮助应对这些问题方面能起到非常好的效果（Kafka 能够有效隔离上下游业务，将上游突增的流量缓存起来，以平滑的方式传导到下游子系统中，避免了流量的不规则冲击）</li></ul></li><li><p>Kafka 有着非常广阔的应用场景</p><ul><li>目前 Apache Kafka 被认为是整个消息引擎领域的执牛耳者</li><li>从学习技术的角度而言，Kafka 也是很有亮点的（我们仅需要学习一套框架就能在实际业务系统中实现消息引擎应用、应用程序集成、分布式存储构建，甚至是流处理应用的开发与部署）</li><li>Kafka 无论是作为消息引擎还是实时流处理平台，都能在大数据工程领域发挥重要的作用</li></ul></li></ul><br><h3 id="学透-Kafka-推荐路径"><a href="#学透-Kafka-推荐路径" class="headerlink" title="学透 Kafka 推荐路径"></a>学透 Kafka 推荐路径</h3><ul><li>软件开发工程师</li></ul><ol><li>根据你掌握的编程语言去寻找对应的 Kafka 客户端</li><li>去官网上学习一下代码示例（如果能够正确编译和运行这些样例，就能轻松地驾驭客户端了）</li><li>尝试修改样例代码尝试去理解并使用其他的 API（观测修改的结果）</li><li>编写一个小型项目来验证下学习成果，然后就是改善和提升客户端的可靠性和性能了</li><li>熟读一遍 Kafka 官网文档，确保理解了那些可能影响可靠性和性能的参数</li><li>学习 Kafka 的高级功能（比如流处理应用开发。流处理 API 不仅能够生产和消费消息，还能执行高级的流式处理操作，比如时间窗口聚合、流处理连接等）</li></ol><ul><li>系统管理员或运维工程师</li></ul><blockquote><p>如果你是系统管理员或运维工程师，那么相应的学习目标应该是学习搭建及管理 Kafka 线上环境。如何根据实际业务需求评估、搭建生产线上环境将是你主要的学习目标。另外对生产环境的监控也是重中之重的工作，Kafka 提供了超多的 JMX 监控指标，你可以选择任意你熟知的框架进行监控。有了监控数据，作为系统运维管理员的你，势必要观测真实业务负载下的 Kafka 集群表现。之后如何利用已有的监控指标来找出系统瓶颈，然后提升整个系统的吞吐量，这也是最能体现你工作价值的地方</p></blockquote><br><h3 id="专栏思维导图"><a href="#专栏思维导图" class="headerlink" title="专栏思维导图"></a>专栏思维导图</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.26rhfqn0svcw.webp" width="100%"><br><p>（1）Kafka 入门</p><ul><li>介绍消息引擎这类系统大致的原理和用途，以及作为优秀消息引擎代表的 Kafka 在这方面的表现</li></ul><p>（2）Kafka 的基本使用</p><ul><li>重点探讨 Kafka 如何用于生产环境，特别是线上环境方案的制定</li></ul><p>（3）客户端详解</p><ul><li>学习 Kafka 客户端的方方面面，既有生产者的实操讲解也有消费者的原理剖析</li></ul><p>（4）Kafka 原理介绍</p><ul><li>着重介绍 Kafka 最核心的设计原理，包括 Controller 的设计机制、请求处理全流程解析等</li></ul><p>（5）Kafka 运维与监控</p><ul><li>获得高效运维 Kafka 集群以及有效监控 Kafka 的实战经验</li></ul><p>（6）高级 Kafka 应用</p><ul><li>Kafka 流处理组件 Kafka Streams 的实战应用</li></ul><br><br><br><h1 id="Kafka入门-5讲"><a href="#Kafka入门-5讲" class="headerlink" title="Kafka入门 (5讲)"></a>Kafka入门 (5讲)</h1><h2 id="01-消息引擎系统ABC"><a href="#01-消息引擎系统ABC" class="headerlink" title="01 | 消息引擎系统ABC"></a>01 | 消息引擎系统ABC</h2><ul><li><strong>Apache Kafka 是一款开源的消息引擎系统</strong></li><li>消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递</li><li>Kafka使用纯二进制字节序列传递消息，消息也是有结构的</li></ul><br><h3 id="消息引擎传输消息模型"><a href="#消息引擎传输消息模型" class="headerlink" title="消息引擎传输消息模型"></a>消息引擎传输消息模型</h3><ul><li><strong>点对点模型</strong>：一对一发送or接收消息</li><li><strong>发布 / 订阅模型</strong>：它有一个主题（Topic）的概念（可以理解成逻辑语义相近的消息容器）。发送方也称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个</li></ul><br><ul><li>JMS：JMS 是 Java Message Service，它也是支持上面这两种消息引擎模型的。严格来说它并非传输协议而仅仅是一组 API 罢了</li></ul><br><h3 id="为什么要使用消息引擎"><a href="#为什么要使用消息引擎" class="headerlink" title="为什么要使用消息引擎"></a>为什么要使用消息引擎</h3><ul><li><strong>削峰填谷</strong></li></ul><blockquote><p>​    所谓的“削峰填谷”就是指缓冲上下游瞬时突发流量，使其更平滑。特别是对于那种发送能力很强的上游系统，如果没有消息引擎的保护，“脆弱”的下游系统可能会直接被压垮导致全链路服务“雪崩”。但是，一旦有了消息引擎，它能够有效地对抗上游的流量冲击，真正做到将上游的“峰”填满到“谷”中，避免了流量的震荡。消息引擎系统的另一大好处在于发送方和接收方的松耦合，这也在一定程度上简化了应用的开发，减少了系统间不必要的交互。</p></blockquote><ul><li>当引入了 Kafka 之后。上游订单服务不再直接与下游子服务进行交互。当新订单生成后它仅仅是向 Kafka Broker 发送一条订单消息即可。类似地，下游的各个子服务订阅 Kafka 中的对应主题，并实时从该主题的各自分区（Partition）中获取到订单消息进行处理，从而实现了上游订单服务与下游订单处理服务的解耦。这样当出现秒杀业务时，Kafka 能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的 TPS，同时也给下游子服务留出了充足的时间去消费它们。这就是 Kafka 这类消息引擎系统的最大意义所在。</li></ul><br><br><h2 id="02-一篇文章带你快速搞定Kafka术语"><a href="#02-一篇文章带你快速搞定Kafka术语" class="headerlink" title="02 | 一篇文章带你快速搞定Kafka术语"></a>02 | 一篇文章带你快速搞定Kafka术语</h2><ul><li>消息：Record。Kafka 是消息引擎，这里的消息就是指 Kafka 处理的主要对象。</li><li>主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。</li><li>分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。</li><li>消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。</li><li>副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。</li><li>生产者：Producer。向主题发布新消息的应用程序。</li><li>消费者：Consumer。从主题订阅新消息的应用程序。</li><li>消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。</li><li>消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。</li><li>重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。</li></ul><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2etr83rywssg.webp" width="80%"><br><ul><li>生产者和消费者统称为客户端（Clients）</li><li>Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。</li></ul><br><h3 id="Kafka提供高可用的手段"><a href="#Kafka提供高可用的手段" class="headerlink" title="Kafka提供高可用的手段"></a>Kafka提供高可用的手段</h3><ul><li>多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上（这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务）</li><li>备份机制（Replication）（把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在 Kafka 中被称为副本（Replica））</li></ul><br><h3 id="副本的工作机制"><a href="#副本的工作机制" class="headerlink" title="副本的工作机制"></a>副本的工作机制</h3><ul><li>生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。</li><li>副本机制可以保证数据的持久化或消息不丢失</li></ul><br><h3 id="Kafka解决伸缩性"><a href="#Kafka解决伸缩性" class="headerlink" title="Kafka解决伸缩性"></a>Kafka解决伸缩性</h3><ul><li>伸缩性即所谓的 Scalability，是分布式系统中非常重要且必须要谨慎对待的问题</li><li>什么是伸缩性：我们拿副本来说，虽然现在有了领导者副本和追随者副本，但倘若领导者副本积累了太多的数据以至于单台 Broker 机器都无法容纳了，此时应该怎么办呢？<strong>把数据分割成多份保存在不同的 Broker 上</strong>。这种机制就是所谓的分区（Partitioning）</li></ul><br><h4 id="分区机制"><a href="#分区机制" class="headerlink" title="分区机制"></a>分区机制</h4><ul><li>Kafka 中的分区机制指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。</li></ul><blockquote><p>生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，这条消息要么在分区 0 中，要么在分区 1 中。如你所见，Kafka 的分区编号是从 0 开始的，如果 Topic 有 100 个分区，那么它们的分区号就是从 0 到 99。</p></blockquote><ul><li><strong>副本</strong>：副本是在分区这个层级定义的。</li></ul><blockquote><p>每个分区下可以配置若干个副本，其中只能有 1 个领导者副本和 N-1 个追随者副本。生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征。分区位移总是从 0 开始，假设一个生产者向一个空分区写入了 10 条消息，那么这 10 条消息的位移依次是 0、1、2、…、9。</p></blockquote><br><h3 id="Kafka-的三层消息架构"><a href="#Kafka-的三层消息架构" class="headerlink" title="Kafka 的三层消息架构"></a>Kafka 的三层消息架构</h3><ul><li>第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。</li><li>第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。</li><li>第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。</li><li>最后，客户端程序只能与分区的领导者副本进行交互。</li></ul><br><h3 id="Kafka-Broker-是如何持久化数据的"><a href="#Kafka-Broker-是如何持久化数据的" class="headerlink" title="Kafka Broker 是如何持久化数据的"></a>Kafka Broker 是如何持久化数据的</h3><ul><li>Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。</li></ul><blockquote><p>因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，<strong>这也是实现 Kafka 高吞吐量特性的一个重要手段。</strong></p></blockquote><ul><li>日志段（Log Segment）机制<ul><li>在 Kafka 底层，一个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。</li></ul></li></ul><br><h3 id="消费者组"><a href="#消费者组" class="headerlink" title="消费者组"></a>消费者组</h3><ul><li>Kafka 中实现这种 P2P 模型的方法就是引入了消费者组（Consumer Group）。</li></ul><blockquote><p>所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。为什么要引入消费者组呢？主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。</p></blockquote><blockquote><p>这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。</p></blockquote><br><h3 id="重平衡"><a href="#重平衡" class="headerlink" title="重平衡"></a>重平衡</h3><blockquote><p>消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助。</p></blockquote><ul><li>假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。</li></ul><blockquote><p>由重平衡引发的消费者问题比比皆是。事实上，目前很多重平衡的 Bug 社区都无力解决。</p></blockquote><br><ul><li>每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）。</li></ul><br><br><h2 id="03-Kafka只是消息引擎系统吗？"><a href="#03-Kafka只是消息引擎系统吗？" class="headerlink" title="03 | Kafka只是消息引擎系统吗？"></a>03 | Kafka只是消息引擎系统吗？</h2><p><strong>有的时候我们会觉得说了解一个系统或框架的前世今生似乎没什么必要，直接开始学具体的技术不是更快更好吗？其实，不论是学习哪种技术，直接扎到具体的细节中，亦或是从一个很小的点开始学习，你很快就会感到厌烦。为什么呢？因为你虽然快速地搞定了某个技术细节，但无法建立全局的认知观，这会导致你只是在单个的点上有所进展，却没法将其串联成一条线进而扩展成一个面，从而实现系统地学习。</strong></p><ul><li><strong>Apache Kafka 是消息引擎系统，也是一个分布式流处理平台</strong>（Distributed Streaming Platform）</li></ul><br><ul><li>Kafka 在设计之初就旨在提供三个方面的特性：<ul><li>提供一套 API 实现生产者和消费者；</li><li>降低网络传输和磁盘存储开销；</li><li>实现高伸缩性架构。</li></ul></li></ul><br><blockquote><p>开源之后的 Kafka 被越来越多的公司应用到它们企业内部的数据管道中，特别是在大数据工程领域，Kafka 在承接上下游、串联数据流管道方面发挥了重要的作用：所有的数据几乎都要从一个系统流入 Kafka 然后再流向下游的另一个系统中。这样的使用方式屡见不鲜以至于引发了 Kafka 社区的思考：与其我把数据从一个系统传递到下一个系统中做处理，我为何不自己实现一套流处理框架呢？基于这个考量，Kafka 社区于 0.10.0.0 版本正式推出了流处理组件 Kafka Streams，也正是从这个版本开始，Kafka 正式“变身”为分布式的流处理平台，而不仅仅是消息引擎系统了。今天 Apache Kafka 是和 Apache Storm、Apache Spark 和 Apache Flink 同等级的实时流处理平台。</p></blockquote><br><h3 id="Kafka-与其他主流大数据流式计算框架相比的优势"><a href="#Kafka-与其他主流大数据流式计算框架相比的优势" class="headerlink" title="Kafka 与其他主流大数据流式计算框架相比的优势"></a>Kafka 与其他主流大数据流式计算框架相比的优势</h3><ul><li><strong>第一点是更容易实现端到端的正确性（Correctness）</strong>。<ul><li><strong>要实现正确性和提供能够推导时间的工具。实现正确性是流处理能够匹敌批处理的基石</strong>。</li></ul></li><li><strong>对于流式计算的定位</strong><ul><li>需要自己选择适合的工具或系统来帮助 Kafka 流处理应用实现这些功能</li></ul></li></ul><br><br><h2 id="04-我应该选择哪种Kafka？"><a href="#04-我应该选择哪种Kafka？" class="headerlink" title="04 | 我应该选择哪种Kafka？"></a>04 | 我应该选择哪种Kafka？</h2><h3 id="Kafka-Connect"><a href="#Kafka-Connect" class="headerlink" title="Kafka Connect"></a>Kafka Connect</h3><ul><li>Kafka Connect 通过一个个具体的连接器（Connector），串联起上下游的外部系统。</li></ul><br><ul><li>Kafka Connect 组件支持的一部分外部系统，如下图</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.6ktbply8no00.webp" width="60%"><br><h3 id="Kafka种类"><a href="#Kafka种类" class="headerlink" title="Kafka种类"></a>Kafka种类</h3><h4 id="Apache-Kafka"><a href="#Apache-Kafka" class="headerlink" title="Apache Kafka"></a><strong>Apache Kafka</strong></h4><ul><li>Apache Kafka 是最“正宗”的 Kafka，也应该是你最熟悉的发行版了。自 Kafka 开源伊始，它便在 Apache 基金会孵化并最终毕业成为顶级项目，它也被称为社区版 Kafka。<ul><li>后面提到的发行版要么是原封不动地继承了 Apache Kafka，要么是在此之上扩展了新功能</li><li>开发人数最多、版本迭代速度最快的 Kafka。社区活跃</li><li>劣势：仅仅提供最最基础的组件<ul><li>社区版 Kafka 只提供一种连接器，即读写磁盘文件的连接器，而没有与其他外部系统交互的连接器，在实际使用过程中需要自行编写代码实现</li></ul></li><li>Apache Kafka 没有提供任何监控框架或工具。必然需要借助第三方的监控框架实现对 Kafka 的监控。（好消息是目前有一些开源的监控框架可以帮助用于监控 Kafka（比如 Kafka manager））</li></ul></li></ul><ul><li><strong>如果你仅仅需要一个消息引擎系统亦或是简单的流处理应用场景，同时需要对系统有较大把控度，推荐你使用 Apache Kafka。</strong></li></ul><br><h4 id="Confluent-Kafka"><a href="#Confluent-Kafka" class="headerlink" title="Confluent Kafka"></a><strong>Confluent Kafka</strong></h4><ul><li>Confluent 公司，它主要从事商业化 Kafka 工具开发，并在此基础上发布了 Confluent Kafka。Confluent Kafka 提供了一些 Apache Kafka 没有的高级特性，比如跨数据中心备份、Schema 注册中心以及集群监控工具等。</li><li>Confluent Kafka 目前分为免费版和企业版两种。前者和 Apache Kafka 非常相像，除了常规的组件之外，免费版还包含 Schema 注册中心和 REST proxy 两大功能。前者是帮助你集中管理 Kafka 消息格式以实现数据前向 / 后向兼容；后者用开放 HTTP 接口的方式允许你通过网络访问 Kafka 的各种功能，这两个都是 Apache Kafka 所没有的。</li><li>免费版包含了更多的连接器，它们都是 Confluent 公司开发并认证过的，你可以免费使用它们。至于企业版，它提供的功能就更多了。在我看来，最有用的当属跨数据中心备份和集群监控两大功能了。多个数据中心之间数据的同步以及对集群的监控历来是 Kafka 的痛点，Confluent Kafka 企业版提供了强大的解决方案帮助你“干掉”它们。</li><li>Confluent 公司暂时没有发展国内业务的计划，相关的资料以及技术支持都很欠缺，很多国内 Confluent Kafka 使用者甚至无法找到对应的中文文档，因此目前 Confluent Kafka 在国内的普及率是比较低的。</li></ul><br><h4 id="Cloudera-Hortonworks-Kafka"><a href="#Cloudera-Hortonworks-Kafka" class="headerlink" title="Cloudera/Hortonworks Kafka"></a><strong>Cloudera/Hortonworks Kafka</strong></h4><ul><li>Cloudera 提供的 CDH 和 Hortonworks 提供的 HDP 是非常著名的大数据平台，里面集成了目前主流的大数据框架，能够帮助用户实现从分布式存储、集群调度、流处理到机器学习、实时数据库等全方位的数据处理。很多创业公司在搭建数据平台时首选就是这两个产品。不管是 CDH 还是 HDP 里面都集成了 Apache Kafka，因此我把这两款产品中的 Kafka 称为 CDH Kafka 和 HDP Kafka。</li><li>Kafka（CDH/HDP Kafka）。这些大数据平台天然集成了 Apache Kafka，通过便捷化的界面操作将 Kafka 的安装、运维、管理、监控全部统一在控制台中。</li><li>降低了你对 Kafka 集群的掌控程度。</li><li>滞后：由于它有自己的发布周期，因此是否能及时地包含最新版本的 Kafka 就成为了一个问题。</li></ul><br><ul><li><strong>如果需要快速地搭建消息引擎系统，或者你需要搭建的是多框架构成的数据平台且 Kafka 只是其中一个组件，那么我推荐你使用这些大数据云公司提供的 Kafka。</strong></li></ul><br><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>Apache Kafka，也称社区版 Kafka。优势在于迭代速度快，社区响应度高，使用它可以让你有更高的把控度；缺陷在于仅提供基础核心组件，缺失一些高级的特性。</li><li>Confluent Kafka，Confluent 公司提供的 Kafka。优势在于集成了很多高级特性且由 Kafka 原班人马打造，质量上有保证；缺陷在于相关文档资料不全，普及率较低，没有太多可供参考的范例。</li><li>CDH/HDP Kafka，大数据云公司提供的 Kafka，内嵌 Apache Kafka。优势在于操作简单，节省运维成本；缺陷在于把控度低，演进速度较慢。</li></ul><br><br><h2 id="05-聊聊Kafka的版本号"><a href="#05-聊聊Kafka的版本号" class="headerlink" title="05 | 聊聊Kafka的版本号"></a>05 | 聊聊Kafka的版本号</h2><ul><li>评判某 Kafka 版本是不是满足业务需求，就需要了解各个版本之间的差异和功能变化</li></ul><br><h3 id="Kafka-版本命名"><a href="#Kafka-版本命名" class="headerlink" title="Kafka 版本命名"></a>Kafka 版本命名</h3><ul><li>kafka-2.11-2.1.1<ul><li>前面的版本号是编译 Kafka 源代码的 Scala 编译器版本。（Kafka 服务器端的代码完全由 Scala 语言编写）</li><li>真正的 Kafka 版本号实际上是 2.1.1<ul><li>前面的 2 表示大版本号，即 Major Version；中间的 1 表示小版本号或次版本号，即 Minor Version；最后的 1 表示修订版本号，也就是 Patch 号。</li></ul></li></ul></li></ul><ul><li>Kafka 社区在发布 1.0.0 版本后特意写过一篇文章，宣布 Kafka 版本命名规则正式从 4 位演进到 3 位，比如 0.11.0.0 版本就是 4 位版本号。<ul><li>假设碰到的 Kafka 版本是 0.10.2.2，你现在就知道了它的大版本是 0.10，小版本是 2，总共打了两个大的补丁，Patch 号是 2。</li></ul></li></ul><br><h3 id="Kafka-版本演进"><a href="#Kafka-版本演进" class="headerlink" title="Kafka 版本演进"></a>Kafka 版本演进</h3><ul><li>Kafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0，其中的小版本和 Patch 版本很多。</li></ul><br><ul><li>0.7 版本<ul><li>最早开源时的“上古”版本。这个版本只提供了最基础的消息队列功能，甚至连副本机制都没有</li></ul></li><li>0.8<ul><li>正式引入了<strong>副本机制</strong>，至此 Kafka 成为了一个真正意义上完备的分布式高可靠消息队列解决方案。有了副本备份机制，Kafka 就能够比较好地做到消息无丢失。那时候生产和消费消息使用的还是老版本的客户端 API，所谓的老版本是指当你用它们的 API 开发生产者和消费者应用时，你需要指定 ZooKeeper 的地址而非 Broker 的地址。</li><li>老版本客户端有很多的问题，特别是生产者 API，它默认使用同步方式发送消息，可以想见其吞吐量一定不会太高。虽然它也支持异步的方式，但实际场景中可能会造成消息的丢失，因此 0.8.2.0 版本社区引入了<strong>新版本 Producer API</strong>，即需要指定 Broker 地址的 Producer。</li><li>国内依然有少部分用户在使用 0.8.1.1、0.8.2 版本。<strong>建议是尽量使用比较新的版本。如果不能升级大版本，也建议至少要升级到 0.8.2.2 这个版本，因为该版本中老版本消费者 API 是比较稳定的。另外即使升到了 0.8.2.2，也不要使用新版本 Producer API，此时它的 Bug 还非常多。</strong></li></ul></li><li>0.9.0.0 版本<ul><li>2015 年 11 月，社区正式发布了 0.9.0.0 版本。</li><li>0.9 大版本增加了基础的安全认证 / 权限功能，同时使用 Java 重写了新版本消费者 API，另外还引入了 Kafka Connect 组件用于实现高性能的数据抽取。</li><li><strong>新版本 Producer API 在这个版本中算比较稳定了</strong>。</li></ul></li><li>0.10.0.0<ul><li>0.10.0.0 是里程碑式的大版本，因为该版本<strong>引入了 Kafka Streams</strong>。从这个版本起，Kafka 正式升级成分布式流处理平台，虽然此时的 Kafka Streams 还基本不能线上部署使用。</li><li><strong>如果你依然在使用 0.10 大版本，我强烈建议你至少升级到 0.10.2.2 然后使用新版本 Consumer API。还有个事情不得不提，0.10.2.2 修复了一个可能导致 Producer 性能降低的 Bug。基于性能的缘故你也应该升级到 0.10.2.2。</strong></li></ul></li><li>0.11.0.0 版本<ul><li>2017 年 6 月，社区发布了 0.11.0.0 版本，引入了两个重量级的功能变更：一个是提供幂等性 Producer API 以及事务（Transaction） API；另一个是对 Kafka 消息格式做了重构。</li></ul></li></ul><br><ul><li>不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致，否则你将损失很多 Kafka 为你提供的性能优化收益。</li></ul><br><br><br><h1 id="Kafka的基本使用-3讲"><a href="#Kafka的基本使用-3讲" class="headerlink" title="Kafka的基本使用 (3讲)"></a>Kafka的基本使用 (3讲)</h1><h2 id="06-Kafka线上集群部署方案怎么做？"><a href="#06-Kafka线上集群部署方案怎么做？" class="headerlink" title="06 | Kafka线上集群部署方案怎么做？"></a>06 | Kafka线上集群部署方案怎么做？</h2><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="60%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;开篇词-1讲&quot;&gt;&lt;a href=&quot;#开篇词-1讲&quot; class=&quot;headerlink&quot; title=&quot;开篇词 (1讲)&quot;&gt;&lt;/a&gt;开篇词 (1讲)&lt;/h1&gt;&lt;h2 id=&quot;开篇词-为什么要学习Kafka？&quot;&gt;&lt;a href=&quot;#开篇词-为什么要学习Kafka？&quot;</summary>
      
    
    
    
    <category term="MQ" scheme="https://ratears.github.io/dev.ratears.life/Categories/MQ/"/>
    
    <category term="Kafka" scheme="https://ratears.github.io/dev.ratears.life/Categories/MQ/Kafka/"/>
    
    
    <category term="Kafka" scheme="https://ratears.github.io/dev.ratears.life/Tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>《MySQL 8.0详解与实战》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8AMySQL-8-0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8AMySQL-8-0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/</id>
    <published>2022-10-24T03:00:34.000Z</published>
    <updated>2022-10-24T03:00:34.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据库选型"><a href="#数据库选型" class="headerlink" title="数据库选型"></a>数据库选型</h1><h2 id="SQL-VS-NOSQL"><a href="#SQL-VS-NOSQL" class="headerlink" title="SQL VS NOSQL"></a>SQL VS NOSQL</h2><table><thead><tr><th align="center">类型</th><th align="center">示例</th><th align="left">特点</th><th align="left">适用场景</th></tr></thead><tbody><tr><td align="center">SQL</td><td align="center">MySQL<br>Oracle<br>SQLServer<br>PostGreSQL</td><td align="left">数据结构化存储在二维表格中。<br/>支持事务的 ACID 特性。<br/>支持使用SQL语言对存储在其中的数据进行操作</td><td align="left">数据之间存在着一定关系，需要关联查询数据的场景。<br/>需要事务支持的业务场景。<br/>需要使用SQL语言灵活操作数据的场景。</td></tr><tr><td align="center">NOSQL</td><td align="center">HBase<br>MongoDB<br>Redis<br>Hadoop</td><td align="left">存储结构灵活，没有固定的存储结构<br/>对事务的支持比较弱，但对数据的并发处理性能高<br/>大多不使用SQL语言操作数据</td><td align="left">数据结构不固定的场景<br/>对事务要求不高，但读写并发比较大的场景。<br/>对数据处理操作比较简单的场景</td></tr></tbody></table><br><br><h2 id="关系数据库选型原则"><a href="#关系数据库选型原则" class="headerlink" title="关系数据库选型原则"></a>关系数据库选型原则</h2><ul><li><p>数据库使用的广泛性</p><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4hxh96wd6lc0.webp" width="80%"></li><li><p>数据库的可扩展性</p><ul><li>支持基于二进制日志的逻辑复制</li><li>存在多种第三方数据库中间件，支持读写分离，分库分表</li></ul></li><li><p>数据库的安全性和稳定性</p><ul><li>MySQL主从复制集群可达到99%的可用性</li><li>配合主从复制高可用架构，可达到99%的可用性</li><li>支持对存储在MySQL的数据，进行分级安全控制</li></ul></li><li><p>数据库所支持的系统</p><ul><li>支持Linux操作系统</li><li>支持windows操作系统</li></ul></li><li><p>数据库的使用成本</p><ul><li>社区版本免费</li><li>使用人员众多，社区活跃，可以方便获取技术支持</li></ul></li></ul><br><br><h2 id="MySQL-8-x-的安装"><a href="#MySQL-8-x-的安装" class="headerlink" title="MySQL 8.x 的安装"></a>MySQL 8.x 的安装</h2><ul><li>服务器环境：CentOS 7 </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（1）下载mysql的安装包</span></span><br><span class="line">[root@localhost ~]# cd /install/</span><br><span class="line">[root@localhost install]# wget https://cdn.mysql.com//Downloads/MySQL-8.0/mysql-8.0.31-el7-x86_64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（2）解压</span></span><br><span class="line">[root@localhost install]# tar -zxvf mysql-8.0.31-el7-x86_64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（3）移动mysql的位置，创建软连接（便于管理）</span></span><br><span class="line">[root@localhost install]# mv mysql-8.0.31-el7-x86_64 /usr/local/</span><br><span class="line">[root@localhost install]# cd /usr/local/</span><br><span class="line">[root@localhost local]# ln -s mysql-8.0.31-el7-x86_64/ mysql</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（4）配置mysql</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先备份原 /etc/my.cnf 文件</span></span><br><span class="line">[root@localhost mysql]# cp /etc/my.cnf /etc/my.cnf.bak</span><br><span class="line">[root@localhost mysql]# vim /etc/my.cnf</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line">[client]</span><br><span class="line">port            = 3306</span><br><span class="line">socket          = /usr/local/mysql/data/mysql.sock</span><br><span class="line">[mysqld]</span><br><span class="line"># Skip #</span><br><span class="line">skip_name_resolve              = 1</span><br><span class="line">skip_external_locking          = 1 </span><br><span class="line">skip_symbolic_links     = 1</span><br><span class="line"># GENERAL #</span><br><span class="line">user = mysql</span><br><span class="line">default_storage_engine = InnoDB</span><br><span class="line">character-set-server = utf8</span><br><span class="line">socket  = /usr/local/mysql/data/mysql.sock</span><br><span class="line">pid_file = /usr/local/mysql/data/mysqld.pid</span><br><span class="line">basedir = /usr/local/mysql</span><br><span class="line">port = 3306</span><br><span class="line">bind-address = 0.0.0.0</span><br><span class="line">explicit_defaults_for_timestamp = off</span><br><span class="line">sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</span><br><span class="line">#read_only=on</span><br><span class="line"># MyISAM #</span><br><span class="line">key_buffer_size                = 32M</span><br><span class="line">#myisam_recover                 = FORCE,BACKUP</span><br><span class="line"></span><br><span class="line"># undo log #</span><br><span class="line">innodb_undo_directory = /usr/local/mysql/undo</span><br><span class="line">innodb_undo_tablespaces = 8</span><br><span class="line"></span><br><span class="line"># SAFETY #</span><br><span class="line">max_allowed_packet             = 100M</span><br><span class="line">max_connect_errors             = 1000000</span><br><span class="line">sysdate_is_now                 = 1</span><br><span class="line">#innodb = FORCE</span><br><span class="line">#innodb_strict_mode = 1</span><br><span class="line">secure-file-priv=&#x27;/tmp&#x27;</span><br><span class="line">default_authentication_plugin=&#x27;mysql_native_password&#x27;</span><br><span class="line"># Replice #</span><br><span class="line"> server-id = 1001</span><br><span class="line"> relay_log = mysqld-relay-bin</span><br><span class="line"> gtid_mode = on</span><br><span class="line"> enforce-gtid-consistency</span><br><span class="line"> log-slave-updates = on</span><br><span class="line"> master_info_repository =TABLE</span><br><span class="line"> relay_log_info_repository =TABLE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># DATA STORAGE #</span><br><span class="line"> datadir = /usr/local/mysql/data/</span><br><span class="line"> tmpdir = /tmp</span><br><span class="line"> </span><br><span class="line"># BINARY LOGGING #</span><br><span class="line"> log_bin = /usr/local/mysql/sql_log/mysql-bin</span><br><span class="line"> max_binlog_size = 1000M</span><br><span class="line"> binlog_format = row</span><br><span class="line"> binlog_expire_logs_seconds=86400</span><br><span class="line"># sync_binlog = 1</span><br><span class="line"></span><br><span class="line"> # CACHES AND LIMITS #</span><br><span class="line"> tmp_table_size                 = 32M</span><br><span class="line"> max_heap_table_size            = 32M</span><br><span class="line"> max_connections                = 4000</span><br><span class="line"> thread_cache_size              = 2048</span><br><span class="line"> open_files_limit               = 65535</span><br><span class="line"> table_definition_cache         = 4096</span><br><span class="line"> table_open_cache               = 4096</span><br><span class="line"> sort_buffer_size               = 2M</span><br><span class="line"> read_buffer_size               = 2M</span><br><span class="line"> read_rnd_buffer_size           = 2M</span><br><span class="line"># thread_concurrency             = 24</span><br><span class="line"> join_buffer_size = 1M</span><br><span class="line"># table_cache = 32768</span><br><span class="line"> thread_stack = 512k</span><br><span class="line"> max_length_for_sort_data = 16k</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> # INNODB #</span><br><span class="line"> innodb_flush_method            = O_DIRECT</span><br><span class="line"> innodb_log_buffer_size = 16M</span><br><span class="line"> innodb_flush_log_at_trx_commit = 2</span><br><span class="line"> innodb_file_per_table          = 1</span><br><span class="line"> innodb_buffer_pool_size        = 256M</span><br><span class="line"> #innodb_buffer_pool_instances = 8</span><br><span class="line"> innodb_stats_on_metadata = off</span><br><span class="line"> innodb_open_files = 8192</span><br><span class="line"> innodb_read_io_threads = 16</span><br><span class="line"> innodb_write_io_threads = 16</span><br><span class="line"> innodb_io_capacity = 20000</span><br><span class="line"> innodb_thread_concurrency = 0</span><br><span class="line"> innodb_lock_wait_timeout = 60</span><br><span class="line"> innodb_old_blocks_time=1000</span><br><span class="line"> innodb_use_native_aio = 1</span><br><span class="line"> innodb_purge_threads=1</span><br><span class="line"> innodb_change_buffering=all</span><br><span class="line"> innodb_log_file_size = 64M</span><br><span class="line"> innodb_log_files_in_group = 2</span><br><span class="line"> innodb_data_file_path  = ibdata1:256M:autoextend</span><br><span class="line"> </span><br><span class="line"> innodb_rollback_on_timeout=on</span><br><span class="line"> # LOGGING #</span><br><span class="line"> log_error                      = /usr/local/mysql/sql_log/mysql-error.log</span><br><span class="line"> # log_queries_not_using_indexes  = 1</span><br><span class="line"> # slow_query_log                 = 1</span><br><span class="line">  slow_query_log_file            = /usr/local/mysql/sql_log/slowlog.log</span><br><span class="line"></span><br><span class="line"> # TimeOut #</span><br><span class="line"> #interactive_timeout = 30</span><br><span class="line"> #wait_timeout        = 30</span><br><span class="line"> #net_read_timeout = 60</span><br><span class="line"></span><br><span class="line">[mysqldump]</span><br><span class="line">quick</span><br><span class="line">max_allowed_packet = 100M</span><br><span class="line"></span><br><span class="line">[mysql]</span><br><span class="line">no-auto-rehash</span><br><span class="line"># Remove the next comment character if you are not familiar with SQL</span><br><span class="line">#safe-updates</span><br><span class="line"></span><br><span class="line">[myisamchk]</span><br><span class="line">key_buffer_size = 256M</span><br><span class="line">sort_buffer_size = 256M</span><br><span class="line">read_buffer = 2M</span><br><span class="line">write_buffer = 2M</span><br><span class="line"></span><br><span class="line">[mysqlhotcopy]</span><br><span class="line">interactive-timeout</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（5）创建管理mysql的用户mysql</span></span><br><span class="line">[root@localhost mysql]# useradd mysql</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（6）创建mysql相关数据目录，并修改文件权限</span></span><br><span class="line">[root@localhost mysql]# mkdir data sql_log undo</span><br><span class="line">[root@localhost mysql]# chown -R mysql:mysql data sql_log undo</span><br><span class="line">[root@localhost mysql]# ll</span><br><span class="line">total 300</span><br><span class="line">drwxr-xr-x.  2  7161 31415   4096 Sep 14 01:50 bin</span><br><span class="line">drwxr-xr-x.  2 mysql mysql      6 Oct 24 13:43 data</span><br><span class="line">drwxr-xr-x.  2  7161 31415     55 Sep 14 01:50 docs</span><br><span class="line">drwxr-xr-x.  3  7161 31415   4096 Sep 14 01:50 include</span><br><span class="line">drwxr-xr-x.  6  7161 31415    201 Sep 14 01:50 lib</span><br><span class="line">-rw-r--r--.  1  7161 31415 287627 Sep 14 00:15 LICENSE</span><br><span class="line">drwxr-xr-x.  4  7161 31415     30 Sep 14 01:50 man</span><br><span class="line">-rw-r--r--.  1  7161 31415    666 Sep 14 00:15 README</span><br><span class="line">drwxr-xr-x. 28  7161 31415   4096 Sep 14 01:50 share</span><br><span class="line">drwxr-xr-x.  2 mysql mysql      6 Oct 24 13:43 sql_log</span><br><span class="line">drwxr-xr-x.  2  7161 31415     77 Sep 14 01:50 support-files</span><br><span class="line">drwxr-xr-x.  2 mysql mysql      6 Oct 24 13:43 undo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（7）配置mysql的环境变量</span></span><br><span class="line">[root@localhost mysql]# vim /etc/profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 /etc/profile 文件末尾添加如下内容</span></span><br><span class="line">export PATH=$PATH:/usr/local/mysql/bin</span><br><span class="line"></span><br><span class="line">[root@localhost mysql]# source /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（8）初始化mysql数据库</span></span><br><span class="line">[root@localhost mysql]# mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">验证：数据库初始化成功后，会在data目录下有相关文件生成</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（9）拷贝数据库启动脚本</span></span><br><span class="line">[root@localhost mysql]# cp support-files/mysql.server /etc/init.d/mysqld</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">至此，mysql数据库安装完成</span></span><br></pre></td></tr></table></figure><br><br><h2 id="MySQL-启动"><a href="#MySQL-启动" class="headerlink" title="MySQL 启动"></a>MySQL 启动</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql]# /etc/init.d/mysqld start</span><br><span class="line">Starting MySQL.. SUCCESS!</span><br><span class="line"></span><br><span class="line"># 获取mysql的初始密码</span><br><span class="line">[root@localhost mysql]# grep password sql_log/mysql-error.log</span><br><span class="line"></span><br><span class="line"># 登录mysql后，修改mysql的密码</span><br><span class="line">mysql&gt; alter user user() identified by &#x27;root&#x27;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><br><br><br><h1 id="数据库设计"><a href="#数据库设计" class="headerlink" title="数据库设计"></a>数据库设计</h1><ul><li>业务分析    =》    逻辑设计    =》    数据类型    =》    对象命名    =》 建立库表</li></ul><h2 id="逻辑设计"><a href="#逻辑设计" class="headerlink" title="逻辑设计"></a>逻辑设计</h2><h3 id="宽表模式存在的问题"><a href="#宽表模式存在的问题" class="headerlink" title="宽表模式存在的问题"></a>宽表模式存在的问题</h3><ul><li>宽表模式：指把所有需求字段设计在一张表中</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3dkqourzzp40.webp" width="70%"><br><br><h4 id="数据冗余"><a href="#数据冗余" class="headerlink" title="数据冗余"></a>数据冗余</h4><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.693sty7axdk0.webp" width="80%"><br><ul><li>相同数据在一个表中出现了多次（增加数据占用空间）</li><li>需要对数据进行多次维护（如果讲师的职位发生了变化，就需要对多条数据进行维护，如果有数据没有维护，就会导致数据不一致）</li></ul><br><br><h4 id="宽表模式的应用场景"><a href="#宽表模式的应用场景" class="headerlink" title="宽表模式的应用场景"></a>宽表模式的应用场景</h4><ul><li>配合列存储的数据报表应用</li></ul><br><br><h2 id="数据库设计范式"><a href="#数据库设计范式" class="headerlink" title="数据库设计范式"></a>数据库设计范式</h2><ul><li>第一范式：要求有主键，并且要求每一个字段原子性不可再分</li><li>第二范式：表中必须存在业务主键，并且非主键全部依赖于业务主键</li><li>第三范式：表中的非主键列之间不能相互依赖</li></ul><br><br><ul><li>反反范式化设计<ul><li>范式化设计存在的问题：为了满足范式化设计要求，我们对表拆分的很细。但是在查询时候关联的表会很多，影响性能</li><li>为了提高查询性能，我们需要反范式化设计</li></ul></li></ul><br><br><h2 id="物理设计"><a href="#物理设计" class="headerlink" title="物理设计"></a>物理设计</h2><h3 id="MySQL常见的存储引擎"><a href="#MySQL常见的存储引擎" class="headerlink" title="MySQL常见的存储引擎"></a>MySQL常见的存储引擎</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.2pqx87bjieq0.webp" width="80%"><br><br><h3 id="InnoDB存储引擎的特点"><a href="#InnoDB存储引擎的特点" class="headerlink" title="InnoDB存储引擎的特点"></a>InnoDB存储引擎的特点</h3><ul><li>事物型存储引擎支持ACID</li><li>数据按主键聚集存储</li><li>支持行级锁及MVCC</li><li>支持Btree和自适应Hash索引</li><li>支持全文和空间索引</li></ul><br><br><h3 id="整数类型"><a href="#整数类型" class="headerlink" title="整数类型"></a>整数类型</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.75n135ulfk00.webp" width="80%"><br><br><h3 id="实数类型"><a href="#实数类型" class="headerlink" title="实数类型"></a>实数类型</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4d7mn2i88vq0.webp" width="80%"><br><br><h3 id="常用时间类型"><a href="#常用时间类型" class="headerlink" title="常用时间类型"></a>常用时间类型</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5e3m2d5s8yc0.webp" width="80%"><br><br><h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.618wwafqys00.webp" width="80%"><br><br><h3 id="选择合适的数据类型"><a href="#选择合适的数据类型" class="headerlink" title="选择合适的数据类型"></a>选择合适的数据类型</h3><ul><li>优先选择符合存储数据需求的最小数据类型</li><li>谨慎使用ENUM,TEXT字符串类型</li><li>同财务相关的数据类型，必须使用decimal类型</li></ul><br><br><h3 id="数据库对象命名原则"><a href="#数据库对象命名原则" class="headerlink" title="数据库对象命名原则"></a>数据库对象命名原则</h3><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.6bx7vkwrtgc0.webp" width="60%"><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.58c8x2q3kq80.webp" width="60%"><br><br><br><h1 id="MySQL-访问数据库"><a href="#MySQL-访问数据库" class="headerlink" title="MySQL 访问数据库"></a>MySQL 访问数据库</h1><h2 id="MySQL-访问异常处理"><a href="#MySQL-访问异常处理" class="headerlink" title="MySQL 访问异常处理"></a>MySQL 访问异常处理</h2><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.6si7f2uku6w0.webp" width="80%"><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4zrntdxrjtk0.webp" width="80%"><br><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><ol><li>数据类型这块还需要加强一下呢</li></ol></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="80%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数据库选型&quot;&gt;&lt;a href=&quot;#数据库选型&quot; class=&quot;headerlink&quot; title=&quot;数据库选型&quot;&gt;&lt;/a&gt;数据库选型&lt;/h1&gt;&lt;h2 id=&quot;SQL-VS-NOSQL&quot;&gt;&lt;a href=&quot;#SQL-VS-NOSQL&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="database" scheme="https://ratears.github.io/dev.ratears.life/Categories/database/"/>
    
    <category term="MySQL" scheme="https://ratears.github.io/dev.ratears.life/Categories/database/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://ratears.github.io/dev.ratears.life/Tags/MySQL/"/>
    
    <category term="database" scheme="https://ratears.github.io/dev.ratears.life/Tags/database/"/>
    
  </entry>
  
  <entry>
    <title>《扛得住的MySQL数据库架构》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8A%E6%89%9B%E5%BE%97%E4%BD%8F%E7%9A%84MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%B6%E6%9E%84%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8A%E6%89%9B%E5%BE%97%E4%BD%8F%E7%9A%84MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%B6%E6%9E%84%E3%80%8Bstudy-notes/</id>
    <published>2022-10-18T03:17:42.000Z</published>
    <updated>2022-10-18T03:17:42.000Z</updated>
    
    <content type="html"><![CDATA[<br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="60%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;br&gt;

&lt;br&gt;

&lt;br&gt;

&lt;h1 id=&quot;学习备注&quot;&gt;&lt;a href=&quot;#学习备注&quot; class=&quot;headerlink&quot; title=&quot;学习备注&quot;&gt;&lt;/a&gt;学习备注&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure cla</summary>
      
    
    
    
    <category term="database" scheme="https://ratears.github.io/dev.ratears.life/Categories/database/"/>
    
    <category term="MySQL" scheme="https://ratears.github.io/dev.ratears.life/Categories/database/MySQL/"/>
    
    
    <category term="MySQL" scheme="https://ratears.github.io/dev.ratears.life/Tags/MySQL/"/>
    
    <category term="database" scheme="https://ratears.github.io/dev.ratears.life/Tags/database/"/>
    
  </entry>
  
  <entry>
    <title>《Nginx 核心知识 150 讲》study notes</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E3%80%8ANginx-%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86-150-%E8%AE%B2%E3%80%8Bstudy-notes/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E3%80%8ANginx-%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86-150-%E8%AE%B2%E3%80%8Bstudy-notes/</id>
    <published>2022-10-06T15:07:51.000Z</published>
    <updated>2022-10-06T15:07:51.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="初识Nginx"><a href="#初识Nginx" class="headerlink" title="初识Nginx"></a>初识Nginx</h1><h2 id="Nginx的三个主要应用场景"><a href="#Nginx的三个主要应用场景" class="headerlink" title="Nginx的三个主要应用场景"></a>Nginx的三个主要应用场景</h2><ul><li><p>静态资源服务</p><ul><li>通过本地文件系统提供服务</li></ul></li><li><p>反向代理服务</p><ul><li>Nginx的强大性能</li><li>缓存</li><li>负载均衡</li></ul></li><li><p>API服务</p><ul><li>OpenResty</li></ul></li></ul><br><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4ie7urbi69s0.webp" width="60%"><br><br><h2 id="Nginx出现的历史背景"><a href="#Nginx出现的历史背景" class="headerlink" title="Nginx出现的历史背景"></a>Nginx出现的历史背景</h2><ul><li>互联网的数据量快速增长<ul><li>互联网的快速普及</li><li>全球化</li><li>物联网</li></ul></li><li>摩尔定律：性能提升</li><li>低效的Apache<ul><li>一个连接对应一个进程</li></ul></li></ul><br><br><h2 id="Nginx的5个主要优点"><a href="#Nginx的5个主要优点" class="headerlink" title="Nginx的5个主要优点"></a>Nginx的5个主要优点</h2><p>（1）高并发，高性能</p><p>（2）可扩展性好</p><p>（3）高可靠性</p><p>（4）热部署</p><p>（5）BSD许可证</p><br><br><h2 id="Nginx的4个主要组成部分"><a href="#Nginx的4个主要组成部分" class="headerlink" title="Nginx的4个主要组成部分"></a>Nginx的4个主要组成部分</h2><p>（1）Nginx 二进制可执行文件</p><blockquote><p>由各模块源码编译出的一个文件</p></blockquote><p>（2）Nginx.conf 配置文件</p><blockquote><p>控制 Nginx 的行为</p></blockquote><p>（3）access.log 访问日志</p><blockquote><p>记录每一条 http 请求信息</p></blockquote><p>（4）error.log 错误日志</p><blockquote><p>定位问题</p></blockquote><br><br><h2 id="Nginx的版本发布历史"><a href="#Nginx的版本发布历史" class="headerlink" title="Nginx的版本发布历史"></a>Nginx的版本发布历史</h2><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.cmiy02n409c.webp" width="60%"><br><ul><li>开源免费的Nginx与商业版Nginx Plus</li><li>阿里巴巴的Tengine</li><li>免费OpenResty与商业版OpenResty</li></ul><br><br><h2 id="编译Nginx"><a href="#编译Nginx" class="headerlink" title="编译Nginx"></a>编译Nginx</h2><ul><li>如果要扩展第三方功能，可以使用编译方式安装nginx</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（1）下载nginx</span></span><br><span class="line">wget https://nginx.org/download/nginx-1.22.0.tar.gz</span><br><span class="line"></span><br><span class="line">tar -zxvf nginx-1.22.0.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装相关依赖库</span></span><br><span class="line">yum install -y pcre pcre-devel gcc zlib zlib-devel</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（2）编译安装</span></span><br><span class="line">[root@bogon nginx-1.22.0]# ./configure --prefix=/usr/local/nginx</span><br><span class="line"></span><br><span class="line">[root@bogon nginx-1.22.0]# make</span><br><span class="line"></span><br><span class="line">[root@bogon nginx-1.22.0]# make install</span><br></pre></td></tr></table></figure><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><ol><li>课程介绍中的问题</li><li></li></ol></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="60%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;初识Nginx&quot;&gt;&lt;a href=&quot;#初识Nginx&quot; class=&quot;headerlink&quot; title=&quot;初识Nginx&quot;&gt;&lt;/a&gt;初识Nginx&lt;/h1&gt;&lt;h2 id=&quot;Nginx的三个主要应用场景&quot;&gt;&lt;a href=&quot;#Nginx的三个主要应用场景&quot; cla</summary>
      
    
    
    
    <category term="Nginx" scheme="https://ratears.github.io/dev.ratears.life/Categories/Nginx/"/>
    
    
    <category term="Nginx" scheme="https://ratears.github.io/dev.ratears.life/Tags/Nginx/"/>
    
    <category term="study-notes" scheme="https://ratears.github.io/dev.ratears.life/Tags/study-notes/"/>
    
  </entry>
  
  <entry>
    <title>Nexus搭建Maven私服</title>
    <link href="https://ratears.github.io/dev.ratears.life/Nexus%E6%90%AD%E5%BB%BAMaven%E7%A7%81%E6%9C%8D/"/>
    <id>https://ratears.github.io/dev.ratears.life/Nexus%E6%90%AD%E5%BB%BAMaven%E7%A7%81%E6%9C%8D/</id>
    <published>2022-09-28T10:38:46.000Z</published>
    <updated>2022-09-28T10:38:46.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Nexus-安装"><a href="#Nexus-安装" class="headerlink" title="Nexus 安装"></a>Nexus 安装</h1><ul><li><a class="link"   href="https://www.sonatype.com/thanks/repo-oss" >Nexus下载<i class="fas fa-external-link-alt"></i></a></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（1）上传 下载的软件到目录 /app</span></span><br><span class="line">[root@bu2-vm-svr-67 app]# ll</span><br><span class="line">total 212392</span><br><span class="line">-rw-r--r-- 1 root root 217484934 Sep 28 14:06 nexus-3.42.0-01-unix.tar.gz</span><br><span class="line"></span><br><span class="line">[root@bu2-vm-svr-67 app]# tar -zxvf nexus-3.42.0-01-unix.tar.gz</span><br><span class="line"></span><br><span class="line">[root@bu2-vm-svr-67 app]# ll</span><br><span class="line">total 212400</span><br><span class="line">drwxr-xr-x 10 root root      4096 Sep 28 18:55 nexus-3.42.0-01</span><br><span class="line">-rw-r--r--  1 root root 217484934 Sep 28 14:06 nexus-3.42.0-01-unix.tar.gz</span><br><span class="line">drwxr-xr-x  3 root root      4096 Sep 28 18:55 sonatype-work</span><br><span class="line"></span><br><span class="line">[root@bu2-vm-svr-67 app]# vi /app/nexus-3.42.0-01/bin/nexus</span><br><span class="line"></span><br><span class="line">run_as_root=false</span><br><span class="line"></span><br><span class="line">[root@bu2-vm-svr-67 app]# vi /app/nexus-3.42.0-01/etc/nexus-default.properties</span><br><span class="line"></span><br><span class="line">application-port=7071</span><br><span class="line"></span><br><span class="line">[root@bu2-vm-svr-67 app]# /app/nexus-3.42.0-01/bin/nexus start</span><br><span class="line">Starting nexus</span><br></pre></td></tr></table></figure><br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="60%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Nexus-安装&quot;&gt;&lt;a href=&quot;#Nexus-安装&quot; class=&quot;headerlink&quot; title=&quot;Nexus 安装&quot;&gt;&lt;/a&gt;Nexus 安装&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&quot;link&quot;   href=&quot;https://www.sona</summary>
      
    
    
    
    <category term="Maven" scheme="https://ratears.github.io/dev.ratears.life/Categories/Maven/"/>
    
    <category term="Nexus" scheme="https://ratears.github.io/dev.ratears.life/Categories/Maven/Nexus/"/>
    
    
    <category term="Nexus" scheme="https://ratears.github.io/dev.ratears.life/Tags/Nexus/"/>
    
    <category term="Maven" scheme="https://ratears.github.io/dev.ratears.life/Tags/Maven/"/>
    
  </entry>
  
  <entry>
    <title>浅析 —— 同步异步&amp;阻塞非阻塞</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E6%B5%85%E6%9E%90-%E2%80%94%E2%80%94-%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5-%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E6%B5%85%E6%9E%90-%E2%80%94%E2%80%94-%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5-%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E/</id>
    <published>2022-09-19T14:14:02.000Z</published>
    <updated>2022-09-19T14:14:02.000Z</updated>
    
    <content type="html"><![CDATA[<br><br><br><h1 id="学习备注"><a href="#学习备注" class="headerlink" title="学习备注"></a>学习备注</h1><blockquote><p>1</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">&amp;emsp;</span><span class="symbol">&amp;emsp;</span></span><br></pre></td></tr></table></figure><br><br><br><img src="" width="60%"><br>]]></content>
    
    
      
      
    <summary type="html">&lt;br&gt;

&lt;br&gt;

&lt;br&gt;

&lt;h1 id=&quot;学习备注&quot;&gt;&lt;a href=&quot;#学习备注&quot; class=&quot;headerlink&quot; title=&quot;学习备注&quot;&gt;&lt;/a&gt;学习备注&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure cla</summary>
      
    
    
    
    <category term="Operating-Systems" scheme="https://ratears.github.io/dev.ratears.life/Categories/Operating-Systems/"/>
    
    <category term="I/O" scheme="https://ratears.github.io/dev.ratears.life/Categories/Operating-Systems/I-O/"/>
    
    
    <category term="Operating-Systems" scheme="https://ratears.github.io/dev.ratears.life/Tags/Operating-Systems/"/>
    
    <category term="communication-mechanism" scheme="https://ratears.github.io/dev.ratears.life/Tags/communication-mechanism/"/>
    
  </entry>
  
  <entry>
    <title>浅析 I/O（3）—— I/O模型</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E6%B5%85%E6%9E%90-I-O%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94-I-O%E6%A8%A1%E5%9E%8B/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E6%B5%85%E6%9E%90-I-O%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94-I-O%E6%A8%A1%E5%9E%8B/</id>
    <published>2022-09-19T14:06:09.000Z</published>
    <updated>2022-09-19T14:06:09.000Z</updated>
    
    <content type="html"><![CDATA[<br><ul><li>网络通信中，最底层的就是内核中的网络 I/O 模型了。</li></ul><blockquote><p>随着技术的发展，操作系统内核的网络模型衍生出了<strong>五种 I/O 模型</strong>，《UNIX网络编程》一书将这五种 I/O 模型分为 <code>阻塞式 I/O</code>、<code>非阻塞式 I/O</code>、<code>I/O 复用</code>、<code>信号驱动式 I/O</code> 和 <code>异步 I/O</code>。每一种 I/O 模型的出现，都是基于前一种 I/O 模型的优化升级。</p></blockquote><br><br><br><h1 id="①-阻塞IO模型"><a href="#①-阻塞IO模型" class="headerlink" title="① 阻塞IO模型"></a>① 阻塞IO模型</h1><ul><li>阻塞式 IO （Blocking IO）：应用进程从发起 IO 系统调用，至内核返回成功标识，这整个期间是处于阻塞状态的。</li></ul><blockquote><p>当应用A发起读取数据申请时，在内核数据没有准备好之前，应用A会一直处于等待数据状态，直到内核把数据准备好了交给应用A才结束。</p></blockquote><blockquote><p><strong>Tips：我们之前所学过的所有的套接字，默认都是阻塞方式。</strong></p></blockquote><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.7wrvgu36e5k.webp" width="75%"><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.qd7jcvl1as0.webp" width="75%"><ul><li>优点：开发相对简单，在阻塞期间，用户线程被挂起，挂起期间不会占用CPU资源；</li><li>缺点：<ul><li>1）连接利用率不高，内核如果没有响应数据，则该连接一直处于阻塞状态，占用连接资源</li><li>2）一个线程维护一个IO资源，当用大量并发请求时，需要创建等价的线程来处理请求，不适合用于高并发场景；</li></ul></li></ul><br><br><br><h1 id="②-非阻塞IO模型"><a href="#②-非阻塞IO模型" class="headerlink" title="② 非阻塞IO模型"></a>② 非阻塞IO模型</h1><ul><li>非阻塞式IO（Non-Blocking IO）：应用进程可以将 Socket 设置为非阻塞，这样应用进程在发起 IO 系统调用后，会立刻返回。应用进程可以轮询的发起 IO 系统调用，直到内核返回成功标识。</li></ul><blockquote><p>当应用A发起读取数据申请时，在内核数据没有准备好之前，应用A会一直处于等待数据状态，直到内核把数据准备好了交给应用A才结束。</p></blockquote><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.3utzrtza30.webp" width="70%"><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.79dq8pifksg0.webp" width="60%"><ul><li>优点：每次发起IO调用去内核获取数据时，在内核等待数据的过程中可以立即返回，用户线程不会被阻塞，实时性较好；</li><li>缺点：<ul><li>1）当用户线程A没有获取到数据时，不断轮询内核，查看是否有新的数据，占用大量CPU时间，效率不高；</li><li>2）和阻塞IO一样，一个线程维护一个IO资源，当用大量并发请求时，需要创建等价的线程来处理请求，不适合用于高并发场景；</li></ul></li></ul><br><br><br><h1 id="③-复用IO模型（IO多路复用模型）"><a href="#③-复用IO模型（IO多路复用模型）" class="headerlink" title="③ 复用IO模型（IO多路复用模型）"></a>③ 复用IO模型（IO多路复用模型）</h1><ul><li>IO 多路复用（IO Multiplexin）：可以将多个应用进程的 Socket 注册到一个 Select（多路复用器）上，然后使用一个进程来监听该 Select（该操作会阻塞），Select 会监听所有注册进来的 Socket。只要有一个 Socket 的数据准备好，就会返回该Socket。再由应用进程发起 IO 系统调用，来完成数据读取。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5bxxajmccj00.webp" width="60%"><br><br><p>&emsp;&emsp;如果在并发的环境下，可能会N个人向应用B发送消息，这种情况下我们的应用就必须创建多个线程去接收N个人发送过来的请求，每个请求都是一个独立的线程来处理；在并发量呈线性增长时，我们需要创建的线程数也随之而然的激增；</p><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4qf0gyqhcao0.webp" width="70%"><p>&emsp;&emsp;这种情况下应用B就需要创建N个线程去读取数据，同时又因为应用线程是不知道什么时候会有数据读取，为了保证消息能及时读取到，那么这些线程自己必须不断的向内核发送请求来读取数据（非阻塞式）；</p><p>&emsp;&emsp;这么多的线程不断请求数据，先不说服务器能不能扛得住这么多线程，就算扛得住那么很明显这种方式是不是太浪费资源了，线程是我们操作系统的宝贵资源，大量的线程用来去读取数据了，那么就意味着能做其它事情的线程就会少。</p><p>&emsp;&emsp;后来，有人就提出了一个思路，能不能提供一种方式，可以由一个线程监控多个网络请求（<strong>linux系统把所有网络请求以一个fd来标识，我们后面将称为fd即文件描述符</strong>），这样就可以只需要一个或几个线程就可以完成数据状态询问的操作，当有数据准备就绪之后再分配对应的线程去读取数据，这么做就可以节省出大量的线程资源出来，这个就是<strong>IO复用模型</strong>的思路。</p><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.4gods2kobxu0.webp" width="70%"><p>&emsp;&emsp;IO复用模型的思路就是系统提供了一种函数（select/poll/epoll）可以同时监控多个fd的操作，有了这个函数后，应用线程通过调用select函数就可以同时监控多个fd，如果select监听的fd都没有可读数据，<strong>select调用进程会被阻塞</strong>；而只要有任何一个fd准备就绪了，select函数就会返回可读状态，这时询问线程再去通知处理数据的线程，对应的线程此时再发起请求去读取内核中准备好的数据；</p><blockquote><p><strong>Tips：在IO复用模型下，允许单线程内处理多个IO请求；</strong></p></blockquote><br><br><ul><li><font color="red"><strong>Linux中IO复用的实现方式主要有select，poll和epoll</strong></font></li></ul><h2 id="1）select"><a href="#1）select" class="headerlink" title="1）select"></a>1）select</h2><ul><li><strong>线性轮询扫描所有的fd</strong>，不管他们是否活跃，监听的IO最大连接数不能多于FD_ SIZE（32位操作系统1024，64位操作系统2048）。</li><li>时间复杂度O(n)</li></ul><blockquote><p><strong>Tips：select方式仅仅知道有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），用户线程只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。</strong></p></blockquote><br><h2 id="2）poll"><a href="#2）poll" class="headerlink" title="2）poll"></a>2）poll</h2><ul><li>原理和select相似，poll底层需要分配一个pollfd结构数组，维护在内核中，它没有数量限制，但IO数量大，扫描线性性能下降。</li><li>时间复杂度O(n)</li></ul><br><h2 id="3）epoll"><a href="#3）epoll" class="headerlink" title="3）epoll"></a>3）epoll</h2><ul><li>用于代替poll和select，没有大小限制。<strong>epoll采用事件驱动代替了轮询</strong>，epoll会把哪个流发生了怎样的I/O事件通知用户线程，所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时用户线程对这些流的操作都是有意义的。（复杂度降低到了O(1)），另外epoll模型采用mmap内存映射实现内核与用户空间的消息传递，减少用户态和内核态数据传输的开销，epoll模型在Linux2.6后内核支持。</li><li>时间复杂度O(1)</li></ul><br><hr><ul><li><font color="red">select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符准备就绪，能够通知程序进行相应的读写操作。<strong>但select，poll，epoll本质上都是同步I/O</strong>，因为他们都需要在读写事件就绪后自己负责进行读写(一个个的处理)，也就是说这个读写过程是<strong>阻塞的</strong>，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。</font></li></ul><blockquote><p>Tips：epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现</p></blockquote><br><h2 id="复用IO模型小结"><a href="#复用IO模型小结" class="headerlink" title="复用IO模型小结"></a>复用IO模型小结</h2><ul><li>关于IO复用模型，下面这个例子可以很好的说明IO复用模型的原理：</li></ul><blockquote><p>某教室有10名学生和1名老师，这些学生上课会不停的提问，所以一个老师处理不了这么多的问题。那么学校为每个学生都配一名老师，也就是这个教室目前有10名老师。此后，只要有新的转校生，那么就会为这个学生专门分配一个老师，因为转校生也喜欢提问题。如果把以上例子中的学生比作客户端，那么老师就是负责进行数据交换的服务端。则该例子可以比作是多进程的方式。</p><p>后来有一天，来了一位具有超能力的老师，这位老师回答问题非常迅速，并且可以应对所有的问题。而这位老师采用的方式是学生提问前必须先举手，确认举手学生后在回答问题。则现在的情况就是IO复用。</p></blockquote><ul><li><strong>IO复用模型的优点</strong>：系统不必创建和维护大量的线程，只使用一个或几个线程来监听select选择器的操作，而一个选择器可同时处理成千上万个连接，大大减少了系统的开销；</li><li><strong>IO复用模型的缺点</strong>：select本质上还是同步阻塞模式；</li></ul><p>&emsp;&emsp;<strong>总结：</strong> 复用IO的基本思路就是通过select或poll、epoll来监控多fd ，来达到不必为每个fd创建一个对应的监控线程，从而减少线程资源创建的目的。<strong>复用IO模型的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。</strong></p><br><br><br><h1 id="④-信号驱动IO模型"><a href="#④-信号驱动IO模型" class="headerlink" title="④ 信号驱动IO模型"></a>④ 信号驱动IO模型</h1><ul><li>信号驱动 IO（Signal Driven IO）：可以为 Socket 开启信号驱动 IO 功能，应用进程需向内核注册一个信号处理程序，该操作并立即返回。当内核中有数据准备好，会发送一个信号给应用进程，应用进程便可以在信号处理程序中发起 IO 系统调用，来完成数据读取了。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.75x9qhoc2nk0.webp" width="60%"><br><br><p>&emsp;&emsp;当进程发起一个IO操作，系统调用sigaction执行一个信号处理函数，该函数向内核注册一个信号处理函数（回调函数），然后进程返回，并且不阻塞当前进程；当内核数据准备好时，内核使用信号（SIGIO）通知应用线程调用recvfrom来读取数据（运行回调函数）。</p><p>&emsp;&emsp;信号驱动IO它也可以看成是一种<strong>异步非阻塞IO</strong></p><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.1qy5yemvy6rk.webp" width="60%"><p>&emsp;&emsp;我们说信号驱动IO模型是一种异步非阻塞IO模型，指的是用户线程去内核空间请求数据时，直接注册一个信号处理函数，然后用户线程返回（异步），而内核空间接收到请求后，开始处理（此时并不会阻塞，内核空间可以同时接收多个请求，注册多个信号处理函数）；</p><p>&emsp;&emsp;但是，等到内核空间读取到数据之后，应用线程需要将数据从内核空间拷贝到用户空间，<strong>此时是用户线程是阻塞的；</strong>也就是说：<strong>应用程序将数据从内核态拷贝到用户态的过程是阻塞等待的，这是和异步IO的本质区别；</strong></p><br><br><br><h1 id="⑤-异步IO模型"><a href="#⑤-异步IO模型" class="headerlink" title="⑤ 异步IO模型"></a>⑤ 异步IO模型</h1><ul><li>异步 IO（Asynchronous IO）： 应用进程发起 IO 系统调用后，会立即返回。当内核中数据完全准备后，并且也复制到了用户空间，会产生一个信号来通知应用进程。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.448rjyvy1va0.webp" width="70%"><br><br><p>&emsp;&emsp;在前面几种IO模型中，应用线程要获取数据总是先发送请求到内核，然后进行如下处理：</p><blockquote><p>1）<strong>阻塞IO</strong>：应用线程等待内核响应数据，期间什么都不能做</p><p>2）<strong>非阻塞IO</strong>：应用线程立即响应，可以去处理其他事情，但需要不断轮询内核去获取数据</p><p>3）<strong>复用IO</strong>：采用IO复用机制，请求都先交给select函数，由应用线程调用select函数来轮询所有的请求，当有请求需要获取数据时，应用线程再去内核获取数据；</p><p>4）<strong>信号驱动IO</strong>：系统注册一个信号处理函数（回调函数），然后应用线程返回（不阻塞）；当内核中准备好数据后，应用线程需要把内核中的数据拷贝到用户空间，<strong>此时用户线程是阻塞的</strong>；</p></blockquote><p>&emsp;&emsp;在以上4种IO模型中，每次要去读取数据时都是事先发送请求询问内核是否有可读数据，然后再发起真正的读取数据请求；</p><p>&emsp;&emsp;在异步IO模型中，应用只需要向内核发送一个请求，告诉内核它要读取数据后即刻返回；内核收到请求后会建立一个信号联系，当数据准备就绪，<strong>内核会主动把数据从内核复制到用户空间</strong>（而信号驱动是告诉应用程序何时可以开始拷贝数据），异步IO模型真正的做到了完完全全的非阻塞；</p><blockquote><p>Tips：异步IO模型和前面模型最大的区别是：<strong>前4个都是阻塞的</strong>，需要自己把用户准备好的数据，去内核拷贝到用户空间。而全异步不同，用户线程完全不需要关心实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接去使用数据，它是最理想的模型。</p></blockquote><br><br><br><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;从上述五种 IO 模型可以看出，应用进程对内核发起 IO 系统调用后，内核会经过两个阶段来完成数据的传输：</p><ul><li>第一阶段：等待数据。即应用进程发起 IO 系统调用后，会一直等待数据；当有数据传入服务器，会将数据放入内核空间，此时数据准备好。</li><li>第二阶段：将数据从内核空间复制到用户空间，并返回给应用程序成功标识。</li></ul><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.1i7o657cwvsw.webp" width="60%"><p>&emsp;&emsp;前四种模型的第二阶段是相同的，都是处于阻塞状态，其主要区别在第一阶段。而异步 IO 模型则不同，应用进程在这两个阶段是完全不阻塞的。</p><table><thead><tr><th align="center">IO 模型</th><th align="center">第一阶段</th><th align="center">第二阶段</th></tr></thead><tbody><tr><td align="center">阻塞式IO</td><td align="center">阻塞</td><td align="center">阻塞</td></tr><tr><td align="center">非阻塞式IO</td><td align="center">非阻塞</td><td align="center">阻塞</td></tr><tr><td align="center">IO多路程复用</td><td align="center">阻塞（Select）</td><td align="center">阻塞</td></tr><tr><td align="center">信号驱动式IO</td><td align="center">异步</td><td align="center">阻塞</td></tr><tr><td align="center">异步IO</td><td align="center">异步</td><td align="center">异步</td></tr></tbody></table><br><br><br><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li>segmentfault：<a class="link"   href="https://segmentfault.com/a/1190000039898780" >浅聊Linux的五种IO模型<i class="fas fa-external-link-alt"></i></a></li><li>w3cjava：<a class="link"   href="https://www.w3cjava.com/e-book/operate-system/124699009.html" >五种IO模型：操作系统五种IO模型大全<i class="fas fa-external-link-alt"></i></a></li></ul><br>]]></content>
    
    
      
      
    <summary type="html">&lt;br&gt;

&lt;ul&gt;
&lt;li&gt;网络通信中，最底层的就是内核中的网络 I/O 模型了。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;随着技术的发展，操作系统内核的网络模型衍生出了&lt;strong&gt;五种 I/O 模型&lt;/strong&gt;，《UNIX网络编程》一书将这五种 I/O</summary>
      
    
    
    
    <category term="Operating-Systems" scheme="https://ratears.github.io/dev.ratears.life/Categories/Operating-Systems/"/>
    
    <category term="I/O" scheme="https://ratears.github.io/dev.ratears.life/Categories/Operating-Systems/I-O/"/>
    
    
    <category term="Operating-Systems" scheme="https://ratears.github.io/dev.ratears.life/Tags/Operating-Systems/"/>
    
    <category term="I/O" scheme="https://ratears.github.io/dev.ratears.life/Tags/I-O/"/>
    
  </entry>
  
  <entry>
    <title>浅析 I/O（2）—— I/O分类</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E6%B5%85%E6%9E%90-I-O%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94-I-O%E5%88%86%E7%B1%BB/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E6%B5%85%E6%9E%90-I-O%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94-I-O%E5%88%86%E7%B1%BB/</id>
    <published>2022-09-19T14:05:34.000Z</published>
    <updated>2022-09-19T14:05:34.000Z</updated>
    
    <content type="html"><![CDATA[<br><ul><li>通常用户进程中的一个完整IO分为两阶段：<strong>用户进程空间&lt;- -&gt;内核空间</strong>、**内核空间&lt;- -&gt;设备空间(磁盘、网络等)**。</li></ul><br><br><h1 id="网络IO-amp-磁盘IO"><a href="#网络IO-amp-磁盘IO" class="headerlink" title="网络IO &amp; 磁盘IO"></a>网络IO &amp; 磁盘IO</h1><p>&emsp;&emsp;IO从读取数据的来源分为<strong>内存IO</strong>、 <strong>网络IO</strong>和<strong>磁盘IO</strong>三种，通常我们说的IO指的是后两者(因为内存IO的读写速度比网络IO和磁盘IO快的多)。</p><p>&emsp;&emsp;I/O按照设备来分的话，分为两种：一种是网络I/O，也就是通过网络进行数据的拉取和输出。一种是磁盘I/O，主要是对磁盘进行读写工作。</p><table><thead><tr><th align="center">类型</th><th align="left">概念解释</th></tr></thead><tbody><tr><td align="center">网络IO</td><td align="left">等待网络数据到达网卡→把网卡中的数据读取到内核缓冲区，然后从内核缓冲区复制数据到进程空间</td></tr><tr><td align="center">磁盘IO</td><td align="left">把数据从磁盘中读取到内核缓冲区，然后从内核缓冲区复制数据到进程空间</td></tr></tbody></table><blockquote><p>Tips：<strong>由于CPU和内存的速度远远高于外部设备（网卡，磁盘等）的速度，所以在IO编程中，存在速度严重不匹配的问题。</strong></p></blockquote><br><br><h1 id="同步IO-amp-异步IO"><a href="#同步IO-amp-异步IO" class="headerlink" title="同步IO &amp; 异步IO"></a>同步IO &amp; 异步IO</h1><table><thead><tr><th align="center">类型</th><th align="left">概念解释</th></tr></thead><tbody><tr><td align="center">同步IO</td><td align="left">A调用B，B的处理是同步的，在处理完之前他不会通知A，只有处理完之后才会明确的通知A。<strong>B在没有处理完A的请求时不能处理其他请求；</strong></td></tr><tr><td align="center">异步IO</td><td align="left">A调用B，B的处理是异步的，B在接到请求后先告诉A我已经接到请求了，然后异步去处理，处理完之后通过回调等方式再通知A。<strong>B在处理A请求的同时，也可以接着处理其他人发送过来的请求；</strong></td></tr></tbody></table><p>&emsp;&emsp;同步和异步最大的区别就是被调用方的<strong>执行方式</strong>和<strong>返回时机</strong>。同步指的是被调用方做完事情之后再返回，异步指的是被调用方先返回，然后再做事情，做完之后再想办法通知调用方。</p><br><br><h1 id="阻塞IO-amp-非阻塞IO"><a href="#阻塞IO-amp-非阻塞IO" class="headerlink" title="阻塞IO &amp; 非阻塞IO"></a>阻塞IO &amp; 非阻塞IO</h1><table><thead><tr><th align="center">类型</th><th align="left">概念解释</th></tr></thead><tbody><tr><td align="center">非阻塞IO</td><td align="left">A调用B，A不用一直等着B的返回，先去忙别的事情了。</td></tr><tr><td align="center">阻塞IO</td><td align="left">A调用B，A一直等着B的返回，别的事情什么也不干。</td></tr></tbody></table><p>&emsp;&emsp;阻塞和非阻塞最大的区别就<strong>是在被调用方返回结果之前的这段时间内，调用方是否一直等待</strong>。阻塞指的是调用方一直等待别的事情什么都不做。非阻塞指的是调用方先去忙别的事情。</p><br><blockquote><p><strong><font color="red">Tips：同步IO和异步IO强调的是被调用方（B），阻塞IO和非阻塞IO强调的是调用方（A）；</font></strong></p></blockquote><br><br><br>]]></content>
    
    
      
      
    <summary type="html">&lt;br&gt;

&lt;ul&gt;
&lt;li&gt;通常用户进程中的一个完整IO分为两阶段：&lt;strong&gt;用户进程空间&amp;lt;- -&amp;gt;内核空间&lt;/strong&gt;、**内核空间&amp;lt;- -&amp;gt;设备空间(磁盘、网络等)**。&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;

&lt;br&gt;

&lt;h1 id=&quot;网络</summary>
      
    
    
    
    <category term="Operating-Systems" scheme="https://ratears.github.io/dev.ratears.life/Categories/Operating-Systems/"/>
    
    <category term="I/O" scheme="https://ratears.github.io/dev.ratears.life/Categories/Operating-Systems/I-O/"/>
    
    
    <category term="Operating-Systems" scheme="https://ratears.github.io/dev.ratears.life/Tags/Operating-Systems/"/>
    
    <category term="I/O" scheme="https://ratears.github.io/dev.ratears.life/Tags/I-O/"/>
    
  </entry>
  
  <entry>
    <title>浅析 I/O（1）—— 操作系统内存简介</title>
    <link href="https://ratears.github.io/dev.ratears.life/%E6%B5%85%E6%9E%90-I-O%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%AE%80%E4%BB%8B/"/>
    <id>https://ratears.github.io/dev.ratears.life/%E6%B5%85%E6%9E%90-I-O%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%AE%80%E4%BB%8B/</id>
    <published>2022-09-19T13:56:50.000Z</published>
    <updated>2022-09-19T13:56:50.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="操作系统的应用与内核"><a href="#操作系统的应用与内核" class="headerlink" title="操作系统的应用与内核"></a>操作系统的应用与内核</h1><p>&emsp;&emsp;现代计算机是由硬件和操作系统组成，我们的应用程序要操作硬件（如往磁盘上写数据），就需要先与内核交互，然后再由内核与硬件交互；</p><p>&emsp;&emsp;操作系统可以划分为：<strong>内核</strong>与<strong>应用</strong>两部分；</p><p>&emsp;&emsp;内核提供进程管理、内存管理、网络等底层功能，封装了与硬件交互的接口，通过系统调用提供给上层应用使用。</p><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/6a59c5e5-a44b-444d-b5de-22a47319e41a.5r3m1k43n280.webp" width="80%"><br><br><br><h1 id="内核空间与用户空间"><a href="#内核空间与用户空间" class="headerlink" title="内核空间与用户空间"></a>内核空间与用户空间</h1><p>&emsp;&emsp;现在操作系统都是采用虚拟地址空间，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间（内核空间），也有访问底层硬件设备的所有权限。</p><p>&emsp;&emsp;为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为<strong>内核空间</strong>，一部分为<strong>用户空间</strong>。内核空间是操作系统内核访问的区域，独立于普通的应用程序，是<strong>受保护的内存空间</strong>。用户空间是普通应用程序可访问的内存区域。</p><p>&emsp;&emsp;针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。</p><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.23luuh3fhlwg.webp" width="60%"><p>&emsp;&emsp;<strong>用户态的程序不能随意操作内核地址空间，即使用户的程序崩溃了，内核也不受影响。这样对操作系统具有一定的安全保护作用。</strong></p><br><br><br><h1 id="CPU指令等级"><a href="#CPU指令等级" class="headerlink" title="CPU指令等级"></a>CPU指令等级</h1><p>&emsp;&emsp;其实早期操作系统是不区分内核空间和用户空间的，但是应用程序能访问任意内存空间，如果程序不稳定常常把系统搞崩溃，比如清除操作系统的内存数据。后来觉得让应用程序随便访问内存太危险了，就按照CPU 指令的重要程度对指令进行了分级；</p><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.5dnygfmt0ow0.webp" width="40%"><p>&emsp;&emsp;CPU指令分为四个级别：Ring0~Ring3，linux 只使用了 Ring0 和 Ring3 两个运行级别，进程运行Ring3级别的指令时运行在用户态，指令只访问用户空间，而运行在 Ring0级别时被称为运行在内核态，可以访问任意内存空间。</p><br><br><br><h1 id="进程的内核态和用户态"><a href="#进程的内核态和用户态" class="headerlink" title="进程的内核态和用户态"></a>进程的内核态和用户态</h1><p>&emsp;&emsp;<strong>当进程运行在内核空间时，它就处于内核态；当进程运行在用户空间时，它就处于用户态。</strong></p><ul><li>那什么时候运行再内核空间什么时候运行再用户空间呢？</li></ul><blockquote><p>当我们需要进行IO操作时，如读写硬盘文件、读写网卡数据等，进程需要切换到内核态，否则无法进行这样的操作，无论是从内核态切换到用户态，还是从用户态切换到内核态，都需要进行一次上下文的切换。一般情况下，应用不能直接操作内核空间的数据，需要把内核态的数据拷贝到用户空间才能操作。</p></blockquote><blockquote><p>比如我们 Java 中需要新建一个线程，调用 start() 方法时，基于Hotspot Linux 的JVM 源码实现，最终是调<code>pthread_create</code>系统方法来创建的线程，这里会从用户态切换到内核态完成系统资源的分配，线程的创建。</p></blockquote><img src="https://cdn.staticaly.com/gh/ratears/image-hosting@main/blog-img-bed/image.ymdgdg0666o.webp" width="60%"><ul><li>当一个任务（进程）执行系统调用而陷入内核代码中执行时，称进程处于内核运行态（内核态）</li></ul><blockquote><p>Tips：除了系统调用可以实现用户态到内核态的切换，软中断和硬中断也会切换用户态和内核态。</p></blockquote><ul><li>在内核态下：进程运行在内核地址空间中，此时 CPU 可以执行任何指令。运行的代码也不受任何的限制，可以自由地访问任何有效地址，也可以直接进行端口的访问。</li><li>在用户态下：进程运行在用户地址空间中，被执行的代码要受到 CPU 的很多检查，比如：进程只能访问映射其地址空间的页表项中规定的在用户态下可访问页面的虚拟地址。</li></ul><br><br><br><h1 id="术语解释"><a href="#术语解释" class="headerlink" title="术语解释"></a>术语解释</h1><h2 id="核心态-内核态-Kernel-model-和用户态-User-model"><a href="#核心态-内核态-Kernel-model-和用户态-User-model" class="headerlink" title="核心态/内核态(Kernel model)和用户态(User model)"></a>核心态/内核态(Kernel model)和用户态(User model)</h2><p>&emsp;&emsp;核心态(Kernel model)和用户态(User model)，CPU会在两个model之间切换。</p><ul><li>核心态代码拥有完全的底层资源控制权限，可以执行任何CPU指令，访问任何内存地址，其占有的处理机是不允许被抢占的。内核态的指令包括：启动I/O，内存清零，修改程序状态字，设置时钟，允许/终止中断和停机。内核态的程序崩溃会导致PC停机。</li><li>用户态是用户程序能够使用的指令，不能直接访问底层硬件和内存地址。用户态运行的程序必须委托系统调用来访问硬件和内存。用户态的指令包括：控制转移，算数运算，取数指令，访管指令（使用户程序从用户态陷入内核态）。</li></ul><br><br><br><h2 id="进程切换"><a href="#进程切换" class="headerlink" title="进程切换"></a>进程切换</h2><p>&emsp;&emsp;为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：</p><blockquote><ol><li>保存处理机上下文，包括程序计数器和其他寄存器。</li><li>更新PCB信息。</li><li>把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。</li><li>选择另一个进程执行，并更新其PCB。</li><li>更新内存管理的数据结构。</li><li>恢复处理机上下文。</li></ol></blockquote><br><br><br><h2 id="文件描述符-fd-File-Descriptor"><a href="#文件描述符-fd-File-Descriptor" class="headerlink" title="文件描述符(fd, File Descriptor)"></a>文件描述符(fd, File Descriptor)</h2><p>&emsp;&emsp;FD用于描述指向文件的引用的抽象化概念。文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。</p><br><br><br>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;操作系统的应用与内核&quot;&gt;&lt;a href=&quot;#操作系统的应用与内核&quot; class=&quot;headerlink&quot; title=&quot;操作系统的应用与内核&quot;&gt;&lt;/a&gt;操作系统的应用与内核&lt;/h1&gt;&lt;p&gt;&amp;emsp;&amp;emsp;现代计算机是由硬件和操作系统组成，我们的应用程序要操</summary>
      
    
    
    
    <category term="Operating-Systems" scheme="https://ratears.github.io/dev.ratears.life/Categories/Operating-Systems/"/>
    
    <category term="I/O" scheme="https://ratears.github.io/dev.ratears.life/Categories/Operating-Systems/I-O/"/>
    
    
    <category term="Operating-Systems" scheme="https://ratears.github.io/dev.ratears.life/Tags/Operating-Systems/"/>
    
    <category term="I/O" scheme="https://ratears.github.io/dev.ratears.life/Tags/I-O/"/>
    
  </entry>
  
</feed>
