[{"title":"Git","url":"/Git/","content":"学习备注\n1、要清楚执行每个git命令后 提示信息表达的意思，不会的单词要记忆，写在这个文档里面\n\n版本控制系统什么是版本控制系统\n版本控制系统是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统\n\n为什么要使用版本控制\n软件开发中采用版本控制系统是个明智的选择\n有了它你就可以将某个文件回溯到之前的状态,甚至将整个项目都回退到过去某个时间点的状态\n就算你乱来一气把整个项目中的文件改的改删的删，你也照样可以轻松恢复到原先的样子\n你可以比较文件的变化细节,查出最后是谁修改了哪个地方,从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等\n但额外增加的工作量却微乎其微\n\n版本管理的演变\nVCS 出现前\n用目录拷贝区别不不同版本\n公共文件容易易被覆盖\n成员沟通成本很高，代码集成效率低下\n\n\n集中式 VCS\n有集中的版本管理服务器\n具备文件版本管理和分支管理能力\n集成效率有明显地提高\n客户端必须时刻和服务器相连\n\n\n分布式 VCS\n服务端和客户端都有完整的版本库\n脱离服务端，客户端照样可以管理理版本\n查看历史和版本比较等多数操作，都不不需要访问服务器器，比集中式 VCS 更更能提⾼高版本管理理效率\n\n\n\n版本控制系统的分类集中化的版本控制系统\n\n\n集中化的版本控制系统诸如CVS, SVN 以及Perforce 等，都有一个单一的集中管理的服务器,保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器,取出最新的文件或者提交更新。多年以来,这已成为版本控制系统的标准做法,这种做法带来了许多好处,现在,每个人都可以在一定程度上看到项目中的其他人正在做些什么。而管理员也可以轻松掌控每个开发者的权限，并且管理一个集中化的版本控制系统;要远比在各个客户端上维护本地数据库来得轻松容易。\n事分两面，有好有坏。这么做最显而易见的缺点是中央服务器的单点故障。如果服务器宕机一小时，那么在这一小时内， 谁都无法提交更新，也就无法协同工作\n\n分布式的版本控制系统\n\n\n由于上面集中化版本控制系统的那些缺点，于是分布式版本控制系统面世了\n在这类系统中，像Git, BitKeeper 等,客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来\n许多这类系统都可以指定和若干不同的远端代码仓库进行交互。这样，你就可以在同一个项目中分别和不同工作小组的人相互协作\n\n\n\n\n分布式的版本控制系统在管理项目时存放的不是项目版本与版本之间的差异.它存的是索引(所需磁盘空间很少所以每个客户端都可以放下整个项目的历史记录)\n\n\n\n版本控制系统的存储方式\n世界上的版本控制总共有两种存储方式，一种是存储差异，另一种是存储快照\n存储差异：存储base文件，以后每次存储base文件的更改，SVN就是这种方式\n存储快照：每次更改都存储一个新文件，Git是这种方式\n\nGit 基础概念\nGit是一个免费的、开源的分布式版本控制系统，可以快速高效地管理从小型到大型的项目\n\nGit 简史\nLinux 内核开源项目有着为数众多的参与者。 绝大多数的 Linux 内核维护工作都花在了提交补丁和保存归档的繁琐事务上（1991－2002年间）。 到 2002 年，整个项目组开始启用一个专有的分布式版本控制系统 BitKeeper 来管理和维护代码。\n\n到了 2005 年，开发 BitKeeper 的商业公司同 Linux 内核开源社区的合作关系结束，他们收回了 Linux 内核社区免费使用 BitKeeper 的权力。 这就迫使 Linux 开源社区（特别是 Linux 的缔造者 Linus Torvalds）基于使用 BitKeeper 时的经验教训，开发出自己的版本系统。 他们对新的系统制订了若干目标\n\n\nGit 的使命 / 目标Git在设计之初就是为了搞定linux内核这种巨无霸而设计的，所以制定了自己的使命\n\n速度\n简单的设计\n对非线性开发模式的强力支持（允许成千上万个并行开发的分支）\n完全分布式\n有能力高效管理类似 Linux 内核一样的超大规模项目（速度和数据量）\n\nGit 的优点 / 特点\n快、非凡的性能\n本地仓库\n轻量级分支\n分布式\n各种工作流\n最优的存储能力\n开源的\n很容易易做备份\n支持离线操作\n很容易易定制工作流程\n\nGit 的结构\n\nGit 的交互方式代码托管中心是干嘛的\n我们已经有了本地库，本地库可以帮我们进行版本控制，为什么还需要代码托管中心呢？它的任务是帮我们维护远程库\n\n本地库和远程库的交互方式团队内部协作\n\n跨团队协作\n\n托管中心种类\n局域网环境下：可以搭建 GitLab服务器作为代码托管中心，GitLab可以自己去搭建\n外网环境下：可以由GitHub或者Gitee作为代码托管中心，GitHub或者Gitee是现成的托管中心，不用自己去搭建 \n\nGit 的下载安装 / 基本设置\n下载安装略（官网下载，一般情况傻瓜式安装即可）\n查看git安装版本（是否安装成功）\n\ngit --version\n\n基本设置\n配置user.name和user.email\n\ngit config --global  user.name &#x27;sonzonzy&#x27;git config --global  user.email &#x27;sonzonzy@gmail.com&#x27;\n\nconfig 的三个作用域\n缺省等同于 local\n优先级：local &gt; global &gt; system\n\n# local只对当前仓库有效git config --local# global 对当前登录用户所有仓库有效git config --global# system 对系统的所有用户有效git config --system\n\n显示 config 的配置git config --list --localgit config --list --globalgit config --list --system\n\n信息设置与清除\n设置    缺省等同于 local\n\ngit config --local user.name &quot;ratears&quot;git config --global user.name &quot;ratears&quot;git config --system user.name &quot;ratears&quot;\n\n\n清除    –unset\n\ngit config --unset --local user.namegit config --unset --global user.namegit config --unset --system user.name\n\nGit 常用命令 &amp; 操作init / 初始化本地仓库# 在git终端进入到本地的文件夹 （例如 $ cd D:\\dev\\git_ws\\git_demo） 执行如下命令#初始化本地仓库，只能初始化本地仓库git init\n\nadd / 添加到暂存区git add .\n\ncommit / 提交到本地仓库# 把暂存区的 文件提交到本地仓库。-m&quot;message&quot; 后的双引号 填写该次提交的说明信息git commit -m&quot;add test1.txt&quot;\n\n\n注意事项\n\n不放在本地仓库中的文件，git是不进行管理\n\n即使放在本地仓库的文件，git也不管理，必须通过add,commit命令操作才可以将内容提交到本地库\n\n\n\n\nstatus / 查看工作区和暂存区的状态git status\n\nmv / 重命名暂存区的文件\n方式一\n\nmv readme readme.mdgit rm readmegit add readme.mdgit commit -m&quot;rename file&quot;\n\n\n方式二\n\ngit mv readme readme.mdgit commit -m&#x27;file name&#x27;\n\nlog / 查看提交日志# 可以让我们查看提交的，显示从最近到最远的日志git log -n[number] --graph --online --all/[branch_name]# -n 指定查看条数# --graph 图形化查看# --online 简单显示# --all 显示所有分支，不加则显示当前分支# branch_name 指定分支git log --pretty=onelinegit reflog# 多了信息：HEAD@&#123;数字&#125; 这个数字的含义：指针回到当前这个历史版本需要走多少步\n\n# 在浏览器打开git log 的帮助文档git help --web log\n\ngitk / git 的gui界面# 打开git的gui界面gitk\n\nrest / 前进或者后退历史版本hard 参数# 本地库的指针移动的同时，重置暂存区，重置工作区git reset --hard [索引]\n\nmixed参数# 本地库的指针移动的同时，重置暂存区，但是工作区不动git reset --mixed [索引]\n\nsoft参数# 本地库的指针移动的时候，暂存区，工作区都不动git reset --soft [索引]\n\ndiff# 将工作区中的文件和暂存区中文件进行比较 git diff [文件名]  # 比较工作区中和暂存区中 所有文件的差异git diff# 比较暂存区和工作区中内容git diff [历史版本] [文件名] \n\n分支","categories":["git"],"tags":["git"]},{"title":"Java - Collection Framework","url":"/Java-Collection-Framework/","content":"Collection\n容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对(两个对象)的映射表\n\nCollection 接口常用方法\n\n\nboolean\tadd(E e)boolean\taddAll(Collection&lt;? extends E&gt; c)void\tclear()boolean\tremove(Object o)    Iterator&lt;E&gt;\titerator()int\tsize()    boolean\tcontains(Object o)boolean\tequals(Object o) boolean\tisEmpty()\n\n\n集合只能存放引用数据类型，不能存放基本数据类型\n\n","categories":["java","collection"],"tags":["collection"]},{"title":"Gradle","url":"/Gradle/","content":"Gradle入门Gradle简介\nGradle 是一款Google 推出的基于 JVM、通用灵活的项目构建工具，支持 Maven，JCenter 多种第三方仓库;支持传递性依赖管理、废弃了繁杂的xml 文件，转而使用简洁的、支持多种语言(例如：java、groovy 等)的 build 脚本文件。（新一代的项目自动化构建工具）\n\n官网地址: https://gradle.org/\n\nGradle与maven进行对比：maven侧重于项目jar包的管理，Gradle侧重于项目的构建\n\n\n学习备注\n\np1 部分笔记还需要补充\n\n\n","categories":["gradle"],"tags":["gradle"]},{"title":"Maven核心知识梳理","url":"/Maven%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86/","content":"第一章 Maven概述Why？为什么要学习 Maven？Maven 作为依赖管理工具①jar 包的规模\n随着我们使用越来越多的框架，或者框架封装程度越来越高，项目中使用的jar包也越来越多。项目中，一个模块里面用到上百个jar包是非常正常的\n比如下面的例子，我们只用到 SpringBoot、SpringCloud 框架中的三个功能：\nNacos 服务注册发现\nWeb 框架环境\n图模板技术 Thymeleaf\n\n\n\n\n最终却导入了 106 个 jar 包\n\n而如果使用 Maven 来引入这些 jar 包只需要配置三个『依赖』：\n&lt;!-- Nacos 服务注册发现启动器 --&gt;   &lt;dependency&gt;       &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;       &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;   &lt;/dependency&gt;   &lt;!-- web启动器依赖 --&gt;   &lt;dependency&gt;       &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;       &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;   &lt;/dependency&gt;   &lt;!-- 视图模板技术 thymeleaf --&gt;   &lt;dependency&gt;       &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;       &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;   &lt;/dependency&gt;\n\n\n\n②jar 包的来源\n这个jar包所属技术的官网。官网通常是英文界面，网站的结构又不尽相同，甚至找到下载链接还发现需要通过特殊的工具下载\n第三方网站提供下载。问题是不规范，在使用过程中会出现各种问题:\njar包的名称\njar包的版本\njar包内的具体细节\n\n\n而使用 Maven 后，依赖对应的 jar 包能够自动下载，方便、快捷又规范\n\n③jar 包之间的依赖关系\n框架中使用的 jar 包，不仅数量庞大，而且彼此之间存在错综复杂的依赖关系。依赖关系的复杂程度，已经上升到了完全不能靠人力手动解决的程度。另外，jar 包之间有可能产生冲突。进一步增加了我们在 jar 包使用过程中的难度\n\n下面是前面例子中 jar 包之间的依赖关系：\n\n\n\n\n\n\n\n而实际上 jar 包之间的依赖关系是普遍存在的，如果要由程序员手动梳理无疑会增加极高的学习成本，而这些工作又对实现业务功能毫无帮助\n使用 Maven 则几乎不需要管理这些关系，极个别的地方调整一下即可，极大的减轻了我们的工作量\n\n\n\n\n\nMaven 作为构建管理工具①你没有注意过的构建\n可以不使用 Maven，但是构建必须要做。当我们使用 IDEA 进行开发时，构建是 IDEA 替我们做的\n\n②脱离 IDE 环境仍需构建\n\n\n\n\n\n结论\n管理规模庞大的 jar 包，需要专门工具。\n脱离 IDE 环境执行构建操作，需要专门工具。\n\n\n\n\n\n\n\nWhat？什么是 Maven？\nMaven 是 Apache 软件基金会组织维护的一款专门为 Java 项目提供构建和依赖管理支持的工具\n\n\n\n\n\n构建\nJava 项目开发过程中，构建指的是使用『原材料生产产品』的过程\n\n\n原材料\nJava 源代码\n基于 HTML 的 Thymeleaf 文件\n图片\n配置文件\n……\n\n\n产品\n一个可以在服务器上运行的项目\n\n\n\n\n构建过程包含的主要的环节：\n\n\n\n清理：删除上一次构建的结果，为下一次构建做好准备\n编译：Java 源程序编译成 *.class 字节码文件\n测试：运行提前准备好的测试程序\n报告：针对刚才测试的结果生成一个全面的信息\n打包\nJava工程：jar包\nWeb工程：war包\n\n\n安装：把一个 Maven 工程经过打包操作生成的 jar 包或 war 包存入 Maven 仓库\n部署\n部署 jar 包：把一个 jar 包部署到 Nexus 私服服务器上\n部署 war 包：借助相关 Maven 插件（例如 cargo），将 war 包部署到 Tomcat 服务器上\n\n\n\n\n依赖\n如果 A 工程里面用到了 B 工程的类、接口、配置文件等等这样的资源，那么我们就可以说 A 依赖 B。例如：\njunit-4.12 依赖 hamcrest-core-1.3\nthymeleaf-3.0.12.RELEASE 依赖 ognl-3.1.26\nognl-3.1.26 依赖 javassist-3.20.0-GA\n\n\n\n\n\n\n依赖管理中要解决的具体问题：\njar 包的下载：使用 Maven 之后，jar 包会从规范的远程仓库下载到本地\njar 包之间的依赖：通过依赖的传递性自动完成\njar 包之间的冲突：通过对依赖的配置进行调整，让某些jar包不会被导入\n\n\n\nMaven 的工作机制\n\n\n\n\n\n\n\n第二章 Maven 核心程序解压和配置Maven核心程序解压与配置\nMaven 官网地址：Maven – Welcome to Apache Maven\n\n\n解压Maven核心程序\n核心程序压缩包：apache-maven-3.8.4-bin.zip，解压到非中文、没有空格的目录\n在解压目录中，我们需要着重关注 Maven 的核心配置文件：conf/settings.xml\n\n\n\n\n指定本地仓库\n建议将 Maven 的本地仓库放在其他盘符下。配置方式如下：\n\n\n\n&lt;!-- localRepository| The path to the local repository maven will use to store artifacts.|| Default: $&#123;user.home&#125;/.m2/repository&lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt;--&gt;&lt;localRepository&gt;D:\\maven-repository&lt;/localRepository&gt;\n\n\n\n\n配置阿里云提供的镜像仓库\nMaven 下载 jar 包默认访问境外的中央仓库，而国外网站速度很慢。改成阿里云提供的镜像仓库，访问国内网站，可以让 Maven 下载 jar 包的时候速度更快。配置的方式是：\n\n\n\n&lt;!--将原有的例子配置注释掉 --&gt;&lt;!-- &lt;mirror&gt;  &lt;id&gt;maven-default-http-blocker&lt;/id&gt;  &lt;mirrorOf&gt;external:http:*&lt;/mirrorOf&gt;  &lt;name&gt;Pseudo repository to mirror external repositories initially using HTTP.&lt;/name&gt;  &lt;url&gt;http://0.0.0.0/&lt;/url&gt;  &lt;blocked&gt;true&lt;/blocked&gt;&lt;/mirror&gt; --&gt;\n\n&lt;!--加入我们的配置 --&gt;&lt;mirror&gt;\t&lt;id&gt;nexus-aliyun&lt;/id&gt;\t&lt;mirrorOf&gt;central&lt;/mirrorOf&gt;\t&lt;name&gt;Nexus aliyun&lt;/name&gt;\t&lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;&lt;/mirror&gt;\n\n\n\n\n配置 Maven 工程的基础 JDK 版本\n\n&lt;profile&gt;  &lt;id&gt;jdk-1.8&lt;/id&gt;  &lt;activation&gt;\t&lt;activeByDefault&gt;true&lt;/activeByDefault&gt;\t&lt;jdk&gt;1.8&lt;/jdk&gt;  &lt;/activation&gt;  &lt;properties&gt;\t&lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;\t&lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;\t&lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt;  &lt;/properties&gt;&lt;/profile&gt;\n\n\n\n\n\n配置环境变量\n检查 JAVA_HOME 配置是否正确\nMaven 是一个用 Java 语言开发的程序，它必须基于 JDK 来运行，需要通过 JAVA_HOME 来找到 JDK 的安装位置\n\n\n配置 MAVEN_HOME\n配置PATH\n验证\n\nC:\\Users\\Administrator&gt;mvn -vApache Maven 3.8.4 (9b656c72d54e5bacbed989b64718c159fe39b537)Maven home: D:\\software\\apache-maven-3.8.4Java version: 1.8.0_141, vendor: Oracle Corporation, runtime: D:\\software\\Java\\jreDefault locale: zh_CN, platform encoding: GBKOS name: &quot;windows 10&quot;, version: &quot;10.0&quot;, arch: &quot;amd64&quot;, family: &quot;windows&quot;\n\n\n\n\n\n\n\n第三章 使用 Maven：命令行环境实验一：根据坐标创建 Maven 工程Maven 核心概念：坐标①数学中的坐标\n使用 x、y、z 三个『向量』作为空间的坐标系，可以在『空间』中唯一的定位到一个『点』\n\n②Maven中的坐标[1]向量说明\n\n使用三个『向量』在『Maven的仓库』中唯一的定位到一个『jar』包。\ngroupId：公司或组织的 id\nartifactId：一个项目或者是项目中的一个模块的 id\nversion：版本号\n\n\n\n[2]三个向量的取值方式\n\ngroupId：公司或组织域名的倒序，通常也会加上项目名称\n例如：com.atguigu.maven\n\n\nartifactId：模块的名称，将来作为 Maven 工程的工程名\nversion：模块的版本号，根据自己的需要设定\n例如：SNAPSHOT 表示快照版本，正在迭代过程中，不稳定的版本\n例如：RELEASE 表示正式版本\n\n\n\n\n举例：\n\n\ngroupId：com.atguigu.maven\nartifactId：pro01-atguigu-maven\nversion：1.0-SNAPSHOT\n\n③坐标和仓库中 jar 包的存储路径之间的对应关系&lt;!-- 坐标： --&gt;&lt;groupId&gt;javax.servlet&lt;/groupId&gt;&lt;artifactId&gt;servlet-api&lt;/artifactId&gt;&lt;version&gt;2.5&lt;/version&gt;\n\n上面坐标对应的 jar 包在 Maven 本地仓库中的位置：Maven本地仓库根目录\\javax\\servlet\\servlet-api\\2.5\\servlet-api-2.5.jar\n\n\n\n实验操作：使用命令生成Maven工程\n\n\n\n\n运行 mvn archetype:generate 命令\n\n\nTIP\nChoose a number or apply filter (format: [groupId:]artifactId, case sensitive contains): 7:【直接回车，使用默认值】\nDefine value for property ‘groupId’: com.atguigu.maven\nDefine value for property ‘artifactId’: pro01-maven-java\nDefine value for property ‘version’ 1.0-SNAPSHOT: :【直接回车，使用默认值】\nDefine value for property ‘package’ com.atguigu.maven: :【直接回车，使用默认值】\nConfirm properties configuration: groupId: com.atguigu.maven artifactId: pro01-maven-java version: 1.0-SNAPSHOT package: com.atguigu.maven Y: :【直接回车，表示确认。如果前面有输入错误，想要重新输入，则输入 N 再回车。】\n\n\n调整\n\n&lt;!-- Maven 默认生成的工程，对 junit 依赖的是较低的 3.8.1 版本，我们可以改成较适合的 4.12 版本。自动生成的 App.java 和 AppTest.java 可以删除  --&gt;&lt;!-- 依赖信息配置 --&gt;&lt;!-- dependencies复数标签：里面包含dependency单数标签 --&gt;&lt;dependencies&gt;\t&lt;!-- dependency单数标签：配置一个具体的依赖 --&gt;\t&lt;dependency&gt;\t\t&lt;!-- 通过坐标来依赖其他jar包 --&gt;\t\t&lt;groupId&gt;junit&lt;/groupId&gt;\t\t&lt;artifactId&gt;junit&lt;/artifactId&gt;\t\t&lt;version&gt;4.12&lt;/version&gt;\t\t\t\t&lt;!-- 依赖的范围 --&gt;\t\t&lt;scope&gt;test&lt;/scope&gt;\t&lt;/dependency&gt;&lt;/dependencies&gt;\n\n\n\n\n自动生成的 pom.xml 解读\n\n &lt;!-- 当前Maven工程的坐标 --&gt; &lt;groupId&gt;com.atguigu.maven&lt;/groupId&gt; &lt;artifactId&gt;pro01-maven-java&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  &lt;!-- 当前Maven工程的打包方式，可选值有下面三种： --&gt; &lt;!-- jar：表示这个工程是一个Java工程  --&gt; &lt;!-- war：表示这个工程是一个Web工程 --&gt; &lt;!-- pom：表示这个工程是“管理其他工程”的工程 --&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;pro01-maven-java&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt;&lt;!-- 工程构建过程中读取源码时使用的字符集 --&gt;   &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;!-- 当前工程所依赖的jar包 --&gt; &lt;dependencies&gt;&lt;!-- 使用dependency配置一个具体的依赖 --&gt;   &lt;dependency&gt;  &lt;!-- 在dependency标签内使用具体的坐标依赖我们需要的一个jar包 --&gt;     &lt;groupId&gt;junit&lt;/groupId&gt;     &lt;artifactId&gt;junit&lt;/artifactId&gt;     &lt;version&gt;4.12&lt;/version&gt;    &lt;!-- scope标签配置依赖的范围 --&gt;     &lt;scope&gt;test&lt;/scope&gt;   &lt;/dependency&gt; &lt;/dependencies&gt;\n\n\n\nMaven核心概念：POM含义\nPOM：Project Object Model，项目对象模型。和 POM 类似的是：DOM（Document Object Model），文档对象模型。它们都是模型化思想的具体体现\n\n模型化思想\nPOM 表示将工程抽象为一个模型，再用程序中的对象来描述这个模型。这样我们就可以用程序来管理项目了。我们在开发过程中，最基本的做法就是将现实生活中的事物抽象为模型，然后封装模型相关的数据作为一个对象，这样就可以在程序中计算与现实事物相关的数据\n\n对应的配置文件\nPOM 理念集中体现在 Maven 工程根目录下 pom.xml 这个配置文件中。所以这个 pom.xml 配置文件就是 Maven 工程的核心配置文件。其实学习 Maven 就是学这个文件怎么配置，各个配置有什么用。\n\nMaven核心概念：约定的目录结构①各个目录的作用\n\n\n\n\n另外还有一个 target 目录专门存放构建操作输出的结果\n\n②约定目录结构的意义\nMaven 为了让构建过程能够尽可能自动化完成，所以必须约定目录结构的作用。例如：Maven 执行编译操作，必须先去 Java 源程序目录读取 Java 源代码，然后执行编译，最后把编译结果存放在 target 目录。\n\n③约定大于配置\nMaven 对于目录结构这个问题，没有采用配置的方式，而是基于约定。这样会让我们在开发过程中非常方便。如果每次创建 Maven 工程后，还需要针对各个目录的位置进行详细的配置，那肯定非常麻烦。\n\n目前开发领域的技术发展趋势就是：约定大于配置，配置大于编码。\n\n\n学习备注\n\nmaven的工作机制还需要深入熟悉\n\n\n\n\n\n\n\n\n","categories":["maven"],"tags":["maven"]},{"title":"Mybatis","url":"/MyBatis/","content":"MyBatis简介MyBatis历史\nMyBatis最初是Apache的一个开源项目iBatis, 2010年6月这个项目由Apache Software Foundation迁移到了Google Code。随着开发团队转投Google Code旗下， iBatis3.x正式更名为MyBatis。代码于2013年11月迁移到Github。\niBatis一词来源于“internet”和“abatis”的组合，是一个基于Java的持久层框架。 iBatis提供的持久层框架包括SQL Maps和Data Access Objects（DAO）。\n\n\n\nMyBatis特性\nMyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架\nMyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集\nMyBatis可以使用简单的XML或注解用于配置和原始映射，将接口和Java的POJO（Plain Old JavaObjects，普通的Java对象）映射成数据库中的记录\nMyBatis 是一个 半自动的ORM（Object Relation Mapping）框架\n\n\n\nMyBatis下载MyBatis下载地址：https://github.com/mybatis/mybatis-3\n\n\n和其它持久化层技术对比\nJDBC\nSQL 夹杂在Java代码中耦合度高，导致硬编码内伤\n维护不易且实际开发需求中 SQL 有变化，频繁修改的情况多见\n代码冗长，开发效率低\n\n\nHibernate 和 JPA\n操作简便，开发效率高\n程序中的长难复杂 SQL 需要绕过框架\n内部自动生产的 SQL，不容易做特殊优化\n基于全映射的全自动框架，大量字段的 POJO 进行部分映射时比较困难\n反射操作太多，导致数据库性能下降\n\n\nMyBatis\n轻量级，性能出色\nSQL 和 Java 编码分开，功能边界清晰。Java代码专注业务、SQL语句专注数据\n开发效率稍逊于HIbernate，但是完全能够接受\n\n\n\n\n\n搭建MyBatis开发环境\nIDE：idea\n构建工具：maven\nMySQL版本：MySQL 8\nMyBatis版本：MyBatis 3.5.7\n\n\nMySQL不同版本的注意事项1、驱动类driver-class-nameMySQL 5版本使用jdbc5驱动，驱动类使用：com.mysql.jdbc.DriverMySQL 8版本使用jdbc8驱动，驱动类使用：com.mysql.cj.jdbc.Driver\n2、连接地址urlMySQL 5版本的url：jdbc:mysql://localhost:3306/ssmMySQL 8版本的url：jdbc:mysql://localhost:3306/ssm?serverTimezone=UTC否则运行测试用例报告如下错误：java.sql.SQLException: The server time zone value ‘ÖÐ¹ú±ê×¼Ê±¼ä’ is unrecognized or represents more\n\n\n\n创建maven工程\n打包方式：jar\n引入依赖\n\n&lt;dependencies&gt;        &lt;!-- Mybatis核心 --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;            &lt;artifactId&gt;mybatis&lt;/artifactId&gt;            &lt;version&gt;3.5.7&lt;/version&gt;        &lt;/dependency&gt;        &lt;!-- junit测试 --&gt;        &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;4.12&lt;/version&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;        &lt;!-- MySQL驱动 --&gt;        &lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;            &lt;version&gt;8.0.16&lt;/version&gt;        &lt;/dependency&gt;&lt;/dependencies&gt;\n\n\n创建MyBatis的核心配置文件\n\n\n\n习惯上命名为mybatis-config.xml，这个文件名仅仅只是建议，并非强制要求。将来整合Spring之后，这个配置文件可以省略，所以大家操作时可以直接复制、粘贴\n核心配置文件主要用于配置连接数据库的环境以及MyBatis的全局配置信息\n核心配置文件存放的位置是src/main/resources目录下\n\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;properties resource=&quot;jdbc.properties&quot; /&gt;    &lt;typeAliases&gt;        &lt;!--        typeAlias：设置某个类型的别名        属性：        type：设置需要设置别名的类型        alias：设置某个类型的别名，若不设置该属性，那么该类型拥有默认的别名，即类名        且不区分大小写        --&gt;        &lt;!--&lt;typeAlias type=&quot;com.atguigu.mybatis.pojo.User&quot;&gt;&lt;/typeAlias&gt;--&gt;        &lt;!--以包为单位，将包下所有的类型设置默认的类型别名，即类名且不区分大小写--&gt;        &lt;package name=&quot;com.study.pojo&quot;/&gt;    &lt;/typeAliases&gt;    &lt;environments default=&quot;development&quot;&gt;        &lt;environment id=&quot;development&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;$&#123;mysql.jdbc.driver&#125;&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;$&#123;mysql.jdbc.url&#125;&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;$&#123;mysql.jdbc.username&#125;&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;$&#123;mysql.jdbc.password&#125;&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;        &lt;environment id=&quot;test&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/ssm?serverTimezone=UTC&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;Happy2022&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;mappers&gt;&lt;!--        &lt;mapper resource=&quot;mappers/UserMapper.xml&quot; /&gt;--&gt;        &lt;package name=&quot;com.study.mapper&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;\n\n\n\n创建mapper接口\nMyBatis中的mapper接口相当于以前的dao。但是区别在于，mapper仅仅是接口，我们不需要提供实现类\n\npublic interface UserMapper &#123;    /**    * 添加用户信息    */    int insertUser();&#125;\n\n\n\n创建MyBatis的映射文件\n相关概念：ORM（Object Relationship Mapping）对象关系映射\n对象：Java的实体类对象\n关系：关系型数据库\n映射：二者之间的对应关系\n\n\n\n\n\n\nJava概念\n数据库概念\n\n\n\n类\n表\n\n\n属性\n字段/列\n\n\n对象\n记录/行\n\n\n\n映射文件的命名规则：\n\n\n表所对应的实体类的类名+Mapper.xml\n例如：表t_user，映射的实体类为User，所对应的映射文件为UserMapper.xml\n因此一个映射文件对应一个实体类，对应一张表的操作\nMyBatis映射文件用于编写SQL，访问以及操作表中的数据\nMyBatis映射文件存放的位置是src/main/resources/mappers目录下\n\n\nMyBatis中可以面向接口操作数据，要保证两个一致：\n\n\n\nmapper接口的全类名和映射文件的命名空间（namespace）保持一致\nmapper接口中方法的方法名和映射文件中编写SQL的标签的id属性保持一致\n\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapperPUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.atguigu.mybatis.mapper.UserMapper&quot;&gt;    &lt;!--int insertUser();--&gt;    &lt;insert id=&quot;insertUser&quot;&gt;    insert into t_user values(null,&#x27;admin&#x27;,&#x27;123456&#x27;,23,&#x27;男&#x27;,&#x27;12345@qq.com&#x27;)    &lt;/insert&gt;&lt;/mapper&gt;\n\n\n\n通过junit测试功能//读取MyBatis的核心配置文件InputStream is = Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;);//创建SqlSessionFactoryBuilder对象SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();//通过核心配置文件所对应的字节输入流创建工厂类SqlSessionFactory，生产SqlSession对象SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is);//创建SqlSession对象，此时通过SqlSession对象所操作的sql都必须手动提交或回滚事务//SqlSession sqlSession = sqlSessionFactory.openSession();//创建SqlSession对象，此时通过SqlSession对象所操作的sql都会自动提交SqlSession sqlSession = sqlSessionFactory.openSession(true);//通过代理模式创建UserMapper接口的代理实现类对象UserMapper userMapper = sqlSession.getMapper(UserMapper.class);//调用UserMapper接口中的方法，就可以根据UserMapper的全类名匹配元素文件，通过调用的方法名匹配映射文件中的SQL标签，并执行标签中的SQL语句int result = userMapper.insertUser();//sqlSession.commit();System.out.println(&quot;结果：&quot;+result);\n\n\nSqlSession：代表Java程序和数据库之间的会话。（HttpSession是Java程序和浏览器之间的会话）\nSqlSessionFactory：是“生产”SqlSession的“工厂”\n工厂模式：如果创建某一个对象，使用的过程基本固定，那么我们就可以把创建这个对象的相关代码封装到一个“工厂类”中，以后都使用这个工厂类来“生产”我们需要的对象\n\n\n\n加入log4j日志功能\n加入依赖\n\n&lt;!-- log4j日志 --&gt;&lt;dependency&gt;    &lt;groupId&gt;log4j&lt;/groupId&gt;    &lt;artifactId&gt;log4j&lt;/artifactId&gt;    &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt;\n\n\n加入log4j的配置文件\n\n\nlog4j的配置文件名为log4j.xml，存放的位置是src/main/resources目录下\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE log4j:configuration SYSTEM &quot;log4j.dtd&quot;&gt;&lt;log4j:configuration xmlns:log4j=&quot;http://jakarta.apache.org/log4j/&quot;&gt;    &lt;appender name=&quot;STDOUT&quot; class=&quot;org.apache.log4j.ConsoleAppender&quot;&gt;        &lt;param name=&quot;Encoding&quot; value=&quot;UTF-8&quot; /&gt;        &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt;            &lt;param name=&quot;ConversionPattern&quot; value=&quot;%-5p %d&#123;MM-dd HH:mm:ss,SSS&#125;%m (%F:%L) \\n&quot; /&gt;        &lt;/layout&gt;    &lt;/appender&gt;    &lt;logger name=&quot;java.sql&quot;&gt;        &lt;level value=&quot;debug&quot; /&gt;    &lt;/logger&gt;    &lt;logger name=&quot;org.apache.ibatis&quot;&gt;        &lt;level value=&quot;info&quot; /&gt;    &lt;/logger&gt;    &lt;root&gt;        &lt;level value=&quot;debug&quot; /&gt;        &lt;appender-ref ref=&quot;STDOUT&quot; /&gt;    &lt;/root&gt;&lt;/log4j:configuration&gt;\n\n\n日志的级别:\n\n\nFATAL(致命)&gt;ERROR(错误)&gt;WARN(警告)&gt;INFO(信息)&gt;DEBUG(调试)\n从左到右打印的内容越来越详细\n\n\n\n核心配置文件详解&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;!--    MyBatis核心配置文件中，标签的顺序：    properties?,settings?,typeAliases?,typeHandlers?,    objectFactory?,objectWrapperFactory?,reflectorFactory?,    plugins?,environments?,databaseIdProvider?,mappers?    --&gt;    &lt;!--引入properties文件--&gt;    &lt;properties resource=&quot;jdbc.properties&quot; /&gt;    &lt;!--设置类型别名--&gt;    &lt;typeAliases&gt;        &lt;!--        typeAlias：设置某个类型的别名        属性：        type：设置需要设置别名的类型        alias：设置某个类型的别名，若不设置该属性，那么该类型拥有默认的别名，即类名        且不区分大小写        --&gt;        &lt;!--&lt;typeAlias type=&quot;com.atguigu.mybatis.pojo.User&quot;&gt;&lt;/typeAlias&gt;--&gt;        &lt;!--以包为单位，将包下所有的类型设置默认的类型别名，即类名且不区分大小写--&gt;        &lt;package name=&quot;com.atguigu.mybatis.pojo&quot;/&gt;    &lt;/typeAliases&gt;    &lt;!--    environments：配置多个连接数据库的环境    属性：    default：设置默认使用的环境的id    --&gt;    &lt;environments default=&quot;development&quot;&gt;        &lt;!--environment：配置某个具体的环境属性：id：表示连接数据库的环境的唯一标识，不能重复--&gt;        &lt;environment id=&quot;development&quot;&gt;            &lt;!--            transactionManager：设置事务管理方式            属性：            type=&quot;JDBC|MANAGED&quot;            JDBC：表示当前环境中，执行SQL时，使用的是JDBC中原生的事务管理方式，事            务的提交或回滚需要手动处理            MANAGED：被管理，例如Spring            --&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;!--            dataSource：配置数据源            属性：            type：设置数据源的类型            type=&quot;POOLED|UNPOOLED|JNDI&quot;            POOLED：表示使用数据库连接池缓存数据库连接            UNPOOLED：表示不使用数据库连接池            JNDI：表示使用上下文中的数据源            --&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;!--设置连接数据库的驱动--&gt;                &lt;property name=&quot;driver&quot; value=&quot;$&#123;jdbc.driver&#125;&quot;/&gt;                &lt;!--设置连接数据库的连接地址--&gt;                &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot;/&gt;                &lt;!--设置连接数据库的用户名--&gt;                &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot;/&gt;                &lt;!--设置连接数据库的密码--&gt;                &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;        &lt;environment id=&quot;test&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;                &lt;property name=&quot;url&quot;                          value=&quot;jdbc:mysql://localhost:3306/ssmserverTimezone=UTC&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;!--引入映射文件--&gt;    &lt;mappers&gt;        &lt;!--&lt;mapper resource=&quot;mappers/UserMapper.xml&quot;/&gt;--&gt;        &lt;!--        以包为单位引入映射文件        要求：        1、mapper接口所在的包要和映射文件所在的包一致        2、mapper接口要和映射文件的名字一致        --&gt;        &lt;package name=&quot;com.atguigu.mybatis.mapper&quot;/&gt;    &lt;/mappers&gt;\n\n\n\n\n\nMyBatis的增删改查","categories":["mybatis"],"tags":["mybatis"]},{"title":"Nexus搭建Maven私服","url":"/Nexus%E6%90%AD%E5%BB%BAMaven%E7%A7%81%E6%9C%8D/","content":"Nexus 安装\nNexus下载\n\n# （1）上传 下载的软件到目录 /app[root@bu2-vm-svr-67 app]# lltotal 212392-rw-r--r-- 1 root root 217484934 Sep 28 14:06 nexus-3.42.0-01-unix.tar.gz[root@bu2-vm-svr-67 app]# tar -zxvf nexus-3.42.0-01-unix.tar.gz[root@bu2-vm-svr-67 app]# lltotal 212400drwxr-xr-x 10 root root      4096 Sep 28 18:55 nexus-3.42.0-01-rw-r--r--  1 root root 217484934 Sep 28 14:06 nexus-3.42.0-01-unix.tar.gzdrwxr-xr-x  3 root root      4096 Sep 28 18:55 sonatype-work[root@bu2-vm-svr-67 app]# vi /app/nexus-3.42.0-01/bin/nexusrun_as_root=false[root@bu2-vm-svr-67 app]# vi /app/nexus-3.42.0-01/etc/nexus-default.propertiesapplication-port=7071[root@bu2-vm-svr-67 app]# /app/nexus-3.42.0-01/bin/nexus startStarting nexus\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n学习备注\n1\n\n&amp;emsp;&amp;emsp;\n\n\n\n\n\n\n\n\n\n","categories":["Maven","Nexus"],"tags":["Nexus","Maven"]},{"title":"Spring","url":"/Spring/","content":"Spring 概览\nSpring IoC\n\n\n\n\n内容\n说明\n重要程度\n\n\n\nSpring 框架介绍\nSpring IoC、DI 和 AOP 等核心概念\n※※※※※\n\n\nSpring IoC 容器\nSpring 实例化与管理对象\n※※※※※\n\n\n集合对象注入\n注入List、Set、Map集合对象\n※※※※※\n\n\n底层原理\nSpring Bean 的生命周期\n※※※※※\n\n\n注解与Java Config\nSpring 注解分类和常用注解应用\n※※※※※\n\n\n\n\nSpring AOP\n\n\n\n内容\n说明\n重要程度\n\n\n\n理解 AOP 及名词\nSpring AOP 开发与配置流程\n※※※※\n\n\n五种通知类型\nSpring 五种通知类型与应用场景\n※※※\n\n\n切点表达式\nPointCut 切点表达式的语法规则及应用\n※※\n\n\n代理模式\nJDK 动态代理和 CGLib代理的执行过程\n※※※※\n\n\n\n\n\nSpring JDBC 与声明式事物\n\n\n\n\n内容\n说明\n重要程度\n\n\n\nSpring JDBC\nSpring JDBC 的环境配置\n※※※※\n\n\nRestTemplate\n基于 RestTemplate 实现 SQL 处理\n※※※\n\n\n配置声明式事物\n声明式事物的配置过程\n※※※※※\n\n\n事物传播行为介绍\n讲解常用事物传播行为的用途\n※※※\n\n\n声明式事物注解形式\n基于注解使用声明式事物\n※※※※※\n\n\n\n\nSpring 的含义\nSpring 可以从狭义与广义两个角度看待\n狭义的 Spring 是指 Spring 框架（Spring Framework）\n广义的 Spring 是指 Spring 生态体系\n\n狭义的 Spring 框架\nSpring 框架是企业开发复杂性的一站式解决方案\nSpring 框架的核心是 IoC 容器与 AOP 面向切面编程\nSpring IoC 负责创建与管理系统对象，并在此基础上扩展功能\n\n广义的 Spring 生态体系\n\n\n\nIoC 控制反转\nIoC 控制反转，全称 Inverse of Control ，是一种设计理念\n由代理人来创建与管理对象，消费者通过代理人来获取对象\nIoC 的目的是降低对象之间直接耦合，加入 IoC 容器将对象统一管理，让对象关联变为弱耦合\n\nDI\nIoC 是设计理念，是现代程序设计遵循的标准，是宏伟目标\nDI （Dependency Injection）是具体技术实现，是微观实现\nDI 在 Java 中利用反射技术实现对象注入（Injection）\n\nSpring框架组成模块\n\n\n\nSpring IoC传统开发方式\n对象直接饮用，导致对象硬性关联，程序难以扩展维护\n\n\n\n\n\nSpring IoC 容器\nIoC 容器是 Spring 生态的地基，用于统一创建与管理对象依赖\n\n\n\n\n\nSpring IoC 容器职责\n对象的控制权交由第三方统一管理（IoC 控制反转）\n利用 Java 反射技术实现运行时对象创建与关联（DI 依赖注入）\n基于配置提高应用程序的可维护性与可扩展性\n\n配置 bean 的三种方式\n基于XML配置bean\n基于注解配置bean\n基于Java代码配置bean\n\nXML实例化Bean的配置方式（1）基于构造方法实例化对象&lt;!--通过默认构造方法创建对象--&gt;&lt;bean id=&quot;lily&quot; class=&quot;com.study.spring.entity.Person&quot; &gt;&lt;/bean&gt;&lt;!--通过有参构造方法创建对象--&gt;&lt;bean id=&quot;andy&quot; class=&quot;com.study.spring.entity.Person&quot; &gt;    &lt;!-- 没有constructor-arg 则代表调用默认构造方法实例化        --&gt;    &lt;constructor-arg name=&quot;nickName&quot; value=&quot;andy&quot; &gt;&lt;/constructor-arg&gt;    &lt;constructor-arg name=&quot;age&quot; value=&quot;18&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;!--通过有参构造方法创建对象--&gt;&lt;bean id=&quot;nacos&quot; class=&quot;com.study.spring.entity.Person&quot; &gt;    &lt;!-- 利用构造方法参数位置实现对象实例化        --&gt;    &lt;constructor-arg index=&quot;0&quot; value=&quot;nacos&quot; &gt;&lt;/constructor-arg&gt;    &lt;constructor-arg index=&quot;1&quot; value=&quot;18&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;\n\n\n\n（2）基于静态工厂实例化对象/** * 使用静态工厂方法创建对象，隐藏创建对象的细节 */public class PersonStaticFactory &#123;    public static Person createPerson() &#123;        Person person = new Person();        person.setAge(19);        person.setNickName(&quot;张三&quot;);        System.out.println(&quot;使用静态工厂方法创建对象，隐藏创建对象的细节&quot;);        return person;    &#125;&#125;\n\n&lt;!--利用静态工厂实例化对象    --&gt;    &lt;bean id=&quot;personStaticFactory&quot; class=&quot;com.study.spring.factory.PersonStaticFactory&quot;          factory-method=&quot;createPerson&quot; &gt;&lt;/bean&gt;\n\n\n\n（3）基于工厂实例方法实例化对象/** * 工厂实例方法创建对象是指IoC容器对工厂类进行实例化并调用对应的实例方法创建对象的过程 */public class PersonFactoryInstance &#123;    public  Person createPerson() &#123;        Person person = new Person();        person.setAge(19);        person.setNickName(&quot;张三&quot;);        System.out.println(&quot;使用工厂实例方法创建对象，隐藏创建对象的细节&quot;);        return person;    &#125;&#125;\n\n&lt;!--利用工厂实例方法实例化bean --&gt;  &lt;bean id=&quot;personFactoryInstance&quot; class=&quot;com.study.spring.factory.PersonFactoryInstance&quot; &gt;&lt;/bean&gt;  &lt;bean id=&quot;wangwu&quot; factory-bean=&quot;personFactoryInstance&quot; factory-method=&quot;createPerson&quot; &gt;&lt;/bean&gt;\n\n\n\n从Spring IoC 容器获取bean// 创建IoC容器并根据配置文件创建对象（初始化IoC容器并实例化对象）ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;classpath:applicationContext.xml&quot;);Person person = ac.getBean(&quot;andy&quot;, Person.class);Person person1 = (Person) ac.getBean(&quot;nacos&quot;);\n\n\n\nxml 方式中 id 与 name属性相同点\nbean id 与 name 都是设置对象在 ioc 容器中唯一标识\n两者在同一配置文件中都不允许出现重复\n两者允许在多个配置文件中出现重复，新对象 覆盖旧对象\n\nxml 方式中 id 与 name 属性区别\nid 要求更为严格，一次只能定义一个对象标识（推荐）\nname 更为宽松，一次允许定义多个对象标识\ntips：id 与 name 的命名要求有意义。按驼峰命名书写\n\n&lt;!-- 没有 id 与 name，默认使用类全名 作为 bean 标识--&gt;&lt;bean class=&quot;com.study.spring.entity.Person&quot;&gt;    &lt;constructor-arg name=&quot;nickName&quot; value=&quot;andy2&quot; &gt;&lt;/constructor-arg&gt;    &lt;constructor-arg name=&quot;age&quot; value=&quot;118&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;\n\nApplicationContext ac = new ClassPathXmlApplicationContext(&quot;classpath:applicationContext.xml&quot;);Person p = (Person) ac.getBean(&quot;com.study.spring.entity.Person&quot;);\n\n\n\nSpring 配置文件，配置路径表达式\n\n加载Spring 的配置文件 // 加载单个配置文件ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;classpath:applicationContext.xml&quot;);\n\n// 加载多个配置文件String [] config = new String[]&#123;&quot;classpath:applicationContext.xml&quot;,&quot;classpath:applicationContext-2.xml&quot;&#125;;ApplicationContext applicationContext = new ClassPathXmlApplicationContext(config);\n\n\n\n对象依赖注入\n依赖注入是指运行时将容器内对象利用反射赋给其它对象的操作\n\n基于setter方法注入对象\n利用setter对象实现静态数值注入\n\n&lt;!--ioc 容器自动利用反射机制运行时调用 setXXX方法为属性赋值--&gt;    &lt;bean id=&quot;guog&quot; class=&quot;com.study.spring.entity.Person&quot;&gt;        &lt;property name=&quot;nickName&quot; value=&quot;guod&quot; &gt;&lt;/property&gt;        &lt;property name=&quot;age&quot; value=&quot;55&quot; &gt;&lt;/property&gt;    &lt;/bean&gt;\n\n\n利用setter对象实现对象注入\n\n基于构造方法注入对象\n\n\n","tags":["spring"]},{"title":"kingbase","url":"/kingbase/","content":"Kingbase 安装与启停安装前准备工作\n服务器安装jdk1.8+版本并配置环境变量\n\n创建kingbase用户组与用户。创建目录，并设置目录属组、属组、权限\n\n上传kingbase安装包和kingbase的license.dat 到服务器（安装包和license可以到官网下载） \n\n\n# 为了利于数据库的日常运维、持续使用、存储扩容等，我们在安装前需做好选项、存储目录规划# 使用root用户登录进服务器# /install 安装软件上传目录  # /kingbase/V8  数据库安装目录  # /backup 备份目录  # /data 数据存储目录  # /archive 归档目录[root@bu2-vm-svr-66 ~]# mkdir -p /install /KingbaseES/V8 /backup /data /archive# 上传 安装包、license.dat 到 /install 目录# 上传 执行脚本 optimize_system_conf_kcp.sh 和 optimize_database_conf.s 到 /install 目录# optimize_system_conf_kcp.sh 优化操作系统的脚本   optimize_database_conf.sh 优化数据库的脚本[root@bu2-vm-svr-66 ~]# ll /install总用量 852348-rw-r--r--. 1 root root 872781824 5月  11 03:27 KingbaseES_V008R006C005B0023_Lin                                      64_single_install.iso-rw-r--r--. 1 root root      3351 5月  11 03:27 license_12350_0.dat-rw-r--r--. 1 root root      6504 5月  11 03:27 optimize_database_conf.sh-rw-r--r--. 1 root root      8023 5月  11 03:27 optimize_system_conf_kcp.sh# 执行 optimize_system_conf_kcp.sh（优化操作系统的脚本）。主要帮我们 创建了kingbase 用户组和用户（用户密码：kingbase）。具体详情可以查看脚本内容bash /install/optimize_system_conf_kcp.sh[root@node1 install]# id kingbaseuid=1001(kingbase) gid=1001(kingbase) 组=1001(kingbase)# 修改目录属组、属主、权限chown -R kingbase:kingbase /install /KingbaseES /backup /archive /datachmod -R 775 /install /KingbaseES /backup /archivechmod -R 700 /data\n\n \n\nKingbase 安装# 我们使用的是 KingbaseES_V008R006C005B0023_Lin64_single_install.iso 文件，所以先使用root用户登录并挂载[root@node1 install]# mount -o loop /install/KingbaseES_V008R006C005B0023_Lin64_single_install.iso  /mnt/[root@node1 install]# ll /mnt/总用量 6dr-xr-xr-x. 2 root root 2048 11月  5 2021 setup-r-xr-xr-x. 1 root root 3820 11月  5 2021 setup.sh\n\n# # 使用kingbase 用户登录服务器 ，进入/mnt 下执行 setup.sh 则开始安装 （[kingbase@node1 mnt]$ cd /mnt[kingbase@node1 mnt]$ bash setup.sh# 也可以使用命令行安装./setup.sh -i console\n\n# 安装完成后 使用root用户登录进服务器，把数据库服务注册成系统服务。并启动数据库[root@node1 ~]# /KingbaseES/V8/install/script/root.sh# 把kingbase注册成系统服务后（root用户执行 /KingbaseES/V8/Scripts/root.sh 后）。kingbase已经启动了，但此时 为什么不可以使用 systemctl  这种方式启停 kingbase？# 必须 使用sys_ctl 数据库先停止. 然后再使用systemctl 启动数据. 才能成功启动, 因为systemctl 需要获取进程状态信息.\n\n\n运行 数据库优化文件\n\nbash /install/optimize_database_conf.sh\n\n\n\nKingbase 相关环境变量配置# 使用kingbase用户登录。配置ksql环境变量[root@sonronzy ~]# su - kingbase[kingbase@sonronzy ~]$ cd ~[kingbase@sonronzy ~]$ vi .bashrcexport PATH=/KingbaseES/V8/Server/bin:$PATH[kingbase@sonronzy ~]$ source .bashrc\n\n# 使用kingbase用户登录 ，使用sys_ctl 专用命令管理金仓数据库# 配置sys_ctl 环境变量[kingbase@sonronzy ~]$ cd ~[kingbase@sonronzy ~]$ vim .bashrcexport PATHexport KINGBASE_DATA=/dataexport PATH=/KingbaseES/V8/Server/bin:$PATH[kingbase@sonronzy ~]$ source .bashrc\n\n\n\nKingbase 启停# kingbase 是进程，kingbase8d 是服务# 注意没有修改linux参数的时候 systemctl 和 service 方式启停数据库 不要混用service kingbase8d start/stop/restart/statusservice kingbase8 start/stop/restart/statussystemctl start kingbase8d/etc/init.d/kingbase8d start# kingbase用户 ，使用sys_ctl 专用命令管理金仓数据库# 首先要配置 环境变量sys_ctl start/stop/restart/status\n\n# 有任何用户连接到数据库里来，都无法关闭数据库，必须等所有用户提交完数据断开连接后 才可关闭数据库。这个可能会关闭很长时间sys_ctl stop -m smart# 默认方式 关闭数据库。最好选用这个。 已经提交的用户踢开连接，未提交的用户 回滚，然后关闭数据库（一致状态，安全关闭方式）sys_ctl stop -m fast | sys_ctl stop# 断电式关闭数据库 (不推荐，可能会导致数据不一致，数据库无法启动)sys_ctl -m immediate\n\n\n\nKingbase 卸载# 使用root用户登录，进入到数据库的安装目录下的 Scripts 目录下，执行 rootuninstall.sh 卸载kingbase数据库cd /KingbaseES/V8/Scripts/KingbaseES/V8/Scripts/rootuninstall.sh# 最后确认已删除的kingbase8d 服务\n\n\n\n实践环境中常见的问题\n\n\n\n* 注意事项Kingbase数据库大小写敏感说明及转换Kingbase数据库大小写敏感说明及转换\n\n\nKingbase 客户端Kingbase 对象管理器\n我们安装kingbase的时候，如果选择完全安装，则会帮我们安装上 数据库对象管理工具\n使用Kingbase 对象管理器连接数据库 操作如下图\n\n\n\n模式\n业务软件所使用的对象的集合。包括：表、视图、序列、索引、函数、存储过程等……\n非模式对象：表空间\n\n\n\n其它客户端\n当我们不想在本机安装kingbase数据库时，可以选择第三方数据库客户端连接kingbase数据库。可以使用的相关客户端有：DBeaver、DataGrip 2020.1 x64、Dbvisualizer\n\n\n\nDBeaver\n官网 下载 DBeaver\n使用DBeaver 连接Kingbase 数据库 操作如下图\n\n\n\n\n\n \n\n\n\nksql 命令行工具\nKsql是Kingbase的交互式终端\n支持上下键翻页，tab键补全\n\n\n\nksql登录 、执行sql语句、sql脚本ksql -Usystem -h localhost -p54321 -W TESTksql -Usystem -W xjnxdb -lksql -Usystem -W xjnxdb -c  &quot;select * from xjnxdb.pa_user&quot;ksql -Usystem -W test -f /install/1.sql\n\n\n\nksql终端常用快捷键# 查看所有快捷键\\?# help\\h create# 查看当前有哪些数据库\\l# 查看表结构\\d xjxndb.pa_user\\c 切换数据库23:17:59 (system@[local]:54321)TEST=# \\c template1口令：您现在已经连接到数据库 &quot;template1&quot;,用户 &quot;system&quot;.23:18:09 (system@[local]:54321)template1=## 退出ksql终端\\q\n\n\n\n自定义sql提示符# 定制sql提示符，便于我们了解 目前在哪台终端、哪个用户、哪个数据库下操作# 使用kingbase用户登录[kingbase@sonronzy ~]$ vim ~/.ksqlrc[kingbase@sonronzy ~]$[kingbase@sonronzy ~]$ cat ~/.ksqlrc\\set PROMPT1 &#x27;%`date +%H:%M:%S` (%n@%M:%&gt;)%/%R%#%x &#x27;\\set PROMPT2 &#x27;%M %n@%/%R%# &#x27;[kingbase@sonronzy ~]$[kingbase@sonronzy ~]$ source ~/.ksqlrc[kingbase@sonronzy ~]$[kingbase@sonronzy ~]$ ksql -Usystem -W TEST口令：ksql (V8.0)输入 &quot;help&quot; 来获取帮助信息.23:13:03 (system@[local]:54321)TEST=#\n\n\\set PROMPT1 &#x27;%`date +%H:%M:%S` (%n@%M:%&gt;)%/%R%#%x &#x27;\\set PROMPT2 &#x27;%M %n@%/%R%# &#x27;\n\n解析：◆ %M      指数据库服务器的主机名 - 如果连接是通过 Unix 域套接字，则为“[local]”◆ %m      也表示数据库主机名，会截断第一个 . 后的内容◆ %&gt;        数据库端口号◆ %n        是指会话用户名◆ %/        当前数据库名◆ %#        如果是超级用户显示为 #，否则显示为 &gt;◆ %R        是指您处于单行模式（^）还是断开连接（！ ） ，但通常为=◆ %x        指的是事务状态 - 通常为空白，除非在事务块（*）\n\n\n常用sqlshow database_mode;show shared_buffers;select get_license_validdays();\n\n\n\n\n\ncopy 与 \\copy\ncopy 命令属于 SQL 命令， \\copy 命令属于元命令\ncopy 命令进行数据导出、导入时，需要具有 superuser 的权限；导出至 stdout 时，仅需模式、对象的相关权限即可；\\copy 命令进行数据导出、导入时，无需 superuser 权限\ncopy 命令只能在源数据库服务器上进行数据导出、导入；\\copy 命令还可以通过远程服务器连接至源数据库服务器，将数据导出至远程服务器、或将远程服务器的数据导入源数据库中\n大数据量的数据进行导出、导入时，copy 比\\copy 的性能高\n如果进行小数据量导出、导入，建议通过\\copy 操作便利；大数据量操作时，建议在源数据库中使用 copy 效率更高\n\n\n\nKingbase 数据迁移第一步：基础数据结构及数据迁移\n准备工作\n根据需要创建用户、表空间、模式等对象\n\n\n使用【数据库迁移工具】完成基础数据迁移工作\n\n\n\n第二步：应用接口及框架迁移springboot 数据源配置#环境业务自身配置开始#默认数据源default，不能修改spring.datasource.dynamic.primary = default#默认数据源，名称 default#spring.datasource.dynamic.datasource.default.driver-class-name=com.mysql.jdbc.Driver#spring.datasource.dynamic.datasource.default.url=jdbc:mysql://localhost:3306/xjnxdb?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTC&amp;useSSL=false#spring.datasource.dynamic.datasource.default.username=root#spring.datasource.dynamic.datasource.default.password=root#kingbase 数据源配置spring.datasource.dynamic.datasource.default.driver-class-name=com.kingbase8.Driverspring.datasource.dynamic.datasource.default.url=jdbc:kingbase8://10.114.12.66:54321/xjnxdbspring.datasource.dynamic.datasource.default.username=xjnxdbspring.datasource.dynamic.datasource.default.password=xjnxdb\n\n\n\nmaven 配置Kingbase 驱动在maven repository中查找kingbase的驱动依赖配置，加入到我们的pom文件\n&lt;!-- https://mvnrepository.com/artifact/kingbase/kingbase8 --&gt;&lt;dependency&gt;    &lt;groupId&gt;kingbase&lt;/groupId&gt;    &lt;artifactId&gt;kingbase8&lt;/artifactId&gt;    &lt;version&gt;8&lt;/version&gt;&lt;/dependency&gt;\n\n\n注意：我们会发现Kingbase8驱动依赖根本下载不下来。此时：我们可以把驱动下载到本地，再使用maven命令install到maven本地仓库即可\n\nkingbase8-8.jar\nmvn install:install-file -DgroupId=kingbase -DartifactId=kingbase8 -Dversion=8 -Dfile=D:\\bak\\kingbase8-8.jar -Dpackaging=jar -DgeneratePom=truemvn install:install-file -DgroupId=kingbase -DartifactId=kingbase8 -Dversion=8.6.0 -Dfile=H:\\bank\\kingbase8-8.6.0.jar -Dpackaging=jar -DgeneratePom=true\n\n\n该语句中参数：\nDgroupId ：组id 【对应pom中的groupId】DartifactId：项目id 【对应pom中的artifactId】Dversion：版本号 【对应pom中的version】Dfile：jar包的绝对路径Dpackaging：是什么包DgeneratePom：是否生成pom\n\n\n最后在pom中直接写入 dependency 就可以了，刷新即可使用\n\n&lt;!-- https://mvnrepository.com/artifact/kingbase/kingbase8 --&gt;&lt;dependency&gt;    &lt;groupId&gt;kingbase&lt;/groupId&gt;    &lt;artifactId&gt;kingbase8&lt;/artifactId&gt;    &lt;version&gt;8.6.0&lt;/version&gt;&lt;/dependency&gt;\n\n\n\n第三步：应用功能测试（SQL兼容情况）date_format 函数支持@Mapper@TableInfo(name = &quot;wf_sequence&quot;, primaryKeys = &#123;&quot;seqNo&quot;&#125;)public interface WfSequenceMapper &#123;\t@Update(&quot;update wf_sequence set seqval = seqval+1 where seqno=#&#123;seqNo&#125;&quot;)\tint incBySeqNo(@Param(&quot;seqNo&quot;) String seqNo);\t@Select(&quot;select * from wf_sequence where seqno=#&#123;seqNo&#125;&quot;)\tWfSequenceDO getBySeqNo(@Param(&quot;seqNo&quot;) String seqNo);\t@Insert(&quot;insert into wf_sequence (seqno,seqval,seqdesc)values(#&#123;seqNo&#125;,#&#123;seqVal&#125;,#&#123;seqDesc&#125;)&quot;)\tint insert(WfSequenceDO seq);\t@Select(&quot;SELECT concat(DATE_FORMAT(sysdate(),&#x27;%Y%m%d&#x27;),right(lpad(seqval,15,0),8)) as seqDesc FROM wf_sequence where seqno=#&#123;seqNo&#125;&quot;)\tWfSequenceDO getTxnBySeqNo(@Param(&quot;seqNo&quot;) String seqNo);&#125;\n\n00:28:12 (system@[local]:54321)TEST=# select date_format(&#x27;2022-05-15&#x27;,&#x27;yyyy-mm-dd&#x27;);错误:  函数 date_format(unknown, unknown) 不存在第1行select date_format(&#x27;2022-05-15&#x27;,&#x27;yyyy-mm-dd&#x27;);            ^提示:  没有匹配指定名称和参数类型的函数. 您也许需要增加明确的类型转换.00:28:15 (system@[local]:54321)TEST=#\n\n\n参考 《[应用开发及迁移][参考手册]KingbaseES扩展插件参考手册.pdf》\n\n\n\nkdb_date_function\n\nkdb_date_function 是一个兼容 mysql 数据库 date 相关函数的扩展。使用时需要 create extension kdb_date_function，不需要时 drop extension kdb_date_function 即可。\n\n00:41:28 (system@[local]:54321)TEST=# select date_format(&#x27;2022-05-15&#x27;,&#x27;yyyy-mm-dd&#x27;);错误:  函数 date_format(unknown, unknown) 不存在第1行select date_format(&#x27;2022-05-15&#x27;,&#x27;yyyy-mm-dd&#x27;);            ^提示:  没有匹配指定名称和参数类型的函数. 您也许需要增加明确的类型转换.00:41:29 (system@[local]:54321)TEST=#00:41:30 (system@[local]:54321)TEST=#00:41:30 (system@[local]:54321)TEST=#00:41:30 (system@[local]:54321)TEST=# create extension kdb_date_function;CREATE EXTENSION00:44:42 (system@[local]:54321)TEST=# select date_format(&#x27;2022-05-15&#x27;,&#x27;yyyy-mm-dd&#x27;); date_format------------- 2022-05-15(1 行记录)00:44:46 (system@[local]:54321)TEST=#\n\n\n\n数据库迁移评估系统\n具体详情参考官方文档\n\n","categories":["database","kingbase"],"tags":["database","kingbase"]},{"title":"linux实战技能","url":"/linux%E5%AE%9E%E6%88%98%E6%8A%80%E8%83%BD/","content":"学习备注\nlinux下的打包 压缩还需深入理解 和操作\n\nlinux 基础介绍\nlinux有两种含义\n\n一种是linus编写的开源操作系统内核\n另一种是广义的操作系统\n\n\n内核版本（分为三个部分）\n\n主版本号、次版本号、末版本号\n次版本号是奇数为开发版本，偶数为稳定版\n\n\n\nlinux 常见目录介绍\n/ 根目录\n/root root用户家目录\n/home/username 普通用户的家目录\n/etc 配置文件目录\n/bin 命令目录\n/sbin 管理命令目录\n/usr/bin /usr/sbin 系统预装的其它命令\n\nlinux 关机 / 重启 命令# 关机init 0# 延时关机 19:30关机shutdown -h 19:30# 延时30分钟关机shutdown -h +30 # 重启reboot\n\n系统操作帮助命令man# man是manual的缩写# 演示man ls\n\nhelp\nshell 自带的命令称为内部命令，其它的是外部命令\n\n# 内部命令使用 help 帮助help cd# 外部命令使用 help 帮助ls --help\n\ninfo\ninfo 帮助比 help 更详细，作为 help 的补充\n\ninfo ls\n\n文件 - 增删改查\nlinux 操作系统中，一切皆文件\n\n# 创建非空目录 mkdir [参数]# -p 递归创建目录mkdir -p [参数]\n\n# 删除非空目录rm [参数]# 递归删除目录（包括目录下的所有文件）rm -r [参数]# 不提示，无需确认，递归删除目录rm -rf [参数]\n\n# 仅仅复制文件cp [] []# 复制文件 or 目录cp -r [] []# -v 查看复制提示、过程  -p 复制的文件保留原文件的时间 -a 保留权限、保留属主cp -vpa [] []\n\n# 移动文件mv [参数] [源文件] [目标文件/目录]# 重命名mv [] []\n\n# 查看当前目录下的文件ls [选项...] [参数...]# -l 长格式显示文件# -a 显示隐藏文件# -r 逆序显示# -t 按照时间顺序显示# -R 递归显示ll\n\n通配符\n定义：shell 内建的符号\n用途：操作多个相似（有规律）的文件\n常用通配符\n* 匹配任意字符串\n? 匹配一个字符串\n[xyz] 匹配xyz任意一个字符\n[a-z] 匹配一个范围\n[!xyz] 或 [^xyz] 不匹配\n\n\n\n文本touch []\n\n# 文本内容显示到终端cat []# 查看文件开头 -number  表示查看文件开头的number行 。不加默认查看10行head -5 []# 查看文件结尾 -number 表示查看文件结尾哦的number行 。不加默认查看10行  -f文件内容更新后，显示同步更新tail -20 -f []# 统计文件内容信息wc []# 查看文件行数wc -l []more [filename]less [filename]\n\n打包 / 压缩","tags":["linux"]},{"title":"《Java 并发编程实战》study notes","url":"/%E3%80%8AJava-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/","content":"前言开篇词 | 你为什么需要学习并发编程？\n近几年，并发编程已经慢慢成为一项必备技能\n\n\n\n学习攻略 | 如何才能学好并发编程？跳出来，看全景\n首要之事就是你建立起一张全景图\n并发编程领域可以抽象成三个核心问题：分工、同步和互斥\n\n\n\n分工\nJava SDK 并发包里的 Executor、Fork/Join、Future 本质上都是一种分工方法\n并发编程领域总结出设计模式：生产者 - 消费者、Thread-Per-Message、Worker Thread 模式等都是用来指导你如何分工的\n\n\n学习这部分内容，最佳的方式就是和现实世界做对比。例如生产者 - 消费者模式，可以类比一下餐馆里的大厨和服务员，大厨就是生产者，负责做菜，做完放到出菜口，而服务员就是消费者，把做好的菜给你端过来。不过，我们经常会发现，出菜口有时候一下子出了好几个菜，服务员是可以把这一批菜同时端给你的。其实这就是生产者 - 消费者模式的一个优点，生产者一个一个地生产数据，而消费者可以批处理，这样就提高了性能\n\n\n\n同步\n在并发编程领域里的同步，主要指的就是线程间的协作。一个线程执行完了一个任务，如何通知执行后续任务的线程开工\n协作一般是和分工相关的。Java SDK 并发包里的 Executor、Fork/Join、Future 本质上都是分工方法，但同时也能解决线程协作的问题\n\n\n例如，用 Future 可以发起一个异步调用，当主线程通过 get() 方法取结果时，主线程就会等待，当异步执行的结果返回时，get() 方法就自动返回了。主线程和异步线程之间的协作，Future 工具类已经帮我们解决了\n\n\n线程协作问题，基本上都可以描述为：当某个条件不满足时，线程需要等待，当某个条件满足时，线程需要被唤醒执行\n\n\n例如，在生产者 - 消费者模型里：当队列满时，生产者线程等待，当队列不满时，生产者线程需要被唤醒执行；当队列空时，消费者线程等待，当队列不空时，消费者线程需要被唤醒执行\n\n\n在 Java 并发编程领域，解决协作问题的核心技术是管程，管程是解决并发问题的万能钥匙。（解决线程协作问题、互斥问题）\n\n\n这部分内容的学习，关键是理解管程模型，学好它就可以解决所有问题。其次是了解 Java SDK 并发包提供的几个线程协作的工具类的应用场景，用好它们可以妥妥地提高你的工作效率\n\n\n\n互斥\n分工、同步主要强调的是性能，但并发程序里还有一部分是关于正确性的，用专业术语叫“线程安全”。并发程序里，当多个线程同时访问同一个共享变量的时候，结果是不确定的。不确定，则意味着可能正确，也可能错误，事先是不知道的。而导致不确定的主要源头是可见性问题、有序性问题和原子性问题，为了解决这三个问题，Java 语言引入了内存模型，内存模型提供了一系列的规则，利用这些规则，我们可以避免可见性问题、有序性问题，但是还不足以完全解决线程安全问题。解决线程安全问题的核心方案还是互斥。\n\n\n互斥，指的是同一时刻，只允许一个线程访问共享变量\n\n实现互斥的核心技术就是锁\n\n\n\n锁解决了安全性问题，但同时也带来了性能问题，那如何保证安全性的同时又尽量提高性能呢？可以分场景优化，Java SDK 里提供的 ReadWriteLock、StampedLock 就可以优化读多写少场景下锁的性能。还可以使用无锁的数据结构，例如 Java SDK 里提供的原子类都是基于无锁技术实现的。\n除此之外，还有一些其他的方案，原理是不共享变量或者变量只允许读。这方面，Java 提供了 Thread Local 和 final 关键字，还有一种 Copy-on-write 的模式。\n使用锁除了要注意性能问题外，还需要注意死锁问题。\n\n\n这部分内容比较复杂，往往还是跨领域的，例如要理解可见性，就需要了解一些 CPU 和缓存的知识；要理解原子性，就需要理解一些操作系统的知识；很多无锁算法的实现往往也需要理解 CPU 缓存。这部分内容的学习，需要博览群书，在大脑里建立起 CPU、内存、I/O 执行的模拟器。这样遇到问题就能得心应手了。\n\n\n\n\n钻进去，看本质\n光跳出来还不够，还需要下一步，就是在某个问题上钻进去，深入理解，找到本质\n工程上的解决方案，一定要有理论做基础\n\n\n探索它背后的理论是什么。分析这些概念和结论是怎么来的，以及它们是用来解决什么问题的\n\n\n\n总结\n要让自己的知识成体系，一定要挖掘 Java SDK 并发包背后的设计理念\n分工、同步和互斥的全景图，是我对并发问题的个人总结，不一定正确，但是可以帮助我快速建立解决并发问题的思路，梳理并发编程的知识，加深认识\n对于某个具体的技术，我建议你探索它背后的理论本质\n探求理论本质，既能加深对技术本身的理解，也能拓展知识深度和广度，这是个一举多得的方法\n\n\n\n第一部分：并发理论基础01 | 可见性、原子性和有序性问题：并发编程Bug的源头并发程序幕后的故事\n核心矛盾一直存在，就是这三者（CPU、内存、I/O 设备）的速度差异\n为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为：\n\n\n\nCPU 增加了缓存，以均衡与内存的速度差异；\n操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；\n编译程序优化指令执行次序，使得缓存能够得到更加合理地利用\n\n\n源头之一：缓存导致的可见性问题源头之二：线程切换带来的原子性问题源头之三：编译优化带来的有序性问题总结课后思考备注","categories":["java","concurrent"],"tags":["concurrent","java"]},{"title":"《Kafka多维度系统精讲，从入门到熟练掌握》study notes","url":"/%E3%80%8AKafka%E5%A4%9A%E7%BB%B4%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%B2%BE%E8%AE%B2%EF%BC%8C%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%86%9F%E7%BB%83%E6%8E%8C%E6%8F%A1%E3%80%8Bstudy-notes/","content":""},{"title":"《Linux 实战技能 100 讲》study notes","url":"/%E3%80%8ALinux-%E5%AE%9E%E6%88%98%E6%8A%80%E8%83%BD-100-%E8%AE%B2%E3%80%8Bstudy-notes/","content":"linux 基础介绍\nlinux有两种含义\n\n一种是linus编写的开源操作系统内核\n另一种是广义的操作系统\n\n\nlinux内核版本（分为三个部分）\n\n主版本号、次版本号、末版本号\n次版本号是奇数为开发版本，偶数为稳定版\n\n\n\n\n\n\n\nlinux 常见目录介绍\n/ 根目录\n/root root用户家目录\n/home/username 普通用户的家目录\n/etc 配置文件目录\n/bin 命令目录\n/sbin 管理命令目录\n/usr/bin /usr/sbin 系统预装的其它命令\n\n\n\n\n\nlinux 关机/重启 命令# 关机init 0# 延时关机 19:30关机shutdown -h 19:30# 延时30分钟关机shutdown -h 30 # 停止延时关闭shutdown -c# 重启reboot\n\n\n\n\n\n\n\n系统操作帮助命令man# man是manual的缩写# 演示man ls\n\n\n\nhelp\nshell 自带的命令称为内部命令，其它的是外部命令\n\n# 内部命令使用 help 帮助help cd# 外部命令使用 help 帮助ls --help# 区分内部、外部命令 演示type cd\n\n\n\ninfo\ninfo 帮助比 help 更详细，作为 help 的补充\n\ninfo ls\n\n\n\n\n\n文件/目录 - 增删改查\nlinux 操作系统中，一切皆文件\n\n# 创建非空目录 mkdir [parameter]# -p 递归创建目录mkdir -p [parameter]\n\n# 删除非空目录rm [parameter]# 递归删除目录（包括目录下的所有文件）rm -r [parameter]# 不提示，无需确认，递归删除目录rm -rf [parameter]\n\n# 仅仅复制文件cp [] []# 复制文件 or 目录cp -r [] []# -v 查看复制提示、过程  -p 复制的文件保留原文件的时间 -a 保留权限、保留属主cp -vpa [] []cd [parameter]cd -cd ~\n\n# 移动文件mv [参数] [源文件] [目标文件/目录]# 重命名mv [] []\n\n# 查看当前目录下的文件ls [选项...]...# -l 长格式显示文件# -a 显示隐藏文件# -r 逆序显示# -t 按照时间顺序显示# -R 递归显示llpwd\n\n\n\n\n\n通配符\n定义：shell 内建的符号\n用途：操作多个相似（有规律）的文件\n常用通配符\n* 匹配任意字符串\n? 匹配一个字符串\n[xyz] 匹配xyz任意一个字符\n[a-z] 匹配一个范围\n[!xyz] 或 [^xyz] 不匹配\n\n\n\n\n\n\n\n文本touch [file_name]\n\n# 文本内容显示到终端cat [text_file_name]# 查看文件开头 -number  表示查看文件开头的number行 。不加默认查看10行head -5 []# 查看文件结尾 -number 表示查看文件结尾哦的number行 。不加默认查看10行  -f文件内容更新后，显示同步更新tail -20 -f []# 统计文件内容信息wc []# 查看文件行数wc -l []more [filename]less [filename]\n\n\n\n\n\n打包 / 压缩\n打包/压缩\n\ntar cf /tmp/etc.tar /etctar czf /tmp/etc.tar.gz /etctar cjf /tmp/etc.tar.bz2 /etc\n\n\n解包/解压缩\n\ntar xf /tmp/etc.tar -C /baktar zxf /tmp/etc.tar.gz -C /baktar jxf /tmp/etc.tar.bz2 -C /bak\n\n\n\n\n\n文本编辑器/vi/vim四种模式\n正常模式\n插入模式\n命令模式\n可视模式\n\n# 进入插入模式 i I o O a Ai 进入插入模式，光标不移动I 进入插入模式，光标移动到当前行的首字符a 进入插入模式，光标移动到下一个字符A 进入插入模式，光标移动到当前行的末尾o 进入插入模式，光标移动到当前行的下一行（新建一行）O 进入插入模式，光标移动到当前行的上一行（新建一行）# 进入可视 模式 v# 移动光标 h j k l yy 复制当前行p 粘贴3yy 复制3行y$ 复制光标位置到当前行文本结尾dd 剪切当前行d$ 剪切光标位置到当前行文本结尾u 撤销ctrl + r 对撤销的内容重做x 单个字符删除r + [新字符] 替换:set nu 显示行号:set nonu 不显示行号# 设置每次打开vim都显示行号vim /etc/vimrc# 在最后一行添加set nu# 保存退出后便生效11+shift+g 11+G    光标移动到11行gg 移动到第一行G 移动到最后一行shift+^ 移动到行首shift+$ 移动到行尾:w 保存:q 退出:wq 保存并退出:q! 不保存退出:! ll /etc/ 临时执行命令/x 查找x，按n匹配下一个，shift+n 匹配上一个字符:%s/x/X 全局替换查找到的第一个字符 （单次替换）:s/x/X 光标所在行替换，替换查找到的第一个字符 （单次替换）:%s/x/X/g 全局替换查找到的所有字符 :s/x/X/g 光标所在行替换，替换查找到的当前行的所有字符 :3,5s/x/X/g 第三行到第五行之间替换# v 字符可视化# V 行可视# ctrl+v 块可视\n\n\n\n\n\n用户和用户组管理# 会创建同名的用户组useradd [user_name]# 不加 -r 会保留用户的家目录，加 -r 会在删除用户的同时删除其家目录userdel -r [user_name]passwd#修改用户属性usermod# 修改用户家目录usermod -d /wilson wilson# 修改用户组usermod -g group1 wilson#修改用户属性（生命周期，密码修改周期等）chage# 用户信息会被记录到 /etc/passwd 文件中 /etc/shadow 这个是密码相关的文件groupadd# 新建用户并直接指定组useradd -g group1 lilygroupdel# 切换用户并切换home目录su - wilson# 以其它用户身份执行# visudo 设置需要使用sudo的用户组sudo visudo# 赋予Wilson 执行如下命令的权限wilson ALL=/sbin/shutdown -c\n\n\n\n\n\n文件与目录权限\n\n\n\n\n权限的前三个字符，表示所属用户对该文件的权限\n中间三个字符，表示所属用户组对该文件的权限\n最后三个字符表示其他人对该文件有什么权限\n\n\n\n\n\n文件类型• - 普通⽂文件• d ⽬目录⽂文件• b 块特殊⽂文件• c 字符特殊⽂文件• l 符号链接• f 命名管道• s 套接字⽂文件\n\n\n\n\n\n\n系统管理学习备注\nlinux下的打包 压缩还需深入理解 和操作\nvim\n\n","categories":["linux"],"tags":["linux"]},{"title":"《MySQL 8.0详解与实战》study notes","url":"/%E3%80%8AMySQL-8-0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/","content":"数据库选型SQL VS NOSQL\n\n\n类型\n示例\n特点\n适用场景\n\n\n\nSQL\nMySQLOracleSQLServerPostGreSQL\n数据结构化存储在二维表格中。支持事务的 ACID 特性。支持使用SQL语言对存储在其中的数据进行操作\n数据之间存在着一定关系，需要关联查询数据的场景。需要事务支持的业务场景。需要使用SQL语言灵活操作数据的场景。\n\n\nNOSQL\nHBaseMongoDBRedisHadoop\n存储结构灵活，没有固定的存储结构对事务的支持比较弱，但对数据的并发处理性能高大多不使用SQL语言操作数据\n数据结构不固定的场景对事务要求不高，但读写并发比较大的场景。对数据处理操作比较简单的场景\n\n\n\n\n\n\n关系数据库选型原则\n数据库使用的广泛性\n\n数据库的可扩展性\n\n支持基于二进制日志的逻辑复制\n存在多种第三方数据库中间件，支持读写分离，分库分表\n\n\n数据库的安全性和稳定性\n\nMySQL主从复制集群可达到99%的可用性\n配合主从复制高可用架构，可达到99%的可用性\n支持对存储在MySQL的数据，进行分级安全控制\n\n\n数据库所支持的系统\n\n支持Linux操作系统\n支持windows操作系统\n\n\n数据库的使用成本\n\n社区版本免费\n使用人员众多，社区活跃，可以方便获取技术支持\n\n\n\n\n\n\n\nMySQL 8.x 的安装\n服务器环境：CentOS 7 \n\n# （1）下载mysql的安装包[root@localhost ~]# cd /install/[root@localhost install]# wget https://cdn.mysql.com//Downloads/MySQL-8.0/mysql-8.0.31-el7-x86_64.tar.gz# （2）解压[root@localhost install]# tar -zxvf mysql-8.0.31-el7-x86_64.tar.gz# （3）移动mysql的位置，创建软连接（便于管理）[root@localhost install]# mv mysql-8.0.31-el7-x86_64 /usr/local/[root@localhost install]# cd /usr/local/[root@localhost local]# ln -s mysql-8.0.31-el7-x86_64/ mysql# （4）配置mysql# 先备份原 /etc/my.cnf 文件[root@localhost mysql]# cp /etc/my.cnf /etc/my.cnf.bak[root@localhost mysql]# vim /etc/my.cnf\n\n[client]port            = 3306socket          = /usr/local/mysql/data/mysql.sock[mysqld]# Skip #skip_name_resolve              = 1skip_external_locking          = 1 skip_symbolic_links     = 1# GENERAL #user = mysqldefault_storage_engine = InnoDBcharacter-set-server = utf8socket  = /usr/local/mysql/data/mysql.sockpid_file = /usr/local/mysql/data/mysqld.pidbasedir = /usr/local/mysqlport = 3306bind-address = 0.0.0.0explicit_defaults_for_timestamp = offsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES#read_only=on# MyISAM #key_buffer_size                = 32M#myisam_recover                 = FORCE,BACKUP# undo log #innodb_undo_directory = /usr/local/mysql/undoinnodb_undo_tablespaces = 8# SAFETY #max_allowed_packet             = 100Mmax_connect_errors             = 1000000sysdate_is_now                 = 1#innodb = FORCE#innodb_strict_mode = 1secure-file-priv=&#x27;/tmp&#x27;default_authentication_plugin=&#x27;mysql_native_password&#x27;# Replice # server-id = 1001 relay_log = mysqld-relay-bin gtid_mode = on enforce-gtid-consistency log-slave-updates = on master_info_repository =TABLE relay_log_info_repository =TABLE# DATA STORAGE # datadir = /usr/local/mysql/data/ tmpdir = /tmp # BINARY LOGGING # log_bin = /usr/local/mysql/sql_log/mysql-bin max_binlog_size = 1000M binlog_format = row binlog_expire_logs_seconds=86400# sync_binlog = 1 # CACHES AND LIMITS # tmp_table_size                 = 32M max_heap_table_size            = 32M max_connections                = 4000 thread_cache_size              = 2048 open_files_limit               = 65535 table_definition_cache         = 4096 table_open_cache               = 4096 sort_buffer_size               = 2M read_buffer_size               = 2M read_rnd_buffer_size           = 2M# thread_concurrency             = 24 join_buffer_size = 1M# table_cache = 32768 thread_stack = 512k max_length_for_sort_data = 16k # INNODB # innodb_flush_method            = O_DIRECT innodb_log_buffer_size = 16M innodb_flush_log_at_trx_commit = 2 innodb_file_per_table          = 1 innodb_buffer_pool_size        = 256M #innodb_buffer_pool_instances = 8 innodb_stats_on_metadata = off innodb_open_files = 8192 innodb_read_io_threads = 16 innodb_write_io_threads = 16 innodb_io_capacity = 20000 innodb_thread_concurrency = 0 innodb_lock_wait_timeout = 60 innodb_old_blocks_time=1000 innodb_use_native_aio = 1 innodb_purge_threads=1 innodb_change_buffering=all innodb_log_file_size = 64M innodb_log_files_in_group = 2 innodb_data_file_path  = ibdata1:256M:autoextend  innodb_rollback_on_timeout=on # LOGGING # log_error                      = /usr/local/mysql/sql_log/mysql-error.log # log_queries_not_using_indexes  = 1 # slow_query_log                 = 1  slow_query_log_file            = /usr/local/mysql/sql_log/slowlog.log # TimeOut # #interactive_timeout = 30 #wait_timeout        = 30 #net_read_timeout = 60[mysqldump]quickmax_allowed_packet = 100M[mysql]no-auto-rehash# Remove the next comment character if you are not familiar with SQL#safe-updates[myisamchk]key_buffer_size = 256Msort_buffer_size = 256Mread_buffer = 2Mwrite_buffer = 2M[mysqlhotcopy]interactive-timeout\n\n# （5）创建管理mysql的用户mysql[root@localhost mysql]# useradd mysql# （6）创建mysql相关数据目录，并修改文件权限[root@localhost mysql]# mkdir data sql_log undo[root@localhost mysql]# chown -R mysql:mysql data sql_log undo[root@localhost mysql]# lltotal 300drwxr-xr-x.  2  7161 31415   4096 Sep 14 01:50 bindrwxr-xr-x.  2 mysql mysql      6 Oct 24 13:43 datadrwxr-xr-x.  2  7161 31415     55 Sep 14 01:50 docsdrwxr-xr-x.  3  7161 31415   4096 Sep 14 01:50 includedrwxr-xr-x.  6  7161 31415    201 Sep 14 01:50 lib-rw-r--r--.  1  7161 31415 287627 Sep 14 00:15 LICENSEdrwxr-xr-x.  4  7161 31415     30 Sep 14 01:50 man-rw-r--r--.  1  7161 31415    666 Sep 14 00:15 READMEdrwxr-xr-x. 28  7161 31415   4096 Sep 14 01:50 sharedrwxr-xr-x.  2 mysql mysql      6 Oct 24 13:43 sql_logdrwxr-xr-x.  2  7161 31415     77 Sep 14 01:50 support-filesdrwxr-xr-x.  2 mysql mysql      6 Oct 24 13:43 undo# （7）配置mysql的环境变量[root@localhost mysql]# vim /etc/profile# 在 /etc/profile 文件末尾添加如下内容export PATH=$PATH:/usr/local/mysql/bin[root@localhost mysql]# source /etc/profile# （8）初始化mysql数据库[root@localhost mysql]# mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data# 验证：数据库初始化成功后，会在data目录下有相关文件生成# （9）拷贝数据库启动脚本[root@localhost mysql]# cp support-files/mysql.server /etc/init.d/mysqld# 至此，mysql数据库安装完成\n\n\n\n\n\nMySQL 启动[root@localhost mysql]# /etc/init.d/mysqld startStarting MySQL.. SUCCESS!# 获取mysql的初始密码[root@localhost mysql]# grep password sql_log/mysql-error.log# 登录mysql后，修改mysql的密码mysql&gt; alter user user() identified by &#x27;root&#x27;;Query OK, 0 rows affected (0.00 sec)\n\n\n\n\n\n\n\n数据库设计\n业务分析    =》    逻辑设计    =》    数据类型    =》    对象命名    =》 建立库表\n\n逻辑设计宽表模式存在的问题\n宽表模式：指把所有需求字段设计在一张表中\n\n\n\n\n\n\n\n数据冗余\n\n\n\n\n相同数据在一个表中出现了多次（增加数据占用空间）\n需要对数据进行多次维护（如果讲师的职位发生了变化，就需要对多条数据进行维护，如果有数据没有维护，就会导致数据不一致）\n\n\n\n\n\n宽表模式的应用场景\n配合列存储的数据报表应用\n\n\n\n\n\n数据库设计范式\n第一范式：要求有主键，并且要求每一个字段原子性不可再分\n第二范式：表中必须存在业务主键，并且非主键全部依赖于业务主键\n第三范式：表中的非主键列之间不能相互依赖\n\n\n\n\n\n\n反反范式化设计\n范式化设计存在的问题：为了满足范式化设计要求，我们对表拆分的很细。但是在查询时候关联的表会很多，影响性能\n为了提高查询性能，我们需要反范式化设计\n\n\n\n\n\n\n\n物理设计MySQL常见的存储引擎\n\n\n\n\n\nInnoDB存储引擎的特点\n事物型存储引擎支持ACID\n数据按主键聚集存储\n支持行级锁及MVCC\n支持Btree和自适应Hash索引\n支持全文和空间索引\n\n\n\n\n\n整数类型\n\n\n\n\n\n实数类型\n\n\n\n\n\n常用时间类型\n\n\n\n\n\n字符串类型\n\n\n\n\n\n选择合适的数据类型\n优先选择符合存储数据需求的最小数据类型\n谨慎使用ENUM,TEXT字符串类型\n同财务相关的数据类型，必须使用decimal类型\n\n\n\n\n\n数据库对象命名原则\n\n\n\n\n\n\n\n\n\n\n\nMySQL 访问数据库MySQL 访问异常处理\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n学习备注\n\n数据类型这块还需要加强一下呢\n\n\n&amp;emsp;&amp;emsp;\n\n\n\n\n\n\n\n\n\n\n\n","categories":["database","MySQL"],"tags":["database","MySQL"]},{"title":"《Nginx 核心知识 150 讲》study notes","url":"/%E3%80%8ANginx-%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86-150-%E8%AE%B2%E3%80%8Bstudy-notes/","content":"初识NginxNginx的三个主要应用场景\n静态资源服务\n\n通过本地文件系统提供服务\n\n\n反向代理服务\n\nNginx的强大性能\n缓存\n负载均衡\n\n\nAPI服务\n\nOpenResty\n\n\n\n\n\n\n\n\n\n\n\nNginx出现的历史背景\n互联网的数据量快速增长\n互联网的快速普及\n全球化\n物联网\n\n\n摩尔定律：性能提升\n低效的Apache\n一个连接对应一个进程\n\n\n\n\n\n\n\nNginx的5个主要优点（1）高并发，高性能\n（2）可扩展性好\n（3）高可靠性\n（4）热部署\n（5）BSD许可证\n\n\n\n\nNginx的4个主要组成部分（1）Nginx 二进制可执行文件\n\n由各模块源码编译出的一个文件\n\n（2）Nginx.conf 配置文件\n\n控制 Nginx 的行为\n\n（3）access.log 访问日志\n\n记录每一条 http 请求信息\n\n（4）error.log 错误日志\n\n定位问题\n\n\n\n\n\nNginx的版本发布历史\n\n\n\n\n开源免费的Nginx与商业版Nginx Plus\n阿里巴巴的Tengine\n免费OpenResty与商业版OpenResty\n\n\n\n\n\n编译Nginx\n如果要扩展第三方功能，可以使用编译方式安装nginx\n\n# （1）下载nginxwget https://nginx.org/download/nginx-1.22.0.tar.gztar -zxvf nginx-1.22.0.tar.gz# 安装相关依赖库yum install -y pcre pcre-devel gcc zlib zlib-devel# （2）编译安装[root@bogon nginx-1.22.0]# ./configure --prefix=/usr/local/nginx[root@bogon nginx-1.22.0]# make[root@bogon nginx-1.22.0]# make install\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n学习备注\n\n课程介绍中的问题\n\n\n\n&amp;emsp;&amp;emsp;\n\n\n\n\n\n\n\n\n\n","categories":["Nginx"],"tags":["Nginx","study-notes"]},{"title":"《Spring Data JPA 原理与实战》study notes","url":"/%E3%80%8ASpring-Data-JPA-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/","content":"Spring Data JPA基础知识Spring Data JPA优势\n某些大公司的大部分项目都在用 Spring Data JPA，究其原因，主要缘于它具有以下 4 点优势\n\n第一，大势所趋，大厂必备技能\n近两年由于 Spring Cloud、Spring Boot 逐渐统一 Java 的框架江湖，而与 Spring Boot 天然集成的 Spring Data JPA 也逐渐走进了 Java 开发者的视野，大量尝鲜者享受到了这门技术带来的便利与功能。JPA 可以使团队在框架约定下进行开发，几乎很难出现有性能瓶颈的 SQL。因此你会发现很多大厂，如阿里、腾讯、抖音等公司，近几年在招聘的时候写明了要熟悉 JPA，这些大厂以及业内很多开源的新项目都在使用 JPA\n\n\n\n第二，提升开发效率\n现在有很多人知道什么是 Spring Data JPA，但是却觉得 JPA 很难用，使用中发现 Bug 不知道原因，本来用 JPA 是为了提升开发效率的，不会使用反倒踩了很多坑，所以我们需要体系化地学习。当你遇到复杂问题，比如平时你可能要花几个小时去想方法名、SQL 逻辑，如果你可以熟练使用 JPA，那么半小时甚至几分钟就可以写好查询方法了；再配合测试用例，你的开发质量也会明显提高很多，系统地学习可以让你少走很多弯路\n\n\n\n第三，提高技术水平\nSpring Data 对数据操作进行了大统一，统一了抽象关系型数据库和非关系型数据的接口、公共的部分，你会发现当掌握了 Spring Data JPA 框架后，你的开发水平几乎可以达到——轻易实现 Redis、MongoDB 等 NoSQL 的操作，因为它们都有统一的 Spring Data Common。如下图所示，从中你可以看到 Spring Data 和 JPA 的全景位置关系，这样一来，你可以清楚地知道 JPA 的重要作用，方便你了解 JPA 的脉络，从而更好地学习\n\n\n\n\n\n第四，求职加分项\n如果简历中突出 Spring Data JPA 框架的使用，面试官会眼前一亮。因为掌握了 JPA，就意味着掌握了很多原理，比如 Session 原理、事务原理、PersistenceContext 原理等，而掌握了底层原理对于技术人员来说可以在开发中解决很多问题。因此，公司可以由此更好地过滤和筛选人才，也能从侧面看出求职者是否对技术足够感兴趣、有追求\n\n备注\n\n第一篇需要动手跟着学习构建\n\n\n","categories":["spring","jpa"],"tags":["spring","jpa"]},{"title":"《Web 协议详解与抓包实战》study notes","url":"/%E3%80%8AWeb-%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%8A%93%E5%8C%85%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/","content":"HTTP/1.1协议浏览器发起 HTTP 请求的典型场景\n\n\n\n\n\n\n\n\n\nHypertext Transfer Protocol (HTTP) 协议\na stateless application-level request/response protocol that usesextensible semantics and self-descriptive message payloads for flexibleinteraction with network-based hypertext information systems（RFC7230 2014.6）\n一种无状态的、应用层的、以请求/应答方式运行的协议，它使用可扩展的语义和自描述消息格式，与基于网络的超文本信息系统灵活的互动\n\n\n\nHTTP 协议格式\n\n\n\nABNF （扩充巴科斯-瑙尔范式）操作符\n空白字符：用来分隔定义中的各个元素\nmethod SP request-target SP HTTP-version CRLF\n\n\n选择 /：表示多个规则都是可供选择的规则\nstart-line = request-line / status-line\n\n\n值范围 %c##-## ：\nOCTAL = “0” / “1” / “2” / “3” / “4” / “5” / “6” / “7” 与 OCTAL = %x30-37 等价\n\n\n序列组合 ()：将规则组合起来，视为单个元素\n不定量重复 m*n：\n元素表示零个或更多元素： *( header-field CRLF )\n1* 元素表示一个或更多元素，2*4 元素表示两个至四个元素\n\n\n可选序列 []：\n[ message-body ]\n\n\n\n\n\n核心规则\n\n\n\n基于 ABNF 描述的 HTTP 协议格式HTTP-message = start-line *( header-field CRLF ) CRLF [ message-body ]\n\nstart-line = request-line / status-line\nrequest-line = method SP request-target SP HTTP-version CRLF\nstatus-line = HTTP-version SP status-code SP reason-phrase CRLF\n\n\nheader-field = field-name “:” OWS field-value OWS\nOWS = *( SP / HTAB )\nfield-name = token\nfield-value = *( field-content / obs-fold )\n\n\nmessage-body = *OCTET\n\n\n\nOSI（Open System Interconnection Reference Model）概念模型\n\n\n\nOSI 模型与 TCP/IP 模型对照\n\n\n\nWireshark 抓包及分析工具报文头部\n\nRoy Thomas Fielding 与 HTTP/1.1\n参与制订 HTTP/1.0 规范（1996.5）\n\n参与制订 URI 规范（1998.8）\n\n主导制订 HTTP/1.1 规范（1999.6）\n\n2000 年发布指导 HTTP/1.1 规范制订的论文\n\n《Architectural Style and the Design of Network-based SoftwareArchitectures》，即我们常谈的Representational State Transfer (REST)架构\n\n\nApache基金会（The Apache Software Foundation）共同创始人\n\n参与开发Apache httpd服务\n\n\n\nForm Follows Function：HTTP 协议为什么是现在这个样子\nHTTP 协议\n\nRoy Thomas Fielding：HTTP 主要作者，REST 架构作者\n\n\nURI：统一资源标识符\n\n\nHTTP 解决了什么问题？解决 WWW 信息交互必须面对的需求：• 低门槛• 可扩展性：巨大的用户群体，超长的寿命• 分布式系统下的 Hypermedia：大粒度数据的网络传输• Internet 规模• 无法控制的 scalability• 不可预测的负载、非法格式的数据、恶意消息• 客户端不能保持所有服务器信息，服务器不能保持多个请求间的状态信息• 独立的组件部署：新老组件并存• 向前兼容：自 1993 年起 HTTP0.9\\1.0（1996）已经被广泛使用\n评估 Web 架构的关键属性HTTP 协议应当在以下属性中取得可接受的均衡：\n性能 Performance：影响高可用的关键因素\n可伸缩性 Scalability：支持部署可以互相交互的大量组件\n简单性 Simplicity：易理解、易实现、易验证\n可见性 Visiable：对两个组件间的交互进行监视或者仲裁的能力。如缓存、分层设计等\n可移植性 Portability：在不同的环境下运行的能力\n可靠性 Reliability：出现部分故障时，对整体影响的程度\n可修改性 Modifiability：对系统作出修改的难易程度，由可进化性、可定制性、可扩展性、可配置性、可重用性构成\n\n\n\n架构属性：性能\n网络性能 Network Performance\nThroughput 吞吐量：小于等于带宽 bandwidth\nOverhead 开销：首次开销，每次开销\n\n\n用户感知到的性能 User-perceived Performance\nLatency 延迟：发起请求到接收到响应的时间\nCompletion 完成时间：完成一个应用动作所花费的时间\n\n\n网络效率 Network Efficiency\n重用缓存、减少交互次数、数据传输距离更近、COD\n\n\n\n\n\n架构属性：可修改性• 可进化性 Evolvability：一个组件独立升级而不影响其他组件• 可扩展性 Extensibility ：向系统添加功能，而不会影响到系统的其他部分• 可定制性 Customizability ：临时性、定制性地更改某一要素来提供服务，不对常规客户产生影响• 可配置性 Configurability ：应用部署后可通过修改配置提供新的功能• 可重用性 Reusabilit ：组件可以不做修改在其他应用在使用\n\n\n5 种架构风格\n数据流风格 Data-flow Styles\n优点：简单性、可进化性、可扩展性、可配置性、可重用性\n\n\n复制风格 Replication Styles\n优点：用户可察觉的性能、可伸缩性，网络效率、可靠性也可以提到提升\n\n\n分层风格 Hierarchical Styles\n优点：简单性、可进化性、可伸缩性\n\n\n移动代码风格 Mobile Code Styles\n优点：可移植性、可扩展性、网络效率\n\n\n点对点风格 Peer-to-Peer Styles\n优点：可进化性、可重用性、可扩展性、可配置性\n\n\n\n\n\nChrome 抓包：快速定位 HTTP 协议问题chrome-devtools\nChrome 抓包：Network 面板\n\n\n控制器：控制面板的外观与功能\n过滤器：过滤请求列表中显示的资源\n按住 Command （Mac）或 Ctrl （Window / Linux），然后点击过滤器可以同时选择多个过滤器\n\n\n概览：显示 HTTP 请求、响应的时间轴\n请求列表：默认时间排序，可选择显示列\n概要：请求总数、总数据量、总花费时间等\n\n控制器\n\n过滤器：按类型\nXHR、JS、CSS、Img、Media、Font、Doc、WS (WebSocket)、Manifest 或 Other（此处未列出的任何其他类型）\n多类型，按住 Command (Mac) 或 Ctrl（Windows、Linux）\n按时间过滤：概览面板，拖动滚动条\n隐藏 Data URLs：CSS 图片等小文件以 BASE64 格式嵌入 HTML 中，以减少 HTTP请求数\n\n过滤器：属性过滤\ndomain：仅显示来自指定域的资源。 您可以使用通配符字符 (*) 纳入多个域\n\nhas-response-header：显示包含指定 HTTP 响应标头的资源\n\nis：使用 is:running 可以查找 WebSocket 资源，is:from-cache 可查找缓存读出的资源\n\nlarger-than： 显示大于指定大小的资源（以字节为单位）。 将值设为 1000 等同于设置为1k\n\nmethod：显示通过指定 HTTP 方法类型检索的资源\n\nmime-type：显示指定 MIME 类型的资源\n\nmixed-content：显示所有混合内容资源 (mixed-content:all)，或者仅显示当前显示的资源(mixed-content:displayed)。\n\nscheme：显示通过未保护 HTTP (scheme:http) 或受保护 HTTPS (scheme:https) 检索的资源。\n\nset-cookie-domain：显示具有 Set-Cookie 标头并且 Domain 属性与指定值匹配的资源。\n\nset-cookie-name：显示具有 Set-Cookie 标头并且名称与指定值匹配的资源。\n\nset-cookie-value：显示具有 Set-Cookie 标头并且值与指定值匹配的资源。\n\nstatus-code：仅显示 HTTP 状态代码与指定代码匹配的资源。\n\n\n多属性间通过空格实现 AND 操作\n请求列表的排序\n时间排序，默认\n按列排序\n按活动时间排序\nStart Time：发出的第一个请求位于顶部\nResponse Time：开始下载的第一个请求位于顶部\nEnd Time：完成的第一个请求位于顶部\nTotal Duration：连接设置时间和请求/响应时间最短的请求位于顶部\nLatency：等待最短响应时间的请求位于顶部\n\n\n\n请求列表\nName : 资源的名称\nStatus : HTTP 状态代码\nType : 请求的资源的 MIME 类型\nInitiator : 发起请求的对象或进程。它可能有以下几种值：\nParser （解析器） : Chrome的 HTML 解析器发起了请求\n鼠标悬停显示 JS 脚本\n\n\nRedirect （重定向） : HTTP 重定向启动了请求\nScript （脚本） : 脚本启动了请求\nOther （其他） : 一些其他进程或动作发起请求，例如用户点击链接跳转到页面或在地址栏中输入网址\n\n\nSize : 服务器返回的响应大小（包括头部和包体），可显示解压后大小\nTime : 总持续时间，从请求的开始到接收响应中的最后一个字节\nWaterfall：各请求相关活动的直观分析图\n\n\n\n\n\n预览请求内容\n查看头部\n查看 cookie\n预览响应正文：查看图像用\n查看响应正文\n时间详细分布\n导出数据为 HAR 格式\n查看未压缩的资源大小：Use Large Request Rows\n\n\n浏览器加载时间（概览、概要、请求列表）\n\nDOMContentLoaded 事件的颜色设置为蓝色，而 load 事件设置为红色\n\n\n将请求数据复制到剪贴版\n\nCopy Link Address: 将请求的网址复制到剪贴板\nCopy Response: 将响应包体复制到剪贴板\nCopy as cURL: 以 cURL 命令形式复制请求\nCopy All as cURL: 以一系列 cURL 命令形式复制所有请求\nCopy All as HAR: 以 HAR 数据形式复制所有请求\n\n\n查看请求上下游：按住 shift 键悬停请求上，绿色是上游，红色是下游\n\n\n浏览器加载时间\n触发流程：\n解析 HTML 结构\n加载外部脚本和样式表文件\n解析并执行脚本代码 // 部分脚本会阻塞页面的加载\nDOM 树构建完成 // DOMContentLoaded 事件\n加载图片等外部文件\n页面加载完毕 // load 事件\n\n\n\n请求时间详细分布\nQueueing: 浏览器在以下情况下对请求排队\n存在更高优先级的请求\n此源已打开六个 TCP 连接，达到限值，仅适用于 HTTP/1.0 和 HTTP/1.1\n浏览器正在短暂分配磁盘缓存中的空间\n\n\nStalled: 请求可能会因 Queueing 中描述的任何原因而停止\nDNS Lookup: 浏览器正在解析请求的 IP 地址\nProxy Negotiation: 浏览器正在与代理服务器协商请求\nRequest sent: 正在发送请求\nServiceWorker Preparation: 浏览器正在启动 Service Worker\nRequest to ServiceWorker: 正在将请求发送到 Service Worker\nWaiting (TTFB): 浏览器正在等待响应的第一个字节。 TTFB 表示 Time To First Byte（至第一字节的时间）。 此时间包括 1 次往返延迟时间及服务器准备响应所用的时间\nContent Download: 浏览器正在接收响应\nReceiving Push: 浏览器正在通过 HTTP/2 服务器推送接收此响应的数据\nReading Push: 浏览器正在读取之前收到的本地数据\n\nURI的基本格式以及与URL的区别\n\n\n\n\n\n学习备注\n\nnginx -s 发送信号，做日志切割这个需要理解，需要了解课程中的日志切割shell\n如何让配置文件语法高亮\n\n\n&amp;emsp;&amp;emsp;\n\n\n\n\n\n\n\n\n\n\n\n","categories":["network"],"tags":["study-notes","wireshark","network"]},{"title":"《快速上手Linux 玩转典型应用》study notes","url":"/%E3%80%8A%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8BLinux-%E7%8E%A9%E8%BD%AC%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8%E3%80%8Bstudy-notes/","content":"WebServer安装和配置讲解Apache\n下载httpd\n\nyum install -y httpd\n\n\n配置虚拟主机\n\n","categories":["linux"],"tags":["linux"]},{"title":"《扛得住的MySQL数据库架构》study notes","url":"/%E3%80%8A%E6%89%9B%E5%BE%97%E4%BD%8F%E7%9A%84MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%B6%E6%9E%84%E3%80%8Bstudy-notes/","content":"\n\n\n\n\n\n学习备注\n1\n\n&amp;emsp;&amp;emsp;\n\n\n\n\n\n\n\n\n\n","categories":["database","MySQL"],"tags":["database","MySQL"]},{"title":"《深入拆解 Java 虚拟机》study notes","url":"/%E3%80%8A%E6%B7%B1%E5%85%A5%E6%8B%86%E8%A7%A3-Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8Bstudy-notes/","content":"","categories":["Java","jvm"],"tags":["jvm"]},{"title":"《玩转Java并发工具，精通JUC》 study notes","url":"/%E3%80%8A%E7%8E%A9%E8%BD%ACJava%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%EF%BC%8C%E7%B2%BE%E9%80%9AJUC%E3%80%8B-study-notes/","content":"线程池简介\n线程池的重要性：\n\n\n\n很多问题是没有用好线程池导致的\n\n线程池是面试中的高频考点，问题层层递进\n\n\n\n\n为什么要使用线程池\n\n\n\n反复创建线程开销大\n过多的线程会占用太多内存\n\n\n\n线程池的好处\n\n\n\n加快响应速度（不需要反复创建和销毁线程；消除了线程创建带来的延迟，增强用户体验）\n合理利用CPU和内存。控制资源总量（每一个Java程序中的线程，会直接对应到操作系统中的线程）（统筹资源，不至于线程过多，内存溢出，也不至于线程过少，浪费CPU资源。达到平衡——效率最高点）\n复用线程（解决线程反复创建销毁带来的开销问题）\n\n\n","categories":["java","concurrent"],"tags":["concurrent"]},{"title":"《理论+实战 构建完整JVM知识体系》study notes","url":"/%E3%80%8A%E7%90%86%E8%AE%BA-%E5%AE%9E%E6%88%98-%E6%9E%84%E5%BB%BA%E5%AE%8C%E6%95%B4JVM%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E3%80%8Bstudy-notes/","content":"认识JVM规范JVM概述\nJVM：Java Virtual Machine\n\n所谓虚拟机是指：通过软件模拟的，具有完整硬件系统功能的、运行在一个完全隔离环境中的计算机\n\nJVM是通过软件来模拟Java字节码的指令集，是Java程序的运行环境\n\n\n\n\n\n\nJVM主要功能\n通过ClassLoader寻找和加载class文件\n解释字节码成机器指令并执行，提供class文件运行环境\n进行运行期间的内存分配和垃圾回收\n提供与硬件交互的平台\n\n\n\n虚拟机是java平台无关的保障\n\n\n\nJVM规范JVM规范的作用\nJava虚拟机规范为不通的硬件平台提供了一种编译Java技术代码的规范\n该规范使Java软件独立于平台，因为编译是针对作为虚拟机的 ”一般机器“ 而做\n这个 ”一般机器“ ，可用软件模拟，并运行于各种现存的计算机系统，也可用硬件来实现\n\n\n\nJVM规范主要内容\ncpu(字节码指令集）\nclass文件格式\n数据类型和值\n运行时数据区\n栈帧\n特殊方法\n类库\n异常\n虚拟机的启动、加载、连接和初始化\n\n\n\nClass字节码","categories":["java","jvm"],"tags":["jvm"]},{"title":"《透视 HTTP 协议》study notes","url":"/%E3%80%8A%E9%80%8F%E8%A7%86-HTTP-%E5%8D%8F%E8%AE%AE%E3%80%8Bstudy-notes/","content":"开篇词 (1讲)开篇词｜To Be a HTTP Hero备注","categories":["network","http"],"tags":["network","http"]},{"title":"字符集和字符编码（Charset & Encoding）","url":"/%E5%AD%97%E7%AC%A6%E9%9B%86%E5%92%8C%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%EF%BC%88Charset-Encoding%EF%BC%89/","content":"引言\n复习Java I/O知识的时候，关于转换流有涉及到字符集的知识。于是想深入理解一下字符集和编码。（毕竟，字符编码是计算机技术、编程的基石，包括编程中涉及到的国际化问题，就必须懂得一点字符编码的知识）查阅相关资料后，并做了笔记\n\n\n\n// charsetName：指定字符编码 public InputStreamReader(InputStream in, String charsetName)public OutputStreamWriter(OutputStream out, String charsetName)\n\nInputStreamReader isr = new InputStreamReader(fis, &quot;GBK&quot;);OutputStreamWriter osw = new OutputStreamWriter(fos, &quot;GBK&quot;);\n\n\n\n\n\n\n\n基础知识编码和解码\n编码：信息按照一定的规则从一种形式或格式转换为另一种形式的过程\n解码：是一个编码的逆转换过程\n\n\n编码解码都是有一套预先规定的方案,无论是在编码过程还是解码过程,都要遵守这套规则来运算\n\n\n\n\n\n为什要编码解码\n在计算机中，是不能直接存储字符的，计算机中储存的信息都是用二进制数表示的；而我们在屏幕上看到的英文、汉字等字符是二进制数转换之后的结果。通俗的说，按照何种规则将字符存储在计算机中，如’a’用什么表示，称为”编码”；反之，将存储在计算机中的二进制数解析显示出来，称为”解码”，如同密码学中的加密和解密。在解码过程中，如果使用了错误的解码规则，则导致’a’解析成’b’或者乱码\n编码解码在不同的场景中具有不同的意义，比如常见的字符编码解码,URL编码解码等\n\n\n计算机为什么采用二进制：有很多原因.在这里简单的说几点,在技术上易实现,因为我们可以使用双稳态电路来表示1和0,高电平为1,低电平为0.且因为只有1和0,所以在传输和处理的过程中不容易出错.另外二进制的运算规则也相对来说简单.综合各方面因素,最终计算机采用二进制\n\n\n\n\n\n字符集（Charset）\n字符集（Charset）是一个系统支持的所有抽象字符的集合。字符是各种文字和符号的总称，包括各国家文字、标点符号、图形符号、数字等\n\n\n\n\n\n字符编码（Character Encoding）\n字符编码（Character Encoding）是一套法则，使用该法则能够对自然语言的字符的一个集合（如字母表或音节表），与其他东西的一个集合（如号码或电脉冲）进行配对。即在符号集合与数字系统之间建立对应关系，它是信息处理的一项基本技术。通常人们用符号集合（一般情况下就是文字）来表达信息。而以计算机为基础的信息处理系统则是利用元件（硬件）不同状态的组合来存储和处理信息的。元件不同状态的组合能代表数字系统的数字，因此字符编码就是将符号转换为计算机可以接受的数字系统的数，称为数字代码（通俗的讲：计算机字符编码就是将 计算机里展示的字符集 和 计算机能理解的二进制数 对应起来）\n\n\n\n\n\n乱码\n乱码就是因为使用了不对应的字符集导致部分或所有字符没法被正确阅读。（就比如我告诉你,打开新华字典的xx页的xx行,就是我想对你说的话.结果你拿了本牛津英汉字典,那你当然不能正确获取到我想对你说的话）\n\n\n\n\n\n为什么有时候乱码都是 ? 号\n在 Java 开发中，经常会碰到乱码显示为 ? 号，比如下面这个例子：\n\nString name = &quot;双子孤狼&quot;;byte[] bytes = name.getBytes(StandardCharsets.ISO_8859_1);System.out.println(new String(bytes));//输出：????\n\n\n这个输出结果的原因是中文无法用 ISO_8859_1 编码进行存储，而示例中却强制用 ISO_8859_1 编码进行解码\n\n\n在 Java 中提供了一个 ISO_8859_1 类用来解码，解码时当发现当前字符转成十进制之后大于 255 时就会直接不进行解码，转而直接赋一个默认值 63，所以上面的示例中的 byte 数组结果就是 63 63 63 63，而63 在 ASCII 中就恰好就对应了 ? 号。\n所以一般我们看到编码出现 ? 基本就说明当前是采用 ISO_8859_1 进行的解码，而当前的字符又大于 255\n\n\n\n\n\n\n\n常用字符集和字符编码\n常见字符集名称：ASCII字符集、GB2312字符集、BIG5字符集、GB18030字符集、Unicode字符集等。计算机要准确的处理各种字符集文字，需要进行字符编码，以便计算机能够识别和存储各种文字\n\n\n\n\n\n\n\n\n\n\n\nASCII字符集&amp;编码\n计算机最开始诞生于美国，而且计算机只能识别二进制，所以我们就需要把常用语言和二进制关联起来。美国人把英文里面常用的字符以及一些控制字符转换成了二进制数据，形成了一个编码对应关系表，这就是ASCII（American Standard Code for Information Interchange，美国信息交换标准代码）字符集和ASCII编码\nASCII（American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统。它主要用于显示现代英语，而其扩展版本EASCII则可以勉强显示其他西欧语言。它是现今最通用的单字节编码系统（但是有被Unicode追上的迹象），并等同于国际标准ISO/IEC 646\n\n\n\n\n\n\n\n\nASCII字符集：主要包括控制字符（回车键、退格、换行键等）；可显示字符（英文大小写字符、阿拉伯数字和西文符号）\nASCII编码：将ASCII字符集转换为计算机可以接受的数字系统的数的规则\n\n\n\n\n\n\n\n\n使用7位（bits）表示一个字符，共128字符；但是7位编码的字符集只能支持128个字符，为了表示更多的欧洲常用字符对ASCII进行了扩展，ASCII扩展字符集使用8位（bits）表示一个字符，共256字符\n\n\n\n\nASCII编码表\n\n\n\n\n\n\n扩展ASCII编码表\n\n\n\n\n\n\nASCII的最大缺点是只能显示26个基本拉丁字母、阿拉伯数目字和英式标点符号，因此只能用于显示现代美国英语（而且在处理英语当中的外来词如naïve、café、élite等等时，所有重音符号都不得不去掉，即使这样做会违反拼写规则）。而EASCII虽然解决了部份西欧语言的显示问题，但对更多其他语言依然无能为力。因此现在的苹果电脑已经抛弃ASCII而转用Unicode\n\n\n\n\n\nGBXXXX字符集&amp;编码\n当天朝也有了计算机之后，ASCII字符集（编码）不够用。为了显示中文，必须设计一套编码规则用于将汉字转换为计算机可以接受的数字系统的数\n天朝专家把那些127号之后的奇异符号们（即EASCII）取消掉，规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，还把数学符号、罗马希腊的 字母、日文的假名们都编进去了，连在ASCII里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了\n\n\n\n\n\nGB2312字符集&amp;编码GB2312字符集设计\n\n\n\n\n01~09区表示除汉子外的682个字符\n\n\n\n\n\n\n10~15区是空白区\n\n16~55区收录3755个一级汉字，按拼音排序\n\n\n\n\n\n\n\n56~87区收录了3008个二级汉字，按部首/笔画排序（不太常用的、生僻汉字）\n\n\n\n\n\n\n\nGB2312字符编码设计\n规定如何在计算机中存储\n\n\n\n\n\n\n以侃这个字为例，侃这个字的码位是 5709，按前两位和后两位分开（57和09）并将其转化为16进制（0x39和0x09），再分别加上0xA0，得到0xD9和0xA9，再将其组合到一起得到0xD90xA9，0xD90xA9便是侃这个字的GB2312编码值。即计算机使用GB2312编码时，侃这个字在计算机中存储的16进制形式是：D9A9\n\n\nJava获取某个汉字的GB2312编码值\n\n\n\n\n\n\n\nGB2312字符集扩展\n\n\n\n\n\n\n\nUnicode字符集&amp;UTF编码\nUnicode 只是一个字符集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储\n\nunicode是一个标准，其包含了对应的字符集和编码规则。UTF-32/ UTF-16/ UTF-8是三种字符编码方案（即：UTF-8 是 Unicode 的实现方式之一）\n\n\n\n\n\n\n\n\n\n\nUTF-8 编码\nUTF-8（8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码（定长码），也是一种前缀码。它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部份修改，即可继续使用\n\nUTF-8编码是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度（每次传送8位数据）\n\nUTF-8 的编码规则（存储规范）：\n\n对于单字节的符号，字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的\n对于n字节的符号（n &gt; 1），第一个字节的前n位都设为1，第n + 1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码\n\n\n\n\n\n\nUnicode符号范围（十六进制）\nUTF-8编码方式（二进制）\n\n\n\n0x0000 0000 - 0x0000 007F\n0xxxxxxx\n\n\n0x0000 0080 - 0x0000 07FF\n110xxxxx 10xxxxxx\n\n\n0x0000 0800 - 0x0000 FFFF\n1110xxxx 10xxxxxx 10xxxxxx\n\n\n0x0001 0000 - 0x0010 FFFF\n11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\n\n\n\n跟据上表（字母x表示可用编码的位），解读 UTF-8 编码非常简单。如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节\n\n\n以汉字严为例，演示如何实现 UTF-8 编码\n\n\n严的 Unicode 是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800 - 0000 FFFF），因此严的 UTF-8 编码需要三个字节，即格式是1110xxxx 10xxxxxx 10xxxxxx。然后，从严的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，严的 UTF-8 编码是11100100 10111000 10100101，转换成十六进制就是E4B8A5。（即：计算机使用Unicode编码时，严这个字在计算机中存储的16进制形式是：E4B8A5）\n\n\n\n\n\n参考与延伸\n阮一峰博客：字符编码笔记：ASCII，Unicode 和 UTF-8\nrunoob（菜鸟教程）：字符集和字符编码\n字符集历史\n\n","categories":["computer","character encoding"],"tags":["computer","character encoding"]},{"title":"浅析 I/O（1）—— 操作系统内存简介","url":"/%E6%B5%85%E6%9E%90-I-O%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%AE%80%E4%BB%8B/","content":"操作系统的应用与内核&emsp;&emsp;现代计算机是由硬件和操作系统组成，我们的应用程序要操作硬件（如往磁盘上写数据），就需要先与内核交互，然后再由内核与硬件交互；\n&emsp;&emsp;操作系统可以划分为：内核与应用两部分；\n&emsp;&emsp;内核提供进程管理、内存管理、网络等底层功能，封装了与硬件交互的接口，通过系统调用提供给上层应用使用。\n\n\n\n\n\n\n\n\n内核空间与用户空间&emsp;&emsp;现在操作系统都是采用虚拟地址空间，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间（内核空间），也有访问底层硬件设备的所有权限。\n&emsp;&emsp;为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。内核空间是操作系统内核访问的区域，独立于普通的应用程序，是受保护的内存空间。用户空间是普通应用程序可访问的内存区域。\n&emsp;&emsp;针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。\n\n\n&emsp;&emsp;用户态的程序不能随意操作内核地址空间，即使用户的程序崩溃了，内核也不受影响。这样对操作系统具有一定的安全保护作用。\n\n\n\n\n\n\nCPU指令等级&emsp;&emsp;其实早期操作系统是不区分内核空间和用户空间的，但是应用程序能访问任意内存空间，如果程序不稳定常常把系统搞崩溃，比如清除操作系统的内存数据。后来觉得让应用程序随便访问内存太危险了，就按照CPU 指令的重要程度对指令进行了分级；\n\n\n\n\n&emsp;&emsp;CPU指令分为四个级别：Ring0~Ring3，linux 只使用了 Ring0 和 Ring3 两个运行级别，进程运行Ring3级别的指令时运行在用户态，指令只访问用户空间，而运行在 Ring0级别时被称为运行在内核态，可以访问任意内存空间。\n\n\n\n\n\n\n进程的内核态和用户态&emsp;&emsp;当进程运行在内核空间时，它就处于内核态；当进程运行在用户空间时，它就处于用户态。\n\n那什么时候运行再内核空间什么时候运行再用户空间呢？\n\n\n当我们需要进行IO操作时，如读写硬盘文件、读写网卡数据等，进程需要切换到内核态，否则无法进行这样的操作，无论是从内核态切换到用户态，还是从用户态切换到内核态，都需要进行一次上下文的切换。一般情况下，应用不能直接操作内核空间的数据，需要把内核态的数据拷贝到用户空间才能操作。\n\n\n比如我们 Java 中需要新建一个线程，调用 start() 方法时，基于Hotspot Linux 的JVM 源码实现，最终是调pthread_create系统方法来创建的线程，这里会从用户态切换到内核态完成系统资源的分配，线程的创建。\n\n\n\n\n当一个任务（进程）执行系统调用而陷入内核代码中执行时，称进程处于内核运行态（内核态）\n\n\nTips：除了系统调用可以实现用户态到内核态的切换，软中断和硬中断也会切换用户态和内核态。\n\n\n在内核态下：进程运行在内核地址空间中，此时 CPU 可以执行任何指令。运行的代码也不受任何的限制，可以自由地访问任何有效地址，也可以直接进行端口的访问。\n在用户态下：进程运行在用户地址空间中，被执行的代码要受到 CPU 的很多检查，比如：进程只能访问映射其地址空间的页表项中规定的在用户态下可访问页面的虚拟地址。\n\n\n\n\n\n\n\n术语解释核心态/内核态(Kernel model)和用户态(User model)&emsp;&emsp;核心态(Kernel model)和用户态(User model)，CPU会在两个model之间切换。\n\n核心态代码拥有完全的底层资源控制权限，可以执行任何CPU指令，访问任何内存地址，其占有的处理机是不允许被抢占的。内核态的指令包括：启动I/O，内存清零，修改程序状态字，设置时钟，允许/终止中断和停机。内核态的程序崩溃会导致PC停机。\n用户态是用户程序能够使用的指令，不能直接访问底层硬件和内存地址。用户态运行的程序必须委托系统调用来访问硬件和内存。用户态的指令包括：控制转移，算数运算，取数指令，访管指令（使用户程序从用户态陷入内核态）。\n\n\n\n\n\n\n\n进程切换&emsp;&emsp;为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：\n\n\n保存处理机上下文，包括程序计数器和其他寄存器。\n更新PCB信息。\n把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。\n选择另一个进程执行，并更新其PCB。\n更新内存管理的数据结构。\n恢复处理机上下文。\n\n\n\n\n\n\n\n\n文件描述符(fd, File Descriptor)&emsp;&emsp;FD用于描述指向文件的引用的抽象化概念。文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。\n\n\n\n\n","categories":["Operating-Systems","I/O"],"tags":["Operating-Systems","I/O"]},{"title":"浅析 I/O（2）—— I/O分类","url":"/%E6%B5%85%E6%9E%90-I-O%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94-I-O%E5%88%86%E7%B1%BB/","content":"\n\n\n通常用户进程中的一个完整IO分为两阶段：用户进程空间&lt;- -&gt;内核空间、**内核空间&lt;- -&gt;设备空间(磁盘、网络等)**。\n\n\n\n\n\n网络IO &amp; 磁盘IO&emsp;&emsp;IO从读取数据的来源分为内存IO、 网络IO和磁盘IO三种，通常我们说的IO指的是后两者(因为内存IO的读写速度比网络IO和磁盘IO快的多)。\n&emsp;&emsp;I/O按照设备来分的话，分为两种：一种是网络I/O，也就是通过网络进行数据的拉取和输出。一种是磁盘I/O，主要是对磁盘进行读写工作。\n\n\n\n类型\n概念解释\n\n\n\n网络IO\n等待网络数据到达网卡→把网卡中的数据读取到内核缓冲区，然后从内核缓冲区复制数据到进程空间\n\n\n磁盘IO\n把数据从磁盘中读取到内核缓冲区，然后从内核缓冲区复制数据到进程空间\n\n\n\nTips：由于CPU和内存的速度远远高于外部设备（网卡，磁盘等）的速度，所以在IO编程中，存在速度严重不匹配的问题。\n\n\n\n\n\n同步IO &amp; 异步IO\n\n\n类型\n概念解释\n\n\n\n同步IO\nA调用B，B的处理是同步的，在处理完之前他不会通知A，只有处理完之后才会明确的通知A。B在没有处理完A的请求时不能处理其他请求；\n\n\n异步IO\nA调用B，B的处理是异步的，B在接到请求后先告诉A我已经接到请求了，然后异步去处理，处理完之后通过回调等方式再通知A。B在处理A请求的同时，也可以接着处理其他人发送过来的请求；\n\n\n&emsp;&emsp;同步和异步最大的区别就是被调用方的执行方式和返回时机。同步指的是被调用方做完事情之后再返回，异步指的是被调用方先返回，然后再做事情，做完之后再想办法通知调用方。\n\n\n\n\n阻塞IO &amp; 非阻塞IO\n\n\n类型\n概念解释\n\n\n\n非阻塞IO\nA调用B，A不用一直等着B的返回，先去忙别的事情了。\n\n\n阻塞IO\nA调用B，A一直等着B的返回，别的事情什么也不干。\n\n\n&emsp;&emsp;阻塞和非阻塞最大的区别就是在被调用方返回结果之前的这段时间内，调用方是否一直等待。阻塞指的是调用方一直等待别的事情什么都不做。非阻塞指的是调用方先去忙别的事情。\n\n\n\nTips：同步IO和异步IO强调的是被调用方（B），阻塞IO和非阻塞IO强调的是调用方（A）；\n\n\n\n\n\n","categories":["Operating-Systems","I/O"],"tags":["Operating-Systems","I/O"]},{"title":"浅析 I/O（3）—— I/O模型","url":"/%E6%B5%85%E6%9E%90-I-O%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94-I-O%E6%A8%A1%E5%9E%8B/","content":"\n\n\n网络通信中，最底层的就是内核中的网络 I/O 模型了。\n\n\n随着技术的发展，操作系统内核的网络模型衍生出了五种 I/O 模型，《UNIX网络编程》一书将这五种 I/O 模型分为 阻塞式 I/O、非阻塞式 I/O、I/O 复用、信号驱动式 I/O 和 异步 I/O。每一种 I/O 模型的出现，都是基于前一种 I/O 模型的优化升级。\n\n\n\n\n\n\n\n① 阻塞IO模型\n阻塞式 IO （Blocking IO）：应用进程从发起 IO 系统调用，至内核返回成功标识，这整个期间是处于阻塞状态的。\n\n\n当应用A发起读取数据申请时，在内核数据没有准备好之前，应用A会一直处于等待数据状态，直到内核把数据准备好了交给应用A才结束。\n\n\nTips：我们之前所学过的所有的套接字，默认都是阻塞方式。\n\n\n\n\n\n\n\n\n\n\n\n优点：开发相对简单，在阻塞期间，用户线程被挂起，挂起期间不会占用CPU资源；\n缺点：\n1）连接利用率不高，内核如果没有响应数据，则该连接一直处于阻塞状态，占用连接资源\n2）一个线程维护一个IO资源，当用大量并发请求时，需要创建等价的线程来处理请求，不适合用于高并发场景；\n\n\n\n\n\n\n\n\n\n② 非阻塞IO模型\n非阻塞式IO（Non-Blocking IO）：应用进程可以将 Socket 设置为非阻塞，这样应用进程在发起 IO 系统调用后，会立刻返回。应用进程可以轮询的发起 IO 系统调用，直到内核返回成功标识。\n\n\n当应用A发起读取数据申请时，在内核数据没有准备好之前，应用A会一直处于等待数据状态，直到内核把数据准备好了交给应用A才结束。\n\n\n\n\n\n\n\n\n\n\n优点：每次发起IO调用去内核获取数据时，在内核等待数据的过程中可以立即返回，用户线程不会被阻塞，实时性较好；\n缺点：\n1）当用户线程A没有获取到数据时，不断轮询内核，查看是否有新的数据，占用大量CPU时间，效率不高；\n2）和阻塞IO一样，一个线程维护一个IO资源，当用大量并发请求时，需要创建等价的线程来处理请求，不适合用于高并发场景；\n\n\n\n\n\n\n\n\n\n③ 复用IO模型（IO多路复用模型）\nIO 多路复用（IO Multiplexin）：可以将多个应用进程的 Socket 注册到一个 Select（多路复用器）上，然后使用一个进程来监听该 Select（该操作会阻塞），Select 会监听所有注册进来的 Socket。只要有一个 Socket 的数据准备好，就会返回该Socket。再由应用进程发起 IO 系统调用，来完成数据读取。\n\n\n\n\n\n\n\n\n\n&emsp;&emsp;如果在并发的环境下，可能会N个人向应用B发送消息，这种情况下我们的应用就必须创建多个线程去接收N个人发送过来的请求，每个请求都是一个独立的线程来处理；在并发量呈线性增长时，我们需要创建的线程数也随之而然的激增；\n\n\n\n\n&emsp;&emsp;这种情况下应用B就需要创建N个线程去读取数据，同时又因为应用线程是不知道什么时候会有数据读取，为了保证消息能及时读取到，那么这些线程自己必须不断的向内核发送请求来读取数据（非阻塞式）；\n&emsp;&emsp;这么多的线程不断请求数据，先不说服务器能不能扛得住这么多线程，就算扛得住那么很明显这种方式是不是太浪费资源了，线程是我们操作系统的宝贵资源，大量的线程用来去读取数据了，那么就意味着能做其它事情的线程就会少。\n&emsp;&emsp;后来，有人就提出了一个思路，能不能提供一种方式，可以由一个线程监控多个网络请求（linux系统把所有网络请求以一个fd来标识，我们后面将称为fd即文件描述符），这样就可以只需要一个或几个线程就可以完成数据状态询问的操作，当有数据准备就绪之后再分配对应的线程去读取数据，这么做就可以节省出大量的线程资源出来，这个就是IO复用模型的思路。\n\n\n\n\n&emsp;&emsp;IO复用模型的思路就是系统提供了一种函数（select/poll/epoll）可以同时监控多个fd的操作，有了这个函数后，应用线程通过调用select函数就可以同时监控多个fd，如果select监听的fd都没有可读数据，select调用进程会被阻塞；而只要有任何一个fd准备就绪了，select函数就会返回可读状态，这时询问线程再去通知处理数据的线程，对应的线程此时再发起请求去读取内核中准备好的数据；\n\nTips：在IO复用模型下，允许单线程内处理多个IO请求；\n\n\n\n\n\n\nLinux中IO复用的实现方式主要有select，poll和epoll\n\n1）select\n线性轮询扫描所有的fd，不管他们是否活跃，监听的IO最大连接数不能多于FD_ SIZE（32位操作系统1024，64位操作系统2048）。\n时间复杂度O(n)\n\n\nTips：select方式仅仅知道有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），用户线程只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。\n\n\n\n2）poll\n原理和select相似，poll底层需要分配一个pollfd结构数组，维护在内核中，它没有数量限制，但IO数量大，扫描线性性能下降。\n时间复杂度O(n)\n\n\n\n3）epoll\n用于代替poll和select，没有大小限制。epoll采用事件驱动代替了轮询，epoll会把哪个流发生了怎样的I/O事件通知用户线程，所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时用户线程对这些流的操作都是有意义的。（复杂度降低到了O(1)），另外epoll模型采用mmap内存映射实现内核与用户空间的消息传递，减少用户态和内核态数据传输的开销，epoll模型在Linux2.6后内核支持。\n时间复杂度O(1)\n\n\n\n\n\nselect，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符准备就绪，能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写(一个个的处理)，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。\n\n\nTips：epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现\n\n\n\n复用IO模型小结\n关于IO复用模型，下面这个例子可以很好的说明IO复用模型的原理：\n\n\n某教室有10名学生和1名老师，这些学生上课会不停的提问，所以一个老师处理不了这么多的问题。那么学校为每个学生都配一名老师，也就是这个教室目前有10名老师。此后，只要有新的转校生，那么就会为这个学生专门分配一个老师，因为转校生也喜欢提问题。如果把以上例子中的学生比作客户端，那么老师就是负责进行数据交换的服务端。则该例子可以比作是多进程的方式。\n后来有一天，来了一位具有超能力的老师，这位老师回答问题非常迅速，并且可以应对所有的问题。而这位老师采用的方式是学生提问前必须先举手，确认举手学生后在回答问题。则现在的情况就是IO复用。\n\n\nIO复用模型的优点：系统不必创建和维护大量的线程，只使用一个或几个线程来监听select选择器的操作，而一个选择器可同时处理成千上万个连接，大大减少了系统的开销；\nIO复用模型的缺点：select本质上还是同步阻塞模式；\n\n&emsp;&emsp;总结： 复用IO的基本思路就是通过select或poll、epoll来监控多fd ，来达到不必为每个fd创建一个对应的监控线程，从而减少线程资源创建的目的。复用IO模型的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。\n\n\n\n\n\n\n④ 信号驱动IO模型\n信号驱动 IO（Signal Driven IO）：可以为 Socket 开启信号驱动 IO 功能，应用进程需向内核注册一个信号处理程序，该操作并立即返回。当内核中有数据准备好，会发送一个信号给应用进程，应用进程便可以在信号处理程序中发起 IO 系统调用，来完成数据读取了。\n\n\n\n\n\n\n\n&emsp;&emsp;当进程发起一个IO操作，系统调用sigaction执行一个信号处理函数，该函数向内核注册一个信号处理函数（回调函数），然后进程返回，并且不阻塞当前进程；当内核数据准备好时，内核使用信号（SIGIO）通知应用线程调用recvfrom来读取数据（运行回调函数）。\n&emsp;&emsp;信号驱动IO它也可以看成是一种异步非阻塞IO\n\n\n\n\n&emsp;&emsp;我们说信号驱动IO模型是一种异步非阻塞IO模型，指的是用户线程去内核空间请求数据时，直接注册一个信号处理函数，然后用户线程返回（异步），而内核空间接收到请求后，开始处理（此时并不会阻塞，内核空间可以同时接收多个请求，注册多个信号处理函数）；\n&emsp;&emsp;但是，等到内核空间读取到数据之后，应用线程需要将数据从内核空间拷贝到用户空间，此时是用户线程是阻塞的；也就是说：应用程序将数据从内核态拷贝到用户态的过程是阻塞等待的，这是和异步IO的本质区别；\n\n\n\n\n\n\n⑤ 异步IO模型\n异步 IO（Asynchronous IO）： 应用进程发起 IO 系统调用后，会立即返回。当内核中数据完全准备后，并且也复制到了用户空间，会产生一个信号来通知应用进程。\n\n\n\n\n\n\n\n\n\n&emsp;&emsp;在前面几种IO模型中，应用线程要获取数据总是先发送请求到内核，然后进行如下处理：\n\n1）阻塞IO：应用线程等待内核响应数据，期间什么都不能做\n2）非阻塞IO：应用线程立即响应，可以去处理其他事情，但需要不断轮询内核去获取数据\n3）复用IO：采用IO复用机制，请求都先交给select函数，由应用线程调用select函数来轮询所有的请求，当有请求需要获取数据时，应用线程再去内核获取数据；\n4）信号驱动IO：系统注册一个信号处理函数（回调函数），然后应用线程返回（不阻塞）；当内核中准备好数据后，应用线程需要把内核中的数据拷贝到用户空间，此时用户线程是阻塞的；\n\n&emsp;&emsp;在以上4种IO模型中，每次要去读取数据时都是事先发送请求询问内核是否有可读数据，然后再发起真正的读取数据请求；\n&emsp;&emsp;在异步IO模型中，应用只需要向内核发送一个请求，告诉内核它要读取数据后即刻返回；内核收到请求后会建立一个信号联系，当数据准备就绪，内核会主动把数据从内核复制到用户空间（而信号驱动是告诉应用程序何时可以开始拷贝数据），异步IO模型真正的做到了完完全全的非阻塞；\n\nTips：异步IO模型和前面模型最大的区别是：前4个都是阻塞的，需要自己把用户准备好的数据，去内核拷贝到用户空间。而全异步不同，用户线程完全不需要关心实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接去使用数据，它是最理想的模型。\n\n\n\n\n\n\n\n总结&emsp;&emsp;从上述五种 IO 模型可以看出，应用进程对内核发起 IO 系统调用后，内核会经过两个阶段来完成数据的传输：\n\n第一阶段：等待数据。即应用进程发起 IO 系统调用后，会一直等待数据；当有数据传入服务器，会将数据放入内核空间，此时数据准备好。\n第二阶段：将数据从内核空间复制到用户空间，并返回给应用程序成功标识。\n\n\n\n\n\n&emsp;&emsp;前四种模型的第二阶段是相同的，都是处于阻塞状态，其主要区别在第一阶段。而异步 IO 模型则不同，应用进程在这两个阶段是完全不阻塞的。\n\n\n\nIO 模型\n第一阶段\n第二阶段\n\n\n\n阻塞式IO\n阻塞\n阻塞\n\n\n非阻塞式IO\n非阻塞\n阻塞\n\n\nIO多路程复用\n阻塞（Select）\n阻塞\n\n\n信号驱动式IO\n异步\n阻塞\n\n\n异步IO\n异步\n异步\n\n\n\n\n\n\n\n\nReference\nsegmentfault：浅聊Linux的五种IO模型\nw3cjava：五种IO模型：操作系统五种IO模型大全\n\n\n\n","categories":["Operating-Systems","I/O"],"tags":["Operating-Systems","I/O"]},{"title":"浅析 —— 同步异步&阻塞非阻塞","url":"/%E6%B5%85%E6%9E%90-%E2%80%94%E2%80%94-%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5-%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E/","content":"\n\n\n\n\n\n学习备注\n1\n\n&amp;emsp;&amp;emsp;\n\n\n\n\n\n\n\n\n\n","categories":["Operating-Systems","I/O"],"tags":["Operating-Systems","communication-mechanism"]},{"title":"Java - I/O 系统","url":"/Java-I-O-%E7%B3%BB%E7%BB%9F/","content":"认识I/O流\nI/O是Input/Output的缩写， I/O技术是非常实用的技术，用于处理设备之间的数据传输。如读/写文件，网络通讯等\n\n\n\n\n\n\n\n\n\nJava如何解决I/O问题\nJava将任意数据源或者数据接收端表达为一个具有生成或者接受数据片段能力的对象（以表示“流”的抽象）。Java程序中，对于数据的输入/输出操作以“流(stream)” 的方式进行\n流（Stream）是一个抽象的概念，当程序需要读取数据的时候，就会开启一个通向数据源的流，数据源可以是文件，内存，或是网络连接。反过来，当程序需要写入数据的时候，就会开启一个通向目的地的流。\n\n\n\n\n\n\n\n\n\n\njava.io包下提供了各种“流”类和接口，且使用装饰器模式来解决扩展功能的问题，用以获取不同种类的数据，并通过标准的方法输入或输出数据\nJava的IO流共涉及40多个类，实际上非常规则，都是从如下4个抽象基类派生的（由这四个类派生出来的子类名称都是以其父类名作为子类名后缀）\n\n\n\n\n\n\n（抽象基类）\n字节流\n字符流\n\n\n\n输入流\nInputStream\nReader\n\n\n输出流\nOutputStream\nWriter\n\n\n\n\n\nJava中所有流流均是由它们派生出来的\n\n\n\n\n\n\n\nJava I/O 流的历史\nJava 1.0 I/O库诞生，分为输入和输出两类，面向字节。输入相关的类都继承自InputStream，输出相关的类都继承自OutputStream，且整体使用了装饰器的设计模式\nJava 1.1 对I/O库进行了重大的修改，不但增强了面向字节的类库功能，还新增了面向字符的Reader和Writer，以解决国际化的问题，延续了装饰器的设计模式\nJava 1.4 引入了java.nio(new I/O），使用通道（channel），缓冲区（buffer），选择器（Selector）等措施极大的提升了性能\nJava 1.7/1.8 对难用的文件I/O的操作体验进行了巨大的改进，且新增了Asynchronous IO（AIO），这时nio也有了一个别名，称之为non-blocking I/O\n\n\nJava8 函数式流和 I/O 流之间并无任何关联\n\n\n\n\n\n\n\n流的分类数据单元：字节流和字符流\n按操作数据单位不同分为：字节流(8 bit)，字符流(16 bit)\n\n\n\n\n\n\n类型\n说明\n\n\n\n字节流(8 bit)\n以字节为单位获取数据，命名上以Stream结尾的流一般是字节流，如FileInputStream、FileOutputStream。 字节流可以处理任何一切形式的数据源，包括音频，视频，图片，纯文本，Word，Excel等等\n\n\n字符流(16 bit)\n以字符为单位获取数据，命名上以Reader/Writer结尾的流一般是字符流，如FileReader、FileWriter。 字符流只能处理字符串，纯文本等。Java使用Unicode的统一标准字符集，一个字符占用两个字节\n\n\n\n\n\n\n字节流（InputStream 和 OutputStream）\n一切的数据在计算机中都可表示为字节\n在不同源之间的字节数据的输入与输出，可形象的表示为“字节的流动”，即字节流\n表示从不同源输入的类：InputStream\n文件, 字节数组，字符串对象，管道，其他流，网络等…\n\n\n表示输出到不同源的类：OutputStream\n\n\n\n\n\n\n\n\n\n字符流（Reader 和 Writer）\nJava 1.0时代的I/O流类库只能支持8位字节流，无法妥善处理16位Unicode字符\nReader和Writer类并不是为了取代InputStream和OutputStream，而是提供了字符操作的能力，为了在所有的I/O操作中都支持Unicode\n在需要操作字符的场景中尽量都使用Reader和Writer相关的类，而在需要进行字节操作的场景中，面向字节的InputStream和OutputStream才是正确的选择，比如读取和写入图片文件，java.util.zip库\n\n\n\n\n\n\n\n\n\nUnicode\nUnicode(统一码)，它整理和编码了世界上大部分的文字系统，使得电脑可以用更简单的方式呈现和处理文字。它遵循通用字符集 (UCS)并规定了其实现方式，即如何映射为计算机的字节，如何传输等。\n\n\n\n\n\n\n\n\n\nUnicode 与 Java\nJava使用Unicode的统一标准字符集\nJava使用UTF-16编码，所以会将字符串表示为一系列16位的单元，如果标准字符集中字符的数值大于16位（超出U+FFFF），则会拆分为两个16位的单元用以表示一个字符。对于能用16位内数字表示的字符，Unicode的字符数值（Code Point）和UTF-16编码后的16位的单元（Code Unit），是一致的。\n\n\n\n\n\n\n\n\n\n流的方向：输入流和输出流\n按数据流的流向不同分为：输入流，输出流\n\n\n\n\n\n\n类型\n说明\n\n\n\n输入流\n数据流向是数据源到程序（以InputStream、Reader结尾的流）\n\n\n输出流\n数据流向是程序到目的地（以OutputStream、Writer结尾的流）\n\n\n\n\n\n\n处理对象：节点流和处理流\n按流的角色（处理对象）的不同分为：节点流，处理流\n\n\n\n\n\n\n类型\n说明\n\n\n\n节点流\n可以从或向一个特定的地方（节点）读写数据，如FileInputStream、FileReader、DataInputStream等。 （ 没有节点流，处理流发挥不了任何作用。）\n\n\n处理流\n不直接连接到数据源或目的地，是 “处理流的流”。通过对已有的节点流进行包装，通过所封装的流的功能调用实现数据读写，提高性能或提高程序的灵活性。 如BufferedInputStream、BufferedReader等。处理流的构造方法总是要带一个其他的流对象做参数。一个流对象经过其他流的多次包装，称为流的链接。处理流也叫 ”包装流/过滤流“。\n\n\n\n\n\n\n\n\n\n\nI/O类型\n按I/O类型来分类\n\n\n\n\n\n\n类型\n说明\n\n\n\n文件流\n对文件进行读、写操作 ：FileReader、FileWriter、FileInputStream、FileOutputStream\n\n\n缓冲流\n在读入或写出时，数据可以基于缓冲批量读写，以减少I/O的次数：BufferedReader、BufferedWriter、BufferedInputStream、BufferedOutputStream\n\n\n内存流\n1.从/向内存数组读写数据: CharArrayReader、 CharArrayWriter、ByteArrayInputStream、ByteArrayOutputStream 2.从/向内存字符串读写数据 StringReader、StringWriter、StringBufferInputStream\n\n\n转换流\n按照一定的编码/解码标准将字节流转换为字符流，或进行反向转换（Stream到Reader,Writer的转换类）：InputStreamReader、OutputStreamWriter\n\n\n对象流\n字节流与对象实例相互转换,实现对象的序列化 ：ObjectInputStream、ObjectOutputStream 注意: 1.读取顺序和写入顺序一定要一致，不然会读取出错。 2.在对象属性前面加transient关键字，则该对象的属性不会被序列化\n\n\n打印流\n只有输出,没有输入，在整个IO包中，打印流是输出信息最方便的类,分为 PrintWriter（字符打印流）、PrintStream(字节打印流)\n\n\nDataConversion数据流\n按基本数据类型读/写，可以字节流与基本类型数据相互转换：DataInputStream、DataOutputStream\n\n\n过滤流\n在数据进行读或写时进行过滤：FilterReader、FilterWriter、FilterInputStream、FilterOutputStream\n\n\n合并流\n把多个输入流按顺序连接成一个输入流 ：SequenceInputStream\n\n\n操作ZIP包流\nZipInputStream可以读取zip格式的流，ZipOutputStream可以把多份数据写入zip包\n\n\n操作JAR包流\nJarInputStream/JarOutputStream,派生自ZipInputStream/ZipOutputStream，它增加的主要功能是直接读取jar文件里面的MANIFEST.MF文件。因为本质上jar包就是zip包，只是额外附加了一些固定的描述文件。\n\n\n管道流\n线程交互的时候使用，管道输出流可以连接到管道输入流，以创建通信管道。管道输出流是管道的发送端。通常数据由某个线程写入管道输出流，并由其他线程从连接的管道输入流读取。注意，管道输出流和输入流需要对接。: PipedReader、PipedWriter、PipedInputStream、PipedOutputStream\n\n\nCounting计数\n在读入数据时对行记数 ：LineNumberReader、LineNumberInputStream\n\n\n推回输入流\n通过缓存机制，进行预读 ：PushbackReader、PushbackInputStream\n\n\n接收和响应客户端请求流\nservletinputstream：用来读取客户端的请求信息的输入流 servletoutputstream:可以将数据返回到客户端\n\n\n随机读取写入流\nRandomAccessFile 既可以读取文件内容，也可以向文件输出数据，RandomAccessFile 对象包含一个记录指针，标识当前读写处的位置，可以控制记录指针从IO任何位置读写文件\n\n\n加密流\n对流加密/解密 CipherOutputStream 由一个 OutputStream 和一个 Cipher 组成 ,write() 方法在将数据写出到基础 OutputStream 之前先对该数据进行处理(加密或解密) , 同样CipherInputStream是由InputStream和一个Cipher组成,read()方法在读入时,对数据进行加解密操作\n\n\n数字签名流\nDigestInputStream : 最大的特点是在读取的数据的时候已经调用MessageDigest实例的update方法，当数据从底层的数据流中读取之后就只可以直接调用MessageDigest实例的digest()方法了，从而完成对输入数据的摘要加密 DigestOutputStream :最大的特点是在向底层的输出流写入数据的时候已经调用MessageDigest实例的update方法，并作为MessageDigest的输入数据，之后就可以直接调用MessageDigest实例的digest()方法完成加密过程；同样的，是否对数据加密也是由该流的on(boolean b)方法进行控制的，如果设置成false，那么在写出数据的过程中便不会将数据传给update方法，那么此时它跟普通的输出流就没有任何区别了\n\n\n\n\n\nCipherInputStream和CipherOutputStream与DigestInputStream/DigestOutputStream/类似，只是后者更为彻底，它们不用在显示地调用传入的Cipher对象的update和doFinal方法，加密或解密过程在读写数据的同时已经隐式地完成了\n\n\n\n\n\n\n\nI/O 流体系I/O流体系图\n下图基于Java 1.8制作，其中需要注意的是StringBufferInputStream和LineNumberInputStream已被废弃\n\n\nStringBufferInputStream: 该类无法准确的将字符转换为字节，推荐用StringReader来取代使用\nLineNumberInputStream: 该类错误地认为字节能恰当地表示字符，推荐使用字符流的类来取代，即LineNumberReader\n\n\n\n\n\n\nI/O流体系类库\n\n\n分类\n字节输入流\n字节输出流\n字符输入流\n字符输出流\n\n\n\n抽象基类\nInputStream\nOutputStream\nReader\nWriter\n\n\n访问文件\nFileInputStream\nFileOutputStream\nFileReader\nFileWriter\n\n\n访问数组\nByteArrayInputStream\nByteArrayOutputStream\nCharArrayReader\nCharArrayWriter\n\n\n访问管道\nPipedInputStream\nPipedOutputStream\nPipedReader\nPipedWriter\n\n\n访问字符串\n\n\nStringReader\nStringWriter\n\n\n缓冲流\nBufferedInputStream\nBufferedOutputStream\nBufferedReader\nBufferedWriter\n\n\n转换流\n\n\nInputStreamReader\nOutputStreamWriter\n\n\n对象流\nObjectInputStream\nObjectOutputStream\n\n\n\n\n抽象基类\nFilterInputStream\nFilterOutputStream\nFilterReader\nFilterWriter\n\n\n打印流\n\nPrintStream\n\nPrintWriter\n\n\n推回输入流\nPushbackInputStream\n\nPushbackReader\n\n\n\n特殊流\nDataInputStream\nDataOutputStream\n\n\n\n\n\n\n\n注：表中粗体所表示的类代表节点流。斜体 表示的类代表抽象基类，无法直接创建实例。其他的为处理流\n\n\n\n\n\nRandomAccessFile\n自成体系，Java输入/输出流体系中功能最丰富的文件内容访问类，既可以读取文件内容，也可以向文件输出数据。\n不支持装饰器，无法与InputStream/OutputStream联合起来用\n与普通的输入/输出流不同的是，RandomAccessFile支持跳到文件任意位置读写数据（支持读写随机文件），可将文件视为在磁盘上的一个大的字节数组，我们能通过数组下标（文件指针）来访问里面的内容\nRandomAccessFile对象包含一个记录指针，标识当前读写处的位置，当程序创建一个新的RandomAccessFile对象时，该对象的文件记录指针对于文件头（也就是0处），当读写n个字节后，文件记录指针将会向后移动n个字节，RandomAccessFile可以通过seek()方法自由移动记录指针\n使用RandomAccessFile就必须知道文件的布局，确定要操作的位置\n优先考虑使用nio的内存映射\n\n\n\n\n\nRandomAccessFile使用\n操作文件记录指针\n\n// 返回文件记录指针的当前位置long getFilePointer()    // 将文件记录指针定位到pos位置void seek(long pos)\n\n\n\n\nRandomAccessFile类在创建对象时，除了指定文件本身，还需要指定一个mode参数。该参数指定RandomAccessFile的访问模式，该参数有如下四个值：\n\n\n\nr：以只读方式打开指定文件。如果试图对该RandomAccessFile指定的文件执行写入方法则会抛出IOException\nrw：以读取、写入方式打开指定文件。如果该文件不存在，则尝试创建文件\nrws：以读取、写入方式打开指定文件。相对于rw模式，还要求对文件的内容或元数据的每个更新都同步写入到底层存储设备，默认情形下(rw模式下),是使用buffer的,只有cache满的或者使用RandomAccessFile.close()关闭流的时候儿才真正的写到文件\nrwd：与rws类似，只是仅对文件的内容同步更新到磁盘，而不修改文件的元数据\n\n\n\n\n\n\nI/O流的主要类\n整个Java.io包中最重要的就是5个类和一个接口\n\n\n\n\n\n5个类：\n\n\n类\n说明\n\n\n\nFile\n表示一个文件或者目录,可以获取文件或目录相关属性,以及创建文件或目录\n\n\nInputStream\n字节输入流父类，单位为字节，定义了所有字节输入流的基本操作\n\n\nOutputStream\n字节输出流父类，单位为字节，定义了所有字节输出流的基本操作\n\n\nReader\n字符输入流父类，单位为字符，定义了所有字符输入流的基本操作\n\n\nWriter\n字符输出流父类，单位为字符，定义了所有字符输出流的基本操作\n\n\n\n\n\nJava中所有流均是由它们派生出来的\njdk 1.4版本开始引入了新I/O类库，它位于 java.nio 包中，新I/O类库利用通道和缓冲区等来提高I/O操作的效率\n\n\n\n\n\n1个接口：\n\n\n类\n说明\n\n\n\nSerializable\n序列化/反序列化对象需要实现 Serializable接口\n\n\n\n\n\n\nI/O流主要三个部分\n\n\n部分\n说明\n\n\n\n流式部分\nI/O的主体部分\n\n\n非流式部分\n主要包含一些辅助流式部分的类，如：File类、RandomAccessFile类和FileDescriptor等类。 RandomAccessFile（随机读取和写入流）可以从文件的任意位置进行读写）\n\n\n其他类\n文件读取部分的与安全相关的类，如：SerializablePermission类，以及与本地操作系统相关的文件系统的类，如：FileSystem类和Win32FileSystem类和WinNTFileSystem类\n\n\n\n\n\n\n重要I/O流的解读转换流\n\n标准输入、输出流\n\n打印流\n\n数据流\n\n对象流\n\n随机存取文件流\n\n\n\n\n\nI/O流API实践字符流：FileReader - FileWriter /**     * 从某个文件的内容写入到另一个文件     *  1. read()的理解：返回读入的一个字符。如果达到文件末尾，返回-1     *     read(char[] cbuf):返回每次读入cbuf数组中的字符的个数。如果达到文件末尾，返回-1     *  2. 异常的处理：为了保证流资源一定可以执行关闭操作。需要使用try-catch-finally处理     *  3. 读入的文件一定要存在，否则就会报FileNotFoundException。     *     * 1. 输出操作，对应的File可以不存在的。并不会报异常     * 2.     *          File对应的硬盘中的文件如果不存在，在输出的过程中，会自动创建此文件。     *          File对应的硬盘中的文件如果存在：     *                 如果流使用的构造器是：FileWriter(file,false) / FileWriter(file):对原有文件的覆盖     *                 如果流使用的构造器是：FileWriter(file,true):不会对原有文件覆盖，而是在原有文件基础上追加内容     *  3. 流的关闭顺序，没有严格顺序     */    @Test    public void testFileReaderFileWriter()&#123;        FileReader fr = null;        FileWriter fw = null;        try &#123;            // 1.File类的实例化            // 2.流实例化            fr = new FileReader(new File(&quot;hello.txt&quot;));            fw = new FileWriter(new File(&quot;hello2.txt&quot;),true);            char [] cbuf = new char[5];            int len;            // 3.流操作-读入 写出            while ((len = fr.read(cbuf)) != -1)&#123;                fw.write(cbuf,0,len);            &#125;        &#125; catch (IOException e) &#123;            throw new RuntimeException(e);        &#125;finally &#123;            //4.关闭流资源            //方式一：            try &#123;                if(fw != null)                    fw.close();            &#125; catch (IOException e) &#123;                e.printStackTrace();            &#125;finally&#123;                try &#123;                    if(fr != null)                        fr.close();                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;            //方式二：//            if (null != fw)&#123;//                try &#123;//                    fw.close();//                &#125; catch (IOException e) &#123;//                    throw new RuntimeException(e);//                &#125;//            &#125;//            if (null != fr) &#123;//                try &#123;//                    fr.close();//                &#125; catch (IOException e) &#123;//                    throw new RuntimeException(e);//                &#125;//            &#125;        &#125;    &#125;\n\n\n\n\n\n字节流：FileInputStream - FileOutputStream\n使用 FileInputStream、FileOutputStream实现文件复制\n\n//指定路径下文件的复制// 使用字节流FileInputStream处理文本文件，可能出现乱码。   public void copyFile(String srcPath,String destPath)&#123;       FileInputStream fis = null;       FileOutputStream fos = null;       try &#123;           // File 实例化           File srcFile = new File(srcPath);           File destFile = new File(destPath);           // 造流           fis = new FileInputStream(srcFile);           fos = new FileOutputStream(destFile);           // 流操作 - 复制的过程           byte[] buffer = new byte[1024];           int len;           while((len = fis.read(buffer)) != -1)&#123;               fos.write(buffer,0,len);           &#125;       &#125; catch (IOException e) &#123;           e.printStackTrace();       &#125; finally &#123;           if(fos != null)&#123;               //               try &#123;                   fos.close();               &#125; catch (IOException e) &#123;                   e.printStackTrace();               &#125;           &#125;           if(fis != null)&#123;               try &#123;                   fis.close();               &#125; catch (IOException e) &#123;                   e.printStackTrace();               &#125;           &#125;       &#125;   &#125;\n\n\n\n\n\n缓冲流：BufferedInputStream - BufferedOutputStream\n使用 BufferedInputStream 、BufferedOutputStream实现文件复制\n\npublic void testBuffered ()&#123;       BufferedInputStream bis = null;       BufferedOutputStream bos = null;       try &#123;           //造文件           File srcFile = new File(&quot;hello.txt&quot;);           File distFile = new File(&quot;hello_word.txt&quot;);           //造流           FileInputStream fis = new FileInputStream(srcFile);           FileOutputStream fos = new FileOutputStream(distFile);           //造缓冲流           bis = new BufferedInputStream(fis);           bos = new BufferedOutputStream(fos);           //3.复制的细节：读取、写入           byte [] buffered = new byte[10];           int len;           while ((len=bis.read(buffered)) != -1)&#123;               bos.write(buffered,0,len);           &#125;       &#125; catch (IOException e) &#123;           throw new RuntimeException(e);       &#125; finally &#123;           //4.资源关闭           //要求：先关闭外层的流，再关闭内层的流           //说明：关闭外层流的同时，内层流也会自动的进行关闭。关于内层流的关闭，我们可以省略.           if(bos != null)&#123;               try &#123;                   bos.close();               &#125; catch (IOException e) &#123;                   e.printStackTrace();               &#125;           &#125;           if(bis != null)&#123;               try &#123;                   bis.close();               &#125; catch (IOException e) &#123;                   e.printStackTrace();               &#125;           &#125;       &#125;   &#125;\n\n\n用BufferedReader和BufferedWriter实现文本文件的复制\n\n    public void testBufferedReaderBufferedWriter()&#123;        BufferedReader br = null;        BufferedWriter bw = null;        try &#123;            //创建文件和相应的流            br = new BufferedReader(new FileReader(new File(&quot;dbcp.txt&quot;)));            bw = new BufferedWriter(new FileWriter(new File(&quot;dbcp1.txt&quot;)));            //读写操作            //方式一：使用char[]数组//            char[] cbuf = new char[1024];//            int len;//            while((len = br.read(cbuf)) != -1)&#123;//                bw.write(cbuf,0,len);//    //            bw.flush();//            &#125;            //方式二：使用String            String data;            while((data = br.readLine()) != null)&#123;                //方法一：//                bw.write(data + &quot;\\n&quot;);//data中不包含换行符                //方法二：                bw.write(data);//data中不包含换行符                bw.newLine();//提供换行的操作            &#125;        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125; finally &#123;            //关闭资源            if(bw != null)&#123;                try &#123;                    bw.close();                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;            if(br != null)&#123;                try &#123;                    br.close();                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;\n\n\n\n\n\n转换流\n综合使用InputStreamReader和OutputStreamWriter\n\npublic void test2() throws Exception &#123;       //1.造文件、造流       File file1 = new File(&quot;dbcp.txt&quot;);       File file2 = new File(&quot;dbcp_gbk.txt&quot;);       FileInputStream fis = new FileInputStream(file1);       FileOutputStream fos = new FileOutputStream(file2);       InputStreamReader isr = new InputStreamReader(fis,&quot;utf-8&quot;);       OutputStreamWriter osw = new OutputStreamWriter(fos,&quot;gbk&quot;);       //2.读写过程       char[] cbuf = new char[20];       int len;       while((len = isr.read(cbuf)) != -1)&#123;           osw.write(cbuf,0,len);       &#125;       //3.关闭资源       isr.close();       osw.close();   &#125;\n\n\n\n\n\n\n\n\n\n参考与延伸\nIO流体系基本概念以及常用操作 - 探索字符串\n并发编程网：Java IO教程\n\n学习备注\n\n本文笔记主要根据 尚硅谷的java体系课程的io部分 梳理的\n后期 应该对io 体系进行一个更大的梳理，包括java的 file path，还有根据 io ，nio bio aio等进行梳理，要明白自己学习的是哪种流，所以要熟悉io历史\n\n\n\n\n","categories":["Operating-Systems","I/O"],"tags":["java","io"]},{"title":"KingbaseES KCA study notes","url":"/KingbaseES-KCA-study-notes/","content":"Kingbase安装与卸载KES安装环境要求\n\n\n环境\n要求\n\n\n\n操作系统\nCentOS 7.x\n\n\n机器规格 - 内存大小\n3GB 及以上\n\n\n机器规格 - 磁盘空间\n20GB 及以上\n\n\nKES 安装包版本\nKingbaseES_V008R006C006B0013_Lin64_install.iso\n\n\njdk 版本\n1.8+\n\n\n安装前准备工作\n服务器安装jdk1.8+版本并配置环境变量\n\n[root@localhost ~]# yum list |grep jdk[root@localhost ~]# yum -y install java-1.8.0-openjdk[root@localhost ~]# java -versionopenjdk version &quot;1.8.0_342&quot;OpenJDK Runtime Environment (build 1.8.0_342-b07)OpenJDK 64-Bit Server VM (build 25.342-b07, mixed mode)\n\n\n\n\n创建用于管理Kingbase的用户\n\n[root@localhost ~]# useradd kingbase[root@localhost ~]# [root@localhost ~]# id kingbaseuid=1000(kingbase) gid=1000(kingbase) 组=1000(kingbase)[root@localhost install]# passwd kingbase\n\n\n\n\n按实施规范创建目录，设置权限\n\n\n为了利于数据库的日常运维、持续使用、存储扩容等，我们在安装前须做好选项、存储目录规划\n\n\n\n\n选项\n设置\n\n\n\n目录\n安装软件存储目录：/install备份目录：/backup归档目录：/archive数据存储目录：/dataKES 安装目录：/KingbaseES/V8\n\n\n端口\n54321\n\n\nSYSTEM 密码\nsystem\n\n\n数据库编码格式\nUTF8\n\n\n大小写是否敏感\nENABLE_CI，默认为 off，表示大小写敏感（根据需求选择）\n\n\n# 使用 root 用户，创建目录，设置权限# 创建目录[root@localhost ~]# mkdir -p /install /KingbaseES/V8 /backup /data /archive# 修改目录属组、属主、权限[root@localhost ~]# chown -R kingbase:kingbase /install /KingbaseES /backup /archive /data[root@localhost ~]# chmod -R 775 /install /KingbaseES /backup /archive[root@localhost ~]# chmod -R 700 /data[root@localhost ~]# ls -l / |grep kingbasedrwxrwxr-x.   2 kingbase kingbase    6 9月   4 22:39 archivedrwxrwxr-x.   2 kingbase kingbase    6 9月   4 22:39 backupdrwx------.   2 kingbase kingbase    6 9月   4 22:39 datadrwxrwxr-x.   2 kingbase kingbase    6 9月   4 22:39 installdrwxrwxr-x.   3 kingbase kingbase   16 9月   4 22:39 KingbaseES\n\n\n\n上传安装包、授权文件、检查 md5、解压# 使用 root 用户将安装文件上传到/install 下[root@localhost install]# ll-rw-r--r--. 1 root root 2180431872 9月   4 22:56 KingbaseES_V008R006C006B0013_Lin64_install.iso# 使用 root 用户将授权文件上传到/install。设置授权文件的属主为kingbase和权限并验证[root@localhost install]# ll-rw-rw-r--. 1 kingbase kingbase       3534 4月  26 11:51 license_18720_0.dat# 检查和校验安装文件的 md5 值[root@localhost install]# md5sum KingbaseES_V008R006C006B0013_Lin64_install.isoc1410ba7062fbaff3308c1453797ce3e  KingbaseES_V008R006C006B0013_Lin64_install.iso# 使用 root 用户挂载 KES 安装虚拟光盘文件[root@localhost install]# mount -o loop /install/KingbaseES_V008R006C006B0013_Lin64_install.iso /mnt/mount: /dev/loop0 写保护，将以只读方式挂载[root@localhost install]# ll /mnt/总用量 6dr-xr-xr-x. 2 root root 2048 6月  14 01:09 setup-r-xr-xr-x. 1 root root 3820 6月  14 01:09 setup.sh# 使用 kingbase 用户复制挂载后的安装文件到/install 下[kingbase@bogon ~]$ ll /mnt/总用量 6dr-xr-xr-x. 2 root root 2048 6月  14 01:09 setup-r-xr-xr-x. 1 root root 3820 6月  14 01:09 setup.sh[kingbase@bogon ~]$ mkdir -p /install/KES_V8R6CB13_INSTALL[kingbase@bogon ~]$ cp -r /mnt/* /install/KES_V8R6CB13_INSTALL/[kingbase@bogon ~]$ ll /install/KES_V8R6CB13_INSTALL/总用量 4dr-xr-xr-x. 2 kingbase kingbase   54 9月   4 23:14 setup-r-xr-xr-x. 1 kingbase kingbase 3820 9月   4 23:14 setup.sh[kingbase@bogon ~]$ du -sm /mnt/2080    /mnt/[kingbase@bogon ~]$ du -sm /install/KES_V8R6CB13_INSTALL/2080    /install/KES_V8R6CB13_INSTALL/\n\n\n\n字符界面安装 KES 程序启动字符界面安装向导进入“简介”界面[kingbase@bogon ~]$ cd /install/KES_V8R6CB13_INSTALL/[kingbase@bogon KES_V8R6CB13_INSTALL]$ bash ./setup.sh -i console# 安装目录输入: /KingbaseES/V8\n\n\n\n创建和初始化数据库集簇# 数据存储目录输入: /data# 直接回车接受参数的默认值或根据规划要求指定参数的值：（1）端口：54321（生产环境可以根据需求，自定义为其它端口）。（2）输入 SYSTEM 超级管理员的密码（本实验环境密码设置为 system）。（3）设置数据库编码格式（推荐设置为“UTF8”）。（4）选择数据库模式（默认为 oracle 模式）\n\n\n\n将 KES 服务注册为 linux 系统服务# 使用 root 用户执行安装程序提供的脚本/KingbaseES/V8/Scripts/root.sh[root@localhost ~]# /KingbaseES/V8/install/script/root.shStarting KingbaseES V8:waiting for server to start.... doneserver startedKingbaseES V8 started successfully\n\n\n\n重启 linux 确认 KES 服务自动启动[kingbase@bogon ~]$ ps -xf |grep -v grep |grep -i &#x27;kingbase&#x27;  2116 ?        S      0:00 sshd: kingbase@notty  2092 ?        S      0:00 sshd: kingbase@pts/1  4919 ?        Ss     0:00 /KingbaseES/V8/KESRealPro/V008R006C006B0013/Server/bin/kingbase -D /data  4920 ?        Ss     0:00  \\_ kingbase: logger  4922 ?        Ss     0:00  \\_ kingbase: checkpointer  4923 ?        Ss     0:00  \\_ kingbase: background writer  4924 ?        Ss     0:00  \\_ kingbase: walwriter  4925 ?        Ss     0:00  \\_ kingbase: autovacuum launcher  4926 ?        Ss     0:00  \\_ kingbase: stats collector  4927 ?        Ss     0:00  \\_ kingbase: ksh writer  4928 ?        Ss     0:00  \\_ kingbase: ksh collector  4929 ?        Ss     0:00  \\_ kingbase: kwr collector  4930 ?        Ss     0:00  \\_ kingbase: logical replication launcher\n\n\n\n确认 KES 是否已正确安装\n可以使用以下几个角度确认 KES 是否已正确安装或启动\n\n\n查看安装过程日志，确认没有错误记录\n\n[kingbase@bogon ~]$ cd /install/KES_V8R6CB13_INSTALL/[kingbase@bogon KES_V8R6CB13_INSTALL]$ ls -al *.logls: 无法访问*.log: 没有那个文件或目录\n\n\n\n\n查看开始菜单中是否已成功安装相关程序\n\n\n查看相关进程是否启动\n\n[kingbase@bogon ~]$ ps -xf |grep -v grep |grep -i &#x27;kingbase&#x27;  2116 ?        S      0:00 sshd: kingbase@notty  2092 ?        S      0:00 sshd: kingbase@pts/1  4919 ?        Ss     0:00 /KingbaseES/V8/KESRealPro/V008R006C006B0013/Server/bin/kingbase -D /data  4920 ?        Ss     0:00  \\_ kingbase: logger  4922 ?        Ss     0:00  \\_ kingbase: checkpointer  4923 ?        Ss     0:00  \\_ kingbase: background writer  4924 ?        Ss     0:00  \\_ kingbase: walwriter  4925 ?        Ss     0:00  \\_ kingbase: autovacuum launcher  4926 ?        Ss     0:00  \\_ kingbase: stats collector  4927 ?        Ss     0:00  \\_ kingbase: ksh writer  4928 ?        Ss     0:00  \\_ kingbase: ksh collector  4929 ?        Ss     0:00  \\_ kingbase: kwr collector  4930 ?        Ss     0:00  \\_ kingbase: logical replication launcher\n\n\n\n\n验证数据库连接是否正常\n\n# 用 ksql 工具测试能否连接到数据库[kingbase@bogon ~]$ /KingbaseES/V8/Server/bin/ksql test systemksql (V8.0)输入 &quot;help&quot; 来获取帮助信息.test=## 在桌面环境中启动“数据库对象管理工具”测试能否连接数据库\n\n\n\n\n查看服务是否已设为开机自启\n\n[kingbase@bogon ~]$ systemctl list-dependencies |grep kingbase● ├─kingbase8d.service[kingbase@bogon ~]$ chkconfig --list |grep kingbase注：该输出结果只显示 SysV 服务，并不包含原生 systemd 服务。SysV 配置数据可能被原生 systemd 配置覆盖。      要列出 systemd 服务，请执行 &#x27;systemctl list-unit-files&#x27;。      查看在具体 target 启用的服务请执行      &#x27;systemctl list-dependencies [target]&#x27;。kingbase8d      0:关    1:关    2:开    3:开    4:开    5:开    6:关\n\n\n\n启停 KES 服务root用户管理KES服务\n以 root 用户身份登录\n\nroot 用户将 KES 注册为 linux 开机自启服务# 使用 root 用户执行安装程序提供的脚本/KingbaseES/V8/Scripts/root.sh 来注册系统服务，这样开机时会自己启动 KES 数据库服务[root@localhost ~]# /KingbaseES/V8/install/script/root.shStarting KingbaseES V8:waiting for server to start.... doneserver startedKingbaseES V8 started successfully\n\n\n\nsystemctl 管理 KES 服务# root 用户使用 systemctl 管理 KES 服务# 1、确认 KES 服务状态。systemctl status kingbase8d.service# 2、停止 KES 服务。systemctl status kingbase8d.service# 3、启动 KES 服务。systemctl start kingbase8d.service# 4、重启 KES 服务。systemctl restart kingbase8d.service\n\n\n\nservice 管理 KES 服务# root 用户使用 service 管理 KES 服务service kingbase8d statusservice kingbase8d startservice kingbase8d restartservice kingbase8d stop\n\n\n\nkingbase用户管理KES服务\n使用 kingbase 用户登录后执行 sys_ctl 命令\n\n使用金仓 sys_ctl 命令管理 KES 服务sys_ctl 长命令格式/KingbaseES/V8/Server/bin/sys_ctl status -D /data/KingbaseES/V8/Server/bin/sys_ctl stop -D /data/KingbaseES/V8/Server/bin/sys_ctl start -D /data/KingbaseES/V8/Server/bin/sys_ctl restart -D /data\n\n\n\nsys_ctl 语法大纲sys_ctl start \t[-D DATADIR] [-l FILENAME] [-W] [-t SECS] [-s]\t\t\t\t[-o OPTIONS] [-p PATH] [-c]\t\t\t\tsys_ctl stop \t[-D DATADIR] [-m SHUTDOWN-MODE] [-W] [-t SECS] [-s]sys_ctl restart [-D DATADIR] [-m SHUTDOWN-MODE] [-W] [-t SECS] [-s]\t\t\t\t[-o OPTIONS] [-c]\t\t\t\tsys_ctl reload \t[-D DATADIR] [-s]sys_ctl status \t[-D DATADIR]sys_ctl promote [-D DATADIR] [-W] [-t SECS] [-s]sys_ctl logrotate [-D DATADIR] [-s]sys_ctl kill SIGNALNAME PID\n\n\n\n使用 kingbase 命令启动 KES 服务/KingbaseES/V8/Server/bin/kingbase -D /data &gt;log1 2&gt;&amp;1 &amp;\n\n\n\n环境变量对相关命令的影响\n定位金仓 sys_ctl 的路径\n\n[kingbase@bogon bin]$ find /KingbaseES/ -name sys_ctl/KingbaseES/V8/KESRealPro/V008R006C006B0013/Server/bin/sys_ctl\n\n\n\n\n定位主数据目录\n\n[kingbase@bogon bin]$ ps -ef|grep &#x27;\\ -D\\ &#x27;kingbase   6723   2093  0 00:27 pts/1    00:00:00 /KingbaseES/V8/Server/bin/kingbase -D /data[root@localhost ~]# find / -name kingbase.conf/data/kingbase.conf\n\n\n\n\n修改环境变量\n\n（1）KINGBASE_DATA 变量\n\n该环境变量指向 KES 主数据目录，此变量名是金仓程序员指定的命名，不要修改\n未指定该变量时，sys_ctl 工具在执行时需要加-D 参数来给定主数据目录位置\n\n（2）修改 shell 的 profile\n\n把【/KingbaseES/V8/Server/bin】加到$PATH 变量里面\n 把/data 赋值给$KINGBASE_DATA\n\n# 编辑 kingbase 的环境变量文件，添加相应路径vi /home/kingbase/.bashrcexport PATH=/KingbaseES/V8/Server/bin:$PATHexport KINGBASE_DATA=/data# 让环境变量生效source /home/kingbase/.bashrc\n\n# 设置变量后命令行比较简捷sys_ctl stop -D $KINGBASE_DATA kingbase -D /data &gt;log1 2&gt;&amp;1 &amp;\n\n\n\n授权文件license.dat查看license有效天数test=# select get_license_validdays(); get_license_validdays-----------------------                    89(1 行记录)test=#\n\n\n\nlicense过期后的故障现象\n\n\n\nlicense过期故障解决\n使用 kingbase 用户登录，上传新的 lincense.dat 到 kingbase的安装目录 /KingbaseES/V8下——替换原旧的 license.dat。然后重新加载数据库（或者重新启动）\n\n# 注意 lincese.dat 的 属组和属组 必须是 kingbase，授权文件名称 必须是 lincese.dat[kingbase@bogon ~]$ sys_ctl reload -D $KINGBASE_DATAserver signaled\n\n\n\nKES卸载\n使用 root 用户执行 rootuninstall.sh 脚本移除 KES 开机自启服务\n\nsu - root/KingbaseES/V8/install/script/rootuninstall.sh\n\n\n\n\n以 kingbase 用户执行 bash /KingbaseES/V8/Uninstall/Uninstaller -i console\n\n[kingbase@bogon ~]$ bash /KingbaseES/V8/Uninstall/Uninstaller -i console# 卸载完后，执行`echo $?`的 结果为 0，则 Uninstaller -i console 执行成功\n\n\n\n\n清除安装目录下残留文件\n\n\n方法一：执行 rm –fr /KingbaseES/V8 直接删除安装目录\n方法二：执行 mv /KingbaseES/V8 /KingbaseES/V8.bak 将安装目录改名\n\n\n\n数据库对象管理工具\n参考培训文档，做实验，以及做好记录\n\n\n\n命令行工具KSQLKSQL简介\nKSQL 是金仓提供给 DBA 的与 KES 数据库交互的命令行客户端程序（部分工作场景是无法使用图形界面工具来工作的；还有部分场景使用SQL效率更高）。熟练使用 KSQL 工具可以帮助 DBA 快速的操作和维护数据库\n\n查看 KSQL 工具的帮助[kingbase@bogon ~]$ ksql --help\n\n\n部分参数解析\n\n\n连接参数\n\n\n\n\n参数\n简介\n\n\n\n-h\n连接服务器的监听 IP 或主机名(-h 缺省时为 localhost 方式登录)\n\n\n-p\n连接服务器的监听端口号当为端口号为默认值 54321 时可缺省-p设置了 KINGBASE_PORT 环境变量时也可缺省-p\n\n\n-U\n连接服务器的用户名\n\n\n-W\n强制输入密码\n\n\n\n通用参数\n\n\n\n\n参数\n简介\n\n\n\n-c\n指定连接数据库后执行的单行命令，执行完成后自动退出数据库连接\n\n\n-d\n指定连接时登录的数据库\n\n\n-f\n指定连接数据库时执行的脚本，执行完成后自动退出数据库连接\n\n\n-l\n打印数据库列表\n\n\n-V\n打印数据库版本信息\n\n\n-?\n打印 ksql 命令的帮助信息\n\n\n\n输入输出参数\n\n\n\n\n参数\n简介\n\n\n\n-H\n以 html 格式展示输出结果\n\n\n-E\n展示元命令所执行的 sql\n\n\n-t\n不输出字段名\n\n\n-x\n调整查询结果为纵向展示\n\n\n-q\n不输出登录提示信息\n\n\n-o\n将命令输出结果保存到指定的文件中\n\n\n\n\n查看标准 SQL 命令的帮助\n使用 \\h 列出所有的 SQL 命令清单\n\ntest=# \\h\n\n\n\n\n使用 \\h &lt;sql 命令&gt; 列出某个 SQL 命令的语法大纲\n\ntest=# \\h deleteCommand:     DELETEDescription: 删除数据表中的数据列Syntax:[ WITH [ RECURSIVE ] with查询语句(with_query) [, ...] ]DELETE FROM [ ONLY ] 表名 [ * ] [ [ AS ] 别名 ]    [ USING USING列表(using_list) ]    [ WHERE 条件 | WHERE CURRENT OF 游标名称 ]    [ RETURNING * | 输出表达式 [ [ AS ] 输出名称 ] [, ...] ]\n\n\n\n查看 KSQL 元命令的帮助\n元命令介绍\n\n\n（1）ksql 提供了一组以“\\”开头的快捷命令，称之为 ksql 元命令。（2）搭配通配符“*”或“?”提高查询效率。（3）使用选项“S”显示系统对象。（4）使用选项“+”显示更加丰富的信息。\n\n\n常用元命令介绍\n\n\n\n\n参数\n简介\n\n\n\n\\d[S+]\n列出表,视图和序列,其中 S 表示包含系统对象，+表示列出详细信息\n\n\n\\d[S+] 名称\n描述表，视图，序列，或索引\n\n\n\\db[+] [模式]\n列出表空间\n\n\n\\di[S+] [模式]\n列出索引\n\n\n\\dp [模式]\n列出表，视图和序列的访问权限(\\z 和相同)\n\n\n\\ds[S+] [模式]\n列出序列\n\n\n\\du[+]\n列出角色\n\n\n\\l[+]\n列出所有的数据库\n\n\nKSQL 连接到数据库使用 SOCKET 方式登录数据库[kingbase@localhost ~]$ ksql -U system -d testksql (V8.0)输入 &quot;help&quot; 来获取帮助信息.test=# \n\n\n\n使用 TCP/IP 方式登录数据库[kingbase@localhost ~]$ ksql -h 192.168.146.129 -p 54321 -U system -d test用户 system 的口令：ksql (V8.0)输入 &quot;help&quot; 来获取帮助信息.test=# \n\n\n\n在 KSQL 中切换登录用户和数据库[kingbase@bogon ~]$ ksql -Usystem -d testksql (V8.0)输入 &quot;help&quot; 来获取帮助信息.test=# \\c tfsdb您现在已经连接到数据库 &quot;tfsdb&quot;,用户 &quot;system&quot;.tfsdb=# \\c - tfsdb您现在已经连接到数据库 &quot;tfsdb&quot;,用户 &quot;tfsdb&quot;.tfsdb=# \\c test system您现在已经连接到数据库 &quot;test&quot;,用户 &quot;system&quot;.\n\n\n\nKSQL 引用环境变量进行快速登录\n\n\n\n\n\n执行 SQL 的几种方式\n交互方式执行 SQL\n\n# 登录ksqltfsdb=# select * from pa_user;\n\n\n\n\n非交互方式执行 SQL (单条 SQL 语句)\n\n# 使用“-c”选项登录 tfsdb 数据库查看[kingbase@bogon ~]$ ksql -U tfsdb -d tfsdb -c &#x27;select * from pa_user;&#x27;\n\n\n\n\n非交互方式执行 SQL (成批的 SQL 语句、SQL文件)\n\n[kingbase@bogon ~]$ ll总用量 8-rw-rw-r--  1 kingbase kingbase  23 9月   9 18:00 demo.sql-rw-------. 1 kingbase kingbase 712 8月  20 19:13 restart.log[kingbase@bogon ~]$ cat demo.sqlselect * from pa_user;[kingbase@bogon ~]$ ksql -U tfsdb -d tfsdb -f /home/kingbase/demo.sql\n\n\n\nKSQL 元命令介绍\n略（查看官网）\n\n使用元命令实现异构数据库数据交换# 导出表数据库到 csv 文件tfsdb=# \\copy tfsdb.pa_user to /home/kingbase/pa_user.csv csvCOPY 16# 查看 csvtfsdb=# \\! cat /home/kingbase/pa_user.csv# 将 csv 文件导入数据库表中tfsdb=# \\copy tfsdb.pa_user from /home/kingbase/pa_user.csv csvCOPY 16\n\n\n\n用户与角色\n用户和角色是数据库管理的基础\n本章主要介绍如何在 KES 数据库中创建用户和角色，以及利用“角色”对多个用户批量授权，使 KES 管理体系更加清晰、简单\n\n数据库用户用户管理概述\n数据库用户代表数据库的使用者\n应该为每个使用者创建用户\n尽量避免多人使用同一个数据库用户\n\n用户管理\n增删改查 略（参考官网）\n\n当待删除用户是部分对象的拥有者时，因对象依赖会导致删除用户失败\n\n\n数据库角色角色的概念\n将一组具有相同权限的用户组织在一起，这一组具有相同权限的用户就称为角色（Role）\n角色在生产系统中一般被视作用户组，利用角色对用户执行批量授权\n\n角色管理\n增删改查 略（参考官网）\n当待删除角色是部分对象的拥有者时，因对象依赖会导致删除角色失败\n当待删除角色被显式授予对象权限时，因权限依赖会导致删除角色失败\n\n对象的访问权限入门\n数据库的表、索引、视图、图表、缺省值、规则、触发器、语法等等，在数据库中的一切，都称为数据库对象，对象分为如下两类：\n\n\n模式（SCHEMA）对象：可视为一个表的集合，可以理解为一个存储目录，包含视图、索引、数据类型、函数和操作符等\n非模式对象：其他的数据库对象，如数据库、表空间、用户、权限。\n\n\n用户或角色访问模式对象或非模式对象的能力称之为对象权限\n\n\n\n\n\n\n\n简单巡检查看 KES 版本信息# 使用 sys_ctl 查看版本[kingbase@localhost ~]$ sys_ctl -Vsys_ctl (Kingbase) 12.1[kingbase@localhost ~]$ sys_ctl --versionsys_ctl (Kingbase) 12.1# 使用 version 函数查看版本test=# select version();                                                       version---------------------------------------------------------------------------------------------------------------------- KingbaseES V008R006C006B0013 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.1.2 20080704 (Red Hat 4.1.2-46), 64-bit(1 行记录)\n\n\n\n\n\n查看 license 有效期test=# select get_license_validdays(); get_license_validdays-----------------------                    66(1 行记录)\n\n\n\n\n\n查看 KES 实例启动时间和运行时长# 查看数据库实例启动时间test=# select sys_postmaster_start_time();   sys_postmaster_start_time------------------------------- 2022-09-25 08:04:56.261041+08(1 行记录)# 查看 KES 无故障运行时长test=# select date_trunc(&#x27;second&#x27;,current_timestamp - sys_postmaster_start_time()) as uptime;         uptime------------------------ 2 days 16:28:15.000000(1 行记录)\n\n\n\n\n\n查看数据库列表# 使用 ksql 的-l 参数或元命令\\l[kingbase@localhost ~]$ ksql -Usystem -d test -l                                           数据库列表    名称     |   拥有者    | 字元编码 | 校对规则 |    Ctype    |            存取权限-------------+-------------+----------+----------+-------------+-------------------------------- security    | system      | UTF8     | ci_x_icu | zh_CN.UTF-8 | template0   | system      | UTF8     | ci_x_icu | zh_CN.UTF-8 | =c/system                     +             |             |          |          |             | system=CTc/system template1   | system      | UTF8     | ci_x_icu | zh_CN.UTF-8 | =c/system                     +             |             |          |          |             | system=CTc/system test        | system      | UTF8     | ci_x_icu | zh_CN.UTF-8 | xjnxdb_test | xjnxdb_test | UTF8     | ci_x_icu | zh_CN.UTF-8 | =Tc/xjnxdb_test               +             |             |          |          |             | xjnxdb_test=C*T*c*/xjnxdb_test(5 行记录)test=# \\l                                           数据库列表    名称     |   拥有者    | 字元编码 | 校对规则 |    Ctype    |            存取权限-------------+-------------+----------+----------+-------------+-------------------------------- security    | system      | UTF8     | ci_x_icu | zh_CN.UTF-8 | template0   | system      | UTF8     | ci_x_icu | zh_CN.UTF-8 | =c/system                     +             |             |          |          |             | system=CTc/system template1   | system      | UTF8     | ci_x_icu | zh_CN.UTF-8 | =c/system                     +             |             |          |          |             | system=CTc/system test        | system      | UTF8     | ci_x_icu | zh_CN.UTF-8 | xjnxdb_test | xjnxdb_test | UTF8     | ci_x_icu | zh_CN.UTF-8 | =Tc/xjnxdb_test               +             |             |          |          |             | xjnxdb_test=C*T*c*/xjnxdb_test(5 行记录)# 使用数据字典test=# select datname from sys_database;   datname------------- test security template1 template0 xjnxdb_test(5 行记录)\n\n\n\n\n\n查看数据库占用的磁盘空间# 统计当前数据库占用的磁盘空间test=# select sys_database_size(current_database())/1024/1024 || &#x27;MB&#x27; MB;  MB------ 12MB(1 行记录)# 统计所有数据库占用的磁盘空间总量xjnxdb_test=# select (sum(sys_database_size(datname))/1024/1024) || &#x27;MB&#x27; MB from sys_database;           MB------------------------ 234.1652364730834961MB(1 行记录)\n\n\n\n\n\n查看表和索引的大小# 统计表的空间占用xjnxdb_test=# select sys_relation_size(&#x27;xjnxdb_test.pa_user&#x27;)/1024 || &#x27;KB&#x27; KB;  KB------ 48KB(1 行记录)xjnxdb_test=# select sys_size_pretty(sys_relation_size(&#x27;xjnxdb_test.pa_user&#x27;)); sys_size_pretty----------------- 48 kB(1 行记录)# 统计表和与表关联的索引占用空间总量xjnxdb_test=# select sys_total_relation_size(&#x27;xjnxdb_test.pa_user&#x27;)/1024 || &#x27;KB&#x27; KB;  KB------ 88KB(1 行记录)xjnxdb_test=# select sys_size_pretty(sys_total_relation_size(&#x27;xjnxdb_test.pa_user&#x27;)); sys_size_pretty----------------- 88 kB(1 行记录)# 统计表的记录数xjnxdb_test=# select count(*) || &#x27; rows&#x27; &quot;rows&quot; from xjnxdb_test.pa_user;   rows---------- 145 rows(1 行记录)\n\n\n\n\n\n查看时区和时间# 查看最近一次加载参数文件的时间xjnxdb_test=# select sys_conf_load_time();      sys_conf_load_time------------------------------- 2022-09-25 08:04:55.822231+08(1 行记录)# 查看时区xjnxdb_test=# show timezone;   TimeZone--------------- Asia/Shanghai(1 行记录)# 查看当前日期或时间xjnxdb_test=# select now();              now------------------------------- 2022-09-28 05:43:22.416126+08(1 行记录)xjnxdb_test=# select current_timestamp;       current_timestamp------------------------------- 2022-09-28 05:43:45.124372+08(1 行记录)xjnxdb_test=# select sysdate;       sysdate--------------------- 2022-09-28 05:44:16(1 行记录)xjnxdb_test=# select current_date; current_date-------------- 2022-09-28(1 行记录)\n\n\n\n\n\n查看当前登录数据库的名称xjnxdb_test=# select current_catalog; current_catalog----------------- xjnxdb_test(1 行记录)xjnxdb_test=# select current_database(); current_database------------------ xjnxdb_test(1 行记录)\n\n\n\n\n\n查看当前会话信息# 查看当前会话的客户端 IP 和端口。test=# select inet_client_addr(),inet_client_port(); inet_client_addr | inet_client_port------------------+------------------ 10.114.200.15    |            52665(1 行记录)# 查看服务器的 IP 和端口。test=# select inet_server_addr(),inet_server_port(); inet_server_addr | inet_server_port------------------+------------------ 10.114.12.66     |            54321(1 行记录)# 查看当前会话的后台进程 ID。test=# select sys_backend_pid(); sys_backend_pid-----------------          341129(1 行记录)\n\n\n\n\n\n查看数据库中的连接信息test=# select datname,usename,client_addr,client_port  from sys_stat_activity;   datname    |   usename    |  client_addr   | client_port--------------+--------------+----------------+-------------              |              |                |              | system       |                |              | system       |                | xjnxdb_2_pt  | xjnxdb_2_pt  | 10.114.12.67   |       45560 xjnxdb_2_pt  | xjnxdb_2_pt  | 10.114.12.67   |       45584 xjnxdb_test2 | xjnxdb_test2 | 10.114.12.67   |       45624 xjnxdb_2_pt  | xjnxdb_2_pt  | 10.114.12.67   |       45630\n\n\n\n\n\n查看会话执行的 SQL 信息# （1）设置参数 track_activities 为 on。test=# show track_activities; track_activities------------------ on(1 行记录)# 查看所有会话执行的 SQL 信息test=# select datname,usename,client_addr,client_port  from sys_stat_activity;   datname    |   usename    |  client_addr   | client_port--------------+--------------+----------------+-------------              |              |                |              | system       |                |              | system       |                | xjnxdb_2_pt  | xjnxdb_2_pt  | 10.114.12.67   |       45654 xjnxdb_2_pt  | xjnxdb_2_pt  | 10.114.12.67   |       45694 tfsdb        | tfsdb        | 10.43.1.113    |       55971 xjnxdb_2_pt  | xjnxdb_2_pt  | 10.114.12.67   |       45630 xjnxdb_2_pt  | xjnxdb_2_pt  | 10.114.12.67   |       45684# 只看正在运行的 SQL 信息test=# select datname,usename,client_addr,client_port  from sys_stat_activity where state not like &#x27;idle%&#x27;;   datname   |   usename   |  client_addr   | client_port-------------+-------------+----------------+------------- xjnxdb_test | xjnxdb_test | 10.114.12.67   |       45706 xjnxdb      | xjnxdb      | 10.114.200.108 |       54113 test        | system      | 10.114.200.15  |       56839(3 行记录)\n\n\n\n\n\n查看耗时较长的 SQLtfsdb=# select current_timestamp - query_start as runtime ,datname,usename,pid,query from  sys_stat_activity where state != &#x27;idle&#x27; order by 1 desc;-[ RECORD 1 ]----------------------------------------------------------------------------------------------------------------------------------------runtime | 00:00:00.000000datname | tfsdbusename | systempid     | 341563query   | select current_timestamp - query_start as runtime ,datname,usename,pid,query from  sys_stat_activity where state != &#x27;idle&#x27; order by 1 desc;\n\n\n\n\n\n\n\n事务阻塞会话的简单处理# 会话 1—关闭自动提交后删除记录\n\n\n\n\n\n\n\n\n\n单表查询\n\n\n\n\n\n学习备注熟悉语义 /KingbaseES/V8/Server/bin/kingbase -D /data &gt;log1 2&gt;&amp;1 &amp;systemctl , sys_ctl service各个命令的隔离性？几种关闭模式需要详细了解和实验记录，需要自己动手做实验sql 的元命令 需要详细了解一下呢copy 和 \\copy事务阻塞会话的简单处理 这一块还需要了解一下\n\n\n\n\n\n\n\n\n\n","categories":["database","kingbase"],"tags":["database","kingbase"]},{"title":"Redis","url":"/Redis/","content":"初识RedisSQL与NoSQL\n\n\n\nSQL（关系型数据库）\nNoSQL（非关系数据库）\n\n\n\n数据结构\n结构化\n非结构化\n\n\n数据关联\n关联的\n无关联的\n\n\n查询方式\nSQL查询\n非SQL\n\n\n事务特性\nACID\nBASE\n\n\n存储方式\n磁盘\n内存\n\n\n扩展性\n垂直\n水平\n\n\n使用场景\n（1）数据结构固定（2）相关业务对数据安全性、一致性有较高要求\n（1）数据结构不固定（2）对一致性、安全性要求不高（3）对性能要求\n\n\n\n\n\n数据结构\n\n\n\n\n\n\n数据关联\n\n\n\n\n\n\n\n\n\n\nSQL查询\n\n\n\n\n\n常见NoSQLRedis简介\nRedis诞生于2009年全称是Remote Dictionary Server，远程词典服务器，是一个基于内存的键值型NoSQL数据库。\n\nRedis特征\n键值（key-value）型，value支持多种不同数据结构，功能丰富\n单线程，每个命令具备原子性\n低延迟，速度快（基于内存、IO多路复用、良好的编码）\n支持数据持久化\n支持主从集群、分片集群\n支持多语言客户端\n\n单机安装Redis# 安装依赖 （Redis是基于C语言编写的，因此首先需要安装Redis所需要的gcc依赖）yum install -y gcc tcl# 上传/下载 安装包并解压cd /usr/local/src/wget https://download.redis.io/releases/redis-6.2.7.tar.gztar -zxvf redis-6.2.7.tar.gz# 编译安装cd /usr/local/src/redis-6.2.7make &amp;&amp; make install# 安装完成后。默认的安装路径是在 `/usr/local/bin`目录下[root@bogon src]# cd /usr/local/bin/[root@bogon bin]# ll总用量 18924-rwxr-xr-x. 1 root root 4830088 7月  25 05:51 redis-benchmarklrwxrwxrwx. 1 root root      12 7月  25 05:51 redis-check-aof -&gt; redis-serverlrwxrwxrwx. 1 root root      12 7月  25 05:51 redis-check-rdb -&gt; redis-server-rwxr-xr-x. 1 root root 5004192 7月  25 05:51 redis-clilrwxrwxrwx. 1 root root      12 7月  25 05:51 redis-sentinel -&gt; redis-server-rwxr-xr-x. 1 root root 9535928 7月  25 05:51 redis-server# 该目录已经默认配置到环境变量，因此可以在任意目录下运行这些命令。其中：redis-server# 是redis的服务端启动脚本redis-cli# 是redis提供的命令行客户端redis-sentinel# 是redis的哨兵启动脚本\n\n\n\nRedis启动默认启动（前台启动）\n这种启动属于前台启动，会阻塞整个会话窗口，窗口关闭或者按下CTRL + C则Redis停止。不推荐使用。\n\nredis-server\n\n\n\n指定配置启动\n如果要让Redis以后台方式启动，则必须修改Redis配置文件\n\n# 我们先将这个配置文件备份一份：cp redis.conf redis.conf.bck\n\n\n然后修改redis.conf文件中的一些配置\n\n# 允许访问的地址，默认是127.0.0.1，会导致只能在本地访问。修改为0.0.0.0则可以在任意IP访问，生产环境不要设置为0.0.0.0bind 0.0.0.0# 守护进程，修改为yes后即可后台运行daemonize yes # 密码，设置后访问Redis必须输入密码requirepass redis@2022\n\n\nRedis的其它常见配置\n\n# 监听的端口port 6379# 工作目录，默认是当前目录，也就是运行redis-server时的命令，日志、持久化等文件会保存在这个目录dir .# 数据库数量，设置为1，代表只使用1个库，默认有16个库，编号0~15databases 1# 设置redis能够使用的最大内存maxmemory 512mb# 日志文件，默认为空，不记录日志，可以指定日志文件名logfile &quot;redis.6379.log&quot;\n\n\n指定配置启动\n\n# 进入redis安装目录 [root@localhost redis]# /usr/local/bin[root@bogon bin]# ll总用量 19112-rw-r--r--. 1 root root   93916 7月  25 06:16 redis.6379.conf-rw-r--r--. 1 root root    1232 7月  25 06:20 redis.6379.log-rwxr-xr-x. 1 root root 4830088 7月  25 05:51 redis-benchmarklrwxrwxrwx. 1 root root      12 7月  25 05:51 redis-check-aof -&gt; redis-serverlrwxrwxrwx. 1 root root      12 7月  25 05:51 redis-check-rdb -&gt; redis-server-rwxr-xr-x. 1 root root 5004192 7月  25 05:51 redis-cli-rw-r--r--. 1 root root   93849 7月  25 06:08 redis.conf.baklrwxrwxrwx. 1 root root      12 7月  25 05:51 redis-sentinel -&gt; redis-server-rwxr-xr-x. 1 root root 9535928 7月  25 05:51 redis-server[root@bogon bin]#[root@localhost redis]# redis-server redis.6379.conf[root@localhost redis]#[root@bogon bin]# ps -ef |grep redisroot       8126      1  0 06:20 ?        00:00:00 redis-server 0.0.0.0:6379root       8194   1552  0 06:21 pts/1    00:00:00 grep --color=auto redis\n\n\n\n开机自启（把redis添加到系统服务）\n我们也可以通过配置来实现开机自启，首先，新建一个系统服务文件\n\nvim /etc/systemd/system/redis.service\n\n\n添加如下内容\n\n[Unit]Description=redis-serverAfter=network.target[Service]Type=forkingExecStart=/usr/local/bin/redis-server /usr/local/bin/redis.6379.confPrivateTmp=true[Install]WantedBy=multi-user.target\n\n\n然后重载系统服务\n\nsystemctl daemon-reload\n\n\n现在，我们可以用下面这组命令来操作redis了\n\n# 启动systemctl start redis# 停止systemctl stop redis# 重启systemctl restart redis# 查看状态systemctl status redis\n\n\n执行下面的命令，可以让redis开机自启\n\nsystemctl enable redis\n\n\n\nRedis的其它常见配置# 监听的端口port 6379# 工作目录，默认是当前目录，也就是运行redis-server时的命令，日志、持久化等文件会保存在这个目录dir .# 数据库数量，设置为1，代表只使用1个库，默认有16个库，编号0~15databases 1# 设置redis能够使用的最大内存maxmemory 512mb# 日志文件，默认为空，不记录日志，可以指定日志文件名logfile &quot;redis.6379.log&quot;\n\n\n\nRedis停止# 利用redis-cli来执行 shutdown 命令，即可停止 Redis 服务，# 因为之前配置了密码，因此需要通过 -a 来指定密码redis-cli -a redis shutdown\n\n\n\nRedis客户端Redis命令行客户端redis-cli [options] [commonds]\n\n其中常见的options有：\n\n-h 127.0.0.1：指定要连接的redis节点的IP地址，默认是127.0.0.1\n-p 6379：指定要连接的redis节点的端口，默认是6379\n-a 123321：指定redis的访问密码 \n\n其中的commonds就是Redis的操作命令，例如：\n\nping：与redis服务端做心跳测试，服务端正常会返回pong\n\n不指定commond时，会进入redis-cli的交互控制台：\n\n\n\n\n图形化桌面客户端\nhttps://github.com/lework/RedisDesktopManager-Windows/releases\n\n\n\nRedis的Java客户端\n\n\n\nJedisJedis使用的基本步骤（1）引入依赖\n&lt;!--Redis依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;redis.clients&lt;/groupId&gt;    &lt;artifactId&gt;jedis&lt;/artifactId&gt;    &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt;\n\n（2）创建Jedis对象，建立连接\nprivate Jedis jedis;   @BeforeEach   void testJedis() &#123;       jedis = new Jedis(&quot;192.168.163.200&quot;,6379);       jedis.auth(&quot;redis&quot;);       jedis.select(0);   &#125;\n\n（3）使用Jedis，方法名与Redis命令一致\n@Testvoid testString() &#123;    // 插入数据，方法名称就是redis命令名称，非常简单    String result = jedis.set(&quot;name&quot;, &quot;张三&quot;);    System.out.println(&quot;result = &quot; + result);    // 获取数据    String name = jedis.get(&quot;name&quot;);    System.out.println(&quot;name = &quot; + name);&#125;\n\n\n（4）释放资源\n@Deprecated   void tearDown() &#123;       if (jedis != null) &#123;           jedis.close();       &#125;   &#125;\n\n\n\nJedis连接池\nJedis本身是线程不安全的，并且频繁的创建和销毁连接会有性能损耗，因此推荐大家使用Jedis连接池代替Jedis的直连方式\n\npublic class JedisConnectionFactory &#123;    private static final JedisPool jedisPool;    static &#123;        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();        // 最大连接        jedisPoolConfig.setMaxTotal(8);        // 最大空闲连接        jedisPoolConfig.setMaxIdle(8);         // 最小空闲连接        jedisPoolConfig.setMinIdle(0);        // 设置最长等待时间， ms        jedisPoolConfig.setMaxWaitMillis(200);        jedisPool = new JedisPool(jedisPoolConfig, &quot;localhost&quot;, 6379,                1000, &quot;123321&quot;);    &#125;    // 获取Jedis对象    public static Jedis getJedis()&#123;        return jedisPool.getResource();    &#125;&#125;\n\n\n\nSpringDataRedisSpringDataRedis简介\nSpringData是Spring中数据操作的模块，包含对各种数据库的集成，其中对Redis的集成模块就叫做SpringDataRedis，官网地址：https://spring.io/projects/spring-data-redis\n\n提供了对不同Redis客户端的整合（Lettuce和Jedis）\n提供了RedisTemplate统一API来操作Redis\n支持Redis的发布订阅模型\n支持Redis哨兵和Redis集群\n支持基于Lettuce的响应式编程\n支持基于JDK、JSON、字符串、Spring对象的数据序列化及反序列化\n支持基于Redis的JDKCollection实现\n\n\nSpringDataRedis中提供了RedisTemplate工具类，其中封装了各种对Redis的操作。并且将不同数据类型的操作API封装到了不同的类型中：\n\n\n\n\n\nAPI\n返回值类型\n说明\n\n\n\nredisTemplate.opsForValue()\nValueOperations\n操作String类型数据\n\n\nredisTemplate.opsForHash()\nHashOperations\n操作Hash类型数据\n\n\nredisTemplate.opsForList()\nListOperations\n操作List类型数据\n\n\nredisTemplate.opsForSet()\nSetOperations\n操作Set类型数据\n\n\nredisTemplate.opsForZSet()\nZSetOperations\n操作SortedSet类型数据\n\n\nredisTemplate\n\n通用的命令\n\n\n\n\nSpringDataRedis快速入门\nSpringBoot已经提供了对SpringDataRedis的支持，使用非常简单\n\n（1）引入spring-boot-starter-data-redis依赖\n&lt;!--Redis依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--连接池依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;    &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt;\n\n（2）在application.yml配置Redis信息\nspring:  redis:    host: 192.168.163.200    port: 6379    password: redis    lettuce:      pool:        max-active: 8 # 最大连接        max-idle: 8 # 最大空闲连接        min-idle: 0 # 最小空闲连接        max-wait: 100 # 连接等待时间\n（3）注入RedisTemplate\n@Autowiredprivate RedisTemplate redisTemplate;\n\n（4）编写测试\n@SpringBootTestpublic class RedisTest &#123;    @Autowired    private RedisTemplate redisTemplate;    @Test    void testString() &#123;         // 插入一条string类型数据        redisTemplate.opsForValue().set(&quot;name&quot;, &quot;李四&quot;);        // 读取一条string类型数据        Object name = redisTemplate.opsForValue().get(&quot;name&quot;);        System.out.println(&quot;name = &quot; + name);    &#125;&#125;\n\n\n\nRedis 数据类型与常见命令Redis 数据结构介绍\nRedis是一个key-value的数据库，key一般是String类型，不过value的类型多种多样\n\n\n\nRedis通用命令\n通用指令是部分数据类型的，都可以使用的指令，常见的有：\nKEYS：查看符合模板的所有key\nDEL：删除一个指定的key\nEXISTS：判断key是否存在\nEXPIRE：给一个key设置有效期，有效期到期时该key会被自动删除\nTTL：查看一个KEY的剩余有效期\n通过help [command] 可以查看一个命令的具体用法\n\n\n\n\n\nRedis Serializer（Redis序列化）SpringDataRedis的序列化方式\nRedisTemplate可以接收任意Object作为值写入Redis，只不过写入前会把Object序列化为字节形式，默认是采用JDK序列化\n\n\n\n\n缺点：\n可读性差\n内存占用较大\n\n\n\n\n\n自定义RedisTemplate的序列化方式@Configurationpublic class RedisConfig &#123;    @Bean    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123;        // 创建Template        RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;();        // 设置连接工厂        redisTemplate.setConnectionFactory(redisConnectionFactory);        // 设置序列化工具        GenericJackson2JsonRedisSerializer jsonRedisSerializer =                new GenericJackson2JsonRedisSerializer();        // key和 hashKey采用 string序列化        redisTemplate.setKeySerializer(RedisSerializer.string());        redisTemplate.setHashKeySerializer(RedisSerializer.string());        // value和 hashValue采用 JSON序列化        redisTemplate.setValueSerializer(jsonRedisSerializer);        redisTemplate.setHashValueSerializer(jsonRedisSerializer);        return redisTemplate;    &#125;&#125;\n\n@SpringBootTestpublic class RedisTest2 &#123;    @Autowired    private RedisTemplate&lt;String, Object&gt; redisTemplate;    @Test    void testString() &#123;        // 插入一条string类型数据        redisTemplate.opsForValue().set(&quot;name&quot;, &quot;李四&quot;);        // 读取一条string类型数据        Object name = redisTemplate.opsForValue().get(&quot;name&quot;);        System.out.println(&quot;name = &quot; + name);    &#125;    @Test    void testSaveObject() &#123;        redisTemplate.opsForValue().set(&quot;user:100&quot;,new Person(&quot;果冻&quot;,28));        Person person = (Person) redisTemplate.opsForValue().get(&quot;user:100&quot;);        System.out.println(person);    &#125;\n\n\n\nStringRedisTemplate（RedisTemplate的序列化方式优化）\n尽管JSON的序列化方式可以满足我们的需求，但依然存在一些问题\n\n\n\n\n为了在反序列化时知道对象的类型，JSON序列化器会将类的class类型写入json结果中，存入Redis，会带来额外的内存开销\n\n为了节省内存空间，我们并不会使用JSON序列化器来处理value，而是统一使用String序列化器，要求只能存储String类型的key和value。当需要存储Java对象时，手动完成对象的序列化和反序列化\n\n\n\n\n\nSpring默认提供了一个StringRedisTemplate类，它的key和value的序列化方式默认就是String方式。省去了我们自定义RedisTemplate的过程：\n\n@SpringBootTestpublic class StingRedisTemplateTests &#123;    @Autowired    private StringRedisTemplate stringRedisTemplate;    // JSON工具    private static final ObjectMapper mapper = new ObjectMapper();    @Test    void testStringTemplate() throws JsonProcessingException &#123;        // 准备对象        Person user = new Person(&quot;lily&quot;, 18);        // 手动序列化        String json = mapper.writeValueAsString(user);        // 写入一条数据到redis        stringRedisTemplate.opsForValue().set(&quot;user:200&quot;, json);        // 读取数据        String val = stringRedisTemplate.opsForValue().get(&quot;user:200&quot;);        // 反序列化        Person user1 = mapper.readValue(val, Person.class);        System.out.println(&quot;user1 = &quot; + user1);    &#125;&#125;\n\n\n\nRedisTemplate序列化总结RedisTemplate的两种序列化实践方案：\n方案一：\n\n自定义RedisTemplate\n修改RedisTemplate的序列化器为GenericJackson2JsonRedisSerializer\n\n\n方案二：\n\n使用StringRedisTemplate\n写入Redis时，手动把对象序列化为JSON\n读取Redis时，手动把读取到的JSON反序列化为对象\n\n\n\n\n\nRedis企业实战商户点评\n\n\n\n目录\n短信登录\n商户查询缓存\n优惠券秒杀\n达人探店\n好友关注\n附近的商户\n用户签到\nUV统计\n\n\n\n短信登录（1）导入商户点评项目\n项目下载地址\n\n\nhm-dianping.zip (将其下载解压缩后复制到idea工作空间，然后利用idea打开即可)（修改自己的MySQL和Redis配置）\n\n启动项目后，在浏览器访问：http://localhost:8081/shop-type/list ，如果可以看到数据则证明运行没有问题\n\nhmdp.sql（导入SQL文件。Mysql的版本采用5.7及以上版本）（注意先创建数据库）\nnginx-1.18.0.zip（windows版本。解压缩后启动即可）\n\n访问: http://127.0.0.1:8080 ，即可看到页面\n\n\n\n\n\n\n\n\n（2）基于Session实现登录\n\n\n\n集群的session共享问题\n基于Redis实现共享session登录\n\n","categories":["database","redis"],"tags":["redis"]},{"title":"《Kafka 核心技术与实战》study notes","url":"/%E3%80%8AKafka-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/","content":"开篇词 (1讲)开篇词 | 为什么要学习Kafka？\n当下互联网行业最火的技术当属 ABC 了\n\nAI 人工智能\nBigData 大数据\nCloud 云计算云平台\n\n\n对于数据密集型应用来说，如何应对数据量激增、数据复杂度增加以及数据变化速率变快，是彰显大数据工程师、架构师功力的最有效表征\n\nKafka 在帮助应对这些问题方面能起到非常好的效果（Kafka 能够有效隔离上下游业务，将上游突增的流量缓存起来，以平滑的方式传导到下游子系统中，避免了流量的不规则冲击）\n\n\nKafka 有着非常广阔的应用场景\n\n目前 Apache Kafka 被认为是整个消息引擎领域的执牛耳者\n从学习技术的角度而言，Kafka 也是很有亮点的（我们仅需要学习一套框架就能在实际业务系统中实现消息引擎应用、应用程序集成、分布式存储构建，甚至是流处理应用的开发与部署）\nKafka 无论是作为消息引擎还是实时流处理平台，都能在大数据工程领域发挥重要的作用\n\n\n\n\n\n学透 Kafka 推荐路径\n软件开发工程师\n\n\n根据你掌握的编程语言去寻找对应的 Kafka 客户端\n去官网上学习一下代码示例（如果能够正确编译和运行这些样例，就能轻松地驾驭客户端了）\n尝试修改样例代码尝试去理解并使用其他的 API（观测修改的结果）\n编写一个小型项目来验证下学习成果，然后就是改善和提升客户端的可靠性和性能了\n熟读一遍 Kafka 官网文档，确保理解了那些可能影响可靠性和性能的参数\n学习 Kafka 的高级功能（比如流处理应用开发。流处理 API 不仅能够生产和消费消息，还能执行高级的流式处理操作，比如时间窗口聚合、流处理连接等）\n\n\n系统管理员或运维工程师\n\n\n如果你是系统管理员或运维工程师，那么相应的学习目标应该是学习搭建及管理 Kafka 线上环境。如何根据实际业务需求评估、搭建生产线上环境将是你主要的学习目标。另外对生产环境的监控也是重中之重的工作，Kafka 提供了超多的 JMX 监控指标，你可以选择任意你熟知的框架进行监控。有了监控数据，作为系统运维管理员的你，势必要观测真实业务负载下的 Kafka 集群表现。之后如何利用已有的监控指标来找出系统瓶颈，然后提升整个系统的吞吐量，这也是最能体现你工作价值的地方\n\n\n\n专栏思维导图\n\n\n\n（1）Kafka 入门\n\n介绍消息引擎这类系统大致的原理和用途，以及作为优秀消息引擎代表的 Kafka 在这方面的表现\n\n（2）Kafka 的基本使用\n\n重点探讨 Kafka 如何用于生产环境，特别是线上环境方案的制定\n\n（3）客户端详解\n\n学习 Kafka 客户端的方方面面，既有生产者的实操讲解也有消费者的原理剖析\n\n（4）Kafka 原理介绍\n\n着重介绍 Kafka 最核心的设计原理，包括 Controller 的设计机制、请求处理全流程解析等\n\n（5）Kafka 运维与监控\n\n获得高效运维 Kafka 集群以及有效监控 Kafka 的实战经验\n\n（6）高级 Kafka 应用\n\nKafka 流处理组件 Kafka Streams 的实战应用\n\n\n\n\n\n\n\nKafka入门 (5讲)01 | 消息引擎系统ABC\nApache Kafka 是一款开源的消息引擎系统\n消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递\nKafka使用纯二进制字节序列传递消息，消息也是有结构的\n\n\n\n消息引擎传输消息模型\n点对点模型：一对一发送or接收消息\n发布 / 订阅模型：它有一个主题（Topic）的概念（可以理解成逻辑语义相近的消息容器）。发送方也称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个\n\n\n\n\nJMS：JMS 是 Java Message Service，它也是支持上面这两种消息引擎模型的。严格来说它并非传输协议而仅仅是一组 API 罢了\n\n\n\n为什么要使用消息引擎\n削峰填谷\n\n\n​    所谓的“削峰填谷”就是指缓冲上下游瞬时突发流量，使其更平滑。特别是对于那种发送能力很强的上游系统，如果没有消息引擎的保护，“脆弱”的下游系统可能会直接被压垮导致全链路服务“雪崩”。但是，一旦有了消息引擎，它能够有效地对抗上游的流量冲击，真正做到将上游的“峰”填满到“谷”中，避免了流量的震荡。消息引擎系统的另一大好处在于发送方和接收方的松耦合，这也在一定程度上简化了应用的开发，减少了系统间不必要的交互。\n\n\n当引入了 Kafka 之后。上游订单服务不再直接与下游子服务进行交互。当新订单生成后它仅仅是向 Kafka Broker 发送一条订单消息即可。类似地，下游的各个子服务订阅 Kafka 中的对应主题，并实时从该主题的各自分区（Partition）中获取到订单消息进行处理，从而实现了上游订单服务与下游订单处理服务的解耦。这样当出现秒杀业务时，Kafka 能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的 TPS，同时也给下游子服务留出了充足的时间去消费它们。这就是 Kafka 这类消息引擎系统的最大意义所在。\n\n\n\n\n\n02 | 一篇文章带你快速搞定Kafka术语\n消息：Record。Kafka 是消息引擎，这里的消息就是指 Kafka 处理的主要对象。\n主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。\n分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。\n消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。\n副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。\n生产者：Producer。向主题发布新消息的应用程序。\n消费者：Consumer。从主题订阅新消息的应用程序。\n消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。\n消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。\n重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。\n\n\n\n\n\n\n\n\n生产者和消费者统称为客户端（Clients）\nKafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。\n\n\n\nKafka提供高可用的手段\n多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上（这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务）\n备份机制（Replication）（把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在 Kafka 中被称为副本（Replica））\n\n\n\n副本的工作机制\n生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。\n副本机制可以保证数据的持久化或消息不丢失\n\n\n\nKafka解决伸缩性\n伸缩性即所谓的 Scalability，是分布式系统中非常重要且必须要谨慎对待的问题\n什么是伸缩性：我们拿副本来说，虽然现在有了领导者副本和追随者副本，但倘若领导者副本积累了太多的数据以至于单台 Broker 机器都无法容纳了，此时应该怎么办呢？把数据分割成多份保存在不同的 Broker 上。这种机制就是所谓的分区（Partitioning）\n\n\n\n分区机制\nKafka 中的分区机制指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。\n\n\n生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，这条消息要么在分区 0 中，要么在分区 1 中。如你所见，Kafka 的分区编号是从 0 开始的，如果 Topic 有 100 个分区，那么它们的分区号就是从 0 到 99。\n\n\n副本：副本是在分区这个层级定义的。\n\n\n每个分区下可以配置若干个副本，其中只能有 1 个领导者副本和 N-1 个追随者副本。生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征。分区位移总是从 0 开始，假设一个生产者向一个空分区写入了 10 条消息，那么这 10 条消息的位移依次是 0、1、2、…、9。\n\n\n\nKafka 的三层消息架构\n第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。\n第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。\n第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。\n最后，客户端程序只能与分区的领导者副本进行交互。\n\n\n\nKafka Broker 是如何持久化数据的\nKafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。\n\n\n因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。\n\n\n日志段（Log Segment）机制\n在 Kafka 底层，一个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。\n\n\n\n\n\n消费者组\nKafka 中实现这种 P2P 模型的方法就是引入了消费者组（Consumer Group）。\n\n\n所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。为什么要引入消费者组呢？主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。\n\n\n这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。\n\n\n\n重平衡\n消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助。\n\n\n假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。\n\n\n由重平衡引发的消费者问题比比皆是。事实上，目前很多重平衡的 Bug 社区都无力解决。\n\n\n\n\n每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）。\n\n\n\n\n\n03 | Kafka只是消息引擎系统吗？有的时候我们会觉得说了解一个系统或框架的前世今生似乎没什么必要，直接开始学具体的技术不是更快更好吗？其实，不论是学习哪种技术，直接扎到具体的细节中，亦或是从一个很小的点开始学习，你很快就会感到厌烦。为什么呢？因为你虽然快速地搞定了某个技术细节，但无法建立全局的认知观，这会导致你只是在单个的点上有所进展，却没法将其串联成一条线进而扩展成一个面，从而实现系统地学习。\n\nApache Kafka 是消息引擎系统，也是一个分布式流处理平台（Distributed Streaming Platform）\n\n\n\n\nKafka 在设计之初就旨在提供三个方面的特性：\n提供一套 API 实现生产者和消费者；\n降低网络传输和磁盘存储开销；\n实现高伸缩性架构。\n\n\n\n\n\n\n开源之后的 Kafka 被越来越多的公司应用到它们企业内部的数据管道中，特别是在大数据工程领域，Kafka 在承接上下游、串联数据流管道方面发挥了重要的作用：所有的数据几乎都要从一个系统流入 Kafka 然后再流向下游的另一个系统中。这样的使用方式屡见不鲜以至于引发了 Kafka 社区的思考：与其我把数据从一个系统传递到下一个系统中做处理，我为何不自己实现一套流处理框架呢？基于这个考量，Kafka 社区于 0.10.0.0 版本正式推出了流处理组件 Kafka Streams，也正是从这个版本开始，Kafka 正式“变身”为分布式的流处理平台，而不仅仅是消息引擎系统了。今天 Apache Kafka 是和 Apache Storm、Apache Spark 和 Apache Flink 同等级的实时流处理平台。\n\n\n\nKafka 与其他主流大数据流式计算框架相比的优势\n第一点是更容易实现端到端的正确性（Correctness）。\n要实现正确性和提供能够推导时间的工具。实现正确性是流处理能够匹敌批处理的基石。\n\n\n对于流式计算的定位\n需要自己选择适合的工具或系统来帮助 Kafka 流处理应用实现这些功能\n\n\n\n\n\n\n\n04 | 我应该选择哪种Kafka？Kafka Connect\nKafka Connect 通过一个个具体的连接器（Connector），串联起上下游的外部系统。\n\n\n\n\nKafka Connect 组件支持的一部分外部系统，如下图\n\n\n\n\n\nKafka种类Apache Kafka\nApache Kafka 是最“正宗”的 Kafka，也应该是你最熟悉的发行版了。自 Kafka 开源伊始，它便在 Apache 基金会孵化并最终毕业成为顶级项目，它也被称为社区版 Kafka。\n后面提到的发行版要么是原封不动地继承了 Apache Kafka，要么是在此之上扩展了新功能\n开发人数最多、版本迭代速度最快的 Kafka。社区活跃\n劣势：仅仅提供最最基础的组件\n社区版 Kafka 只提供一种连接器，即读写磁盘文件的连接器，而没有与其他外部系统交互的连接器，在实际使用过程中需要自行编写代码实现\n\n\nApache Kafka 没有提供任何监控框架或工具。必然需要借助第三方的监控框架实现对 Kafka 的监控。（好消息是目前有一些开源的监控框架可以帮助用于监控 Kafka（比如 Kafka manager））\n\n\n\n\n如果你仅仅需要一个消息引擎系统亦或是简单的流处理应用场景，同时需要对系统有较大把控度，推荐你使用 Apache Kafka。\n\n\n\nConfluent Kafka\nConfluent 公司，它主要从事商业化 Kafka 工具开发，并在此基础上发布了 Confluent Kafka。Confluent Kafka 提供了一些 Apache Kafka 没有的高级特性，比如跨数据中心备份、Schema 注册中心以及集群监控工具等。\nConfluent Kafka 目前分为免费版和企业版两种。前者和 Apache Kafka 非常相像，除了常规的组件之外，免费版还包含 Schema 注册中心和 REST proxy 两大功能。前者是帮助你集中管理 Kafka 消息格式以实现数据前向 / 后向兼容；后者用开放 HTTP 接口的方式允许你通过网络访问 Kafka 的各种功能，这两个都是 Apache Kafka 所没有的。\n免费版包含了更多的连接器，它们都是 Confluent 公司开发并认证过的，你可以免费使用它们。至于企业版，它提供的功能就更多了。在我看来，最有用的当属跨数据中心备份和集群监控两大功能了。多个数据中心之间数据的同步以及对集群的监控历来是 Kafka 的痛点，Confluent Kafka 企业版提供了强大的解决方案帮助你“干掉”它们。\nConfluent 公司暂时没有发展国内业务的计划，相关的资料以及技术支持都很欠缺，很多国内 Confluent Kafka 使用者甚至无法找到对应的中文文档，因此目前 Confluent Kafka 在国内的普及率是比较低的。\n\n\n\nCloudera/Hortonworks Kafka\nCloudera 提供的 CDH 和 Hortonworks 提供的 HDP 是非常著名的大数据平台，里面集成了目前主流的大数据框架，能够帮助用户实现从分布式存储、集群调度、流处理到机器学习、实时数据库等全方位的数据处理。很多创业公司在搭建数据平台时首选就是这两个产品。不管是 CDH 还是 HDP 里面都集成了 Apache Kafka，因此我把这两款产品中的 Kafka 称为 CDH Kafka 和 HDP Kafka。\nKafka（CDH/HDP Kafka）。这些大数据平台天然集成了 Apache Kafka，通过便捷化的界面操作将 Kafka 的安装、运维、管理、监控全部统一在控制台中。\n降低了你对 Kafka 集群的掌控程度。\n滞后：由于它有自己的发布周期，因此是否能及时地包含最新版本的 Kafka 就成为了一个问题。\n\n\n\n\n如果需要快速地搭建消息引擎系统，或者你需要搭建的是多框架构成的数据平台且 Kafka 只是其中一个组件，那么我推荐你使用这些大数据云公司提供的 Kafka。\n\n\n\n小结\nApache Kafka，也称社区版 Kafka。优势在于迭代速度快，社区响应度高，使用它可以让你有更高的把控度；缺陷在于仅提供基础核心组件，缺失一些高级的特性。\nConfluent Kafka，Confluent 公司提供的 Kafka。优势在于集成了很多高级特性且由 Kafka 原班人马打造，质量上有保证；缺陷在于相关文档资料不全，普及率较低，没有太多可供参考的范例。\nCDH/HDP Kafka，大数据云公司提供的 Kafka，内嵌 Apache Kafka。优势在于操作简单，节省运维成本；缺陷在于把控度低，演进速度较慢。\n\n\n\n\n\n05 | 聊聊Kafka的版本号\n评判某 Kafka 版本是不是满足业务需求，就需要了解各个版本之间的差异和功能变化\n\n\n\nKafka 版本命名\nkafka-2.11-2.1.1\n前面的版本号是编译 Kafka 源代码的 Scala 编译器版本。（Kafka 服务器端的代码完全由 Scala 语言编写）\n真正的 Kafka 版本号实际上是 2.1.1\n前面的 2 表示大版本号，即 Major Version；中间的 1 表示小版本号或次版本号，即 Minor Version；最后的 1 表示修订版本号，也就是 Patch 号。\n\n\n\n\n\n\nKafka 社区在发布 1.0.0 版本后特意写过一篇文章，宣布 Kafka 版本命名规则正式从 4 位演进到 3 位，比如 0.11.0.0 版本就是 4 位版本号。\n假设碰到的 Kafka 版本是 0.10.2.2，你现在就知道了它的大版本是 0.10，小版本是 2，总共打了两个大的补丁，Patch 号是 2。\n\n\n\n\n\nKafka 版本演进\nKafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0，其中的小版本和 Patch 版本很多。\n\n\n\n\n0.7 版本\n最早开源时的“上古”版本。这个版本只提供了最基础的消息队列功能，甚至连副本机制都没有\n\n\n0.8\n正式引入了副本机制，至此 Kafka 成为了一个真正意义上完备的分布式高可靠消息队列解决方案。有了副本备份机制，Kafka 就能够比较好地做到消息无丢失。那时候生产和消费消息使用的还是老版本的客户端 API，所谓的老版本是指当你用它们的 API 开发生产者和消费者应用时，你需要指定 ZooKeeper 的地址而非 Broker 的地址。\n老版本客户端有很多的问题，特别是生产者 API，它默认使用同步方式发送消息，可以想见其吞吐量一定不会太高。虽然它也支持异步的方式，但实际场景中可能会造成消息的丢失，因此 0.8.2.0 版本社区引入了新版本 Producer API，即需要指定 Broker 地址的 Producer。\n国内依然有少部分用户在使用 0.8.1.1、0.8.2 版本。建议是尽量使用比较新的版本。如果不能升级大版本，也建议至少要升级到 0.8.2.2 这个版本，因为该版本中老版本消费者 API 是比较稳定的。另外即使升到了 0.8.2.2，也不要使用新版本 Producer API，此时它的 Bug 还非常多。\n\n\n0.9.0.0 版本\n2015 年 11 月，社区正式发布了 0.9.0.0 版本。\n0.9 大版本增加了基础的安全认证 / 权限功能，同时使用 Java 重写了新版本消费者 API，另外还引入了 Kafka Connect 组件用于实现高性能的数据抽取。\n新版本 Producer API 在这个版本中算比较稳定了。\n\n\n0.10.0.0\n0.10.0.0 是里程碑式的大版本，因为该版本引入了 Kafka Streams。从这个版本起，Kafka 正式升级成分布式流处理平台，虽然此时的 Kafka Streams 还基本不能线上部署使用。\n如果你依然在使用 0.10 大版本，我强烈建议你至少升级到 0.10.2.2 然后使用新版本 Consumer API。还有个事情不得不提，0.10.2.2 修复了一个可能导致 Producer 性能降低的 Bug。基于性能的缘故你也应该升级到 0.10.2.2。\n\n\n0.11.0.0 版本\n2017 年 6 月，社区发布了 0.11.0.0 版本，引入了两个重量级的功能变更：一个是提供幂等性 Producer API 以及事务（Transaction） API；另一个是对 Kafka 消息格式做了重构。\n\n\n\n\n\n\n不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致，否则你将损失很多 Kafka 为你提供的性能优化收益。\n\n\n\n\n\n\n\nKafka的基本使用 (3讲)06 | Kafka线上集群部署方案怎么做？\n\n\n\n\n\n学习备注\n1\n\n&amp;emsp;&amp;emsp;\n\n\n\n\n\n\n\n\n\n","categories":["MQ","Kafka"],"tags":["Kafka"]},{"title":"《MySQL 必知必会》study notes","url":"/%E3%80%8AMySQL-%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%E3%80%8Bstudy-notes/","content":"前言\n近期学习了极客时间的专栏《MySQL 必知必会》，对专栏的核心知识做了学习笔记，便于参考及查漏补缺\n\n\n\n\n\n\n\n课前准备 (2讲)开篇词-在实战中学习，是解锁MySQL技能的最佳方法\n熟练使用MySQL，对技术人来说变得越来越重要，是我们拿到心仪Offer的敲门砖\n最重要的绝对不是你的知识储备量，而是你解决实际问题的能力\n正确的学习方法，远比你投入的时间更重要。而实战，就是最高效的方法\n项目的实际需求–&gt;解决问题所需的知识点–&gt;用好这些知识的实战经验\n\n\n\n\n\n\n\n实践篇 (13讲)01 | 存储：一个完整的数据存储过程是怎样的？\n一个完整的数据存储过程总共有4步，分别是创建数据库、确认字段、创建数据表、插入数据\n\n\n\n\n\n\nMySQL数据库系统从大到小依次是：数据库服务器、数据库、数据表、数据表的行与列\n数据库是MySQL里面最大的存储单元 \n\n\n\n\n\n① 创建数据库# 创建数据库CREATE DATABASE `demo`  DEFAULT CHARACTER SET utf8mb4;# 查看数据库mysql&gt; SHOW DATABASES;+--------------------+| Database           |+--------------------+| demo               || information_schema || mysql              || performance_schema || sys                |+--------------------+5 rows in set (0.00 sec)\n\n\n“information_schema”是MySQL系统自带的数据库，主要保存MySQL数据库服务器的系统信息，比如数据库的名称、数据表的名称、字段名称、存取权限、数据文件所在的文件夹和系统使用的文件夹，等等。\n\n“performance_schema”是MySQL系统自带的数据库，可以用来监控MySQL的各类性能指标\n\n“sys”数据库是MySQL系统自带的数据库，主要作用是，以一种更容易被理解的方式展示MySQL数据库服务器的各类性能指标，帮助系统管理员和开发人员监控MySQL的技术性能\n\n“mysql”数据库保存了MySQL数据库服务器运行时需要的系统信息，比如数据文件夹、当前使用的字符集、约束检查信息，等等\n\n想深入了解MySQL数据库系统的相关信息，可以看下官方文档\n\n\n\n\n\n\n② 确认字段\nMySQL会让我们确认新表中有哪些列，以及它们的数据类型。这些列就是MySQL数据表的字段\n\n\n\n\n\n③ 创建数据表\n创建表的时候，最好指明数据库\n\nCREATE TABLE demo.test(   barcode text,  goodsname text,  price int); \n\n\n\n查看表的结构# 查看表的结构mysql&gt; describe demo.test;+-----------+------+------+-----+---------+-------+| Field     | Type | Null | Key | Default | Extra |+-----------+------+------+-----+---------+-------+| barcode   | text | YES  |     | NULL    |       || goodsname | text | YES  |     | NULL    |       || price     | int  | YES  |     | NULL    |       |+-----------+------+------+-----+---------+-------+3 rows in set (0.01 sec)\n\n\nField：表示字段名称\nType：表示字段类型\nNull：表示这个字段是否允许是空值（NULL）。注意，在MySQL里面，空值不等于空字符串。一个空字符串的长度是0，而一个空值的长度是空。而且，在MySQL里面，空值是占用空间的。\nKey：我们暂时把它叫做键。\nDefault：表示默认值。\nExtra：表示附加信息。\n\n\n\n查看数据库中的表USE demo;SHOW TABLES;\n\n\n\n设置主键\nMySQL中数据表的主键，是表中的一个字段或者几个字段的组合。它主要有3个特征：\n必须唯一，不能重复；\n不能是空；\n必须可以唯一标识数据表中的记录\n\n\n\n\n一个MySQL数据表中只能有一个主键。虽然MySQL也允许创建没有主键的表，但是，建议一定要给表定义主键，并且养成习惯。因为主键可以帮助减少错误数据，并且提高查询的速度\n\n# 如果数据表中所有的字段都有重复的可能。我们可以自己添加一个不会重复的字段来做主键ALTER TABLE demo.test ADD COLUMN itemnumber int PRIMARY KEY AUTO_INCREMENT;\n\n\n\n\n\n④ 插入数据INSERT INTO demo.test VALUES (&#x27;003&#x27;,&#x27;橡皮&#x27;,3);\n\n\n要插入数据的字段名也可以不写，但是建议不要怕麻烦，一定要每次都写。这样做的好处是可读性好，不易出错，而且容易修改。否则，如果记不住表的字段，就只能去查表的结构，才能知道值所对应的字段了。\n由于字段itemnumber定义了AUTO_INCREMENT，所以我们插入一条记录的时候，不给它赋值，系统也会自动给它赋值。而且，每次赋值，都会在上次的赋值基础上，自动增加1。也可以在插入一条记录的时候给itemnumber 赋值，由于它是主键，新的值必须与已有记录的itemnumber值不同，否则系统会提示错误。\n\n\n\n\n\n小结（sql汇总）-- 创建数据库CREATE DATABASE demo；-- 删除数据库DROP DATABASE demo；-- 查看数据库SHOW DATABASES;-- 创建数据表：CREATE TABLE demo.test(    barcode text,  goodsname text,  price int); -- 查看表结构DESCRIBE demo.test;-- 查看所有表DESCRIBE TABLES;-- 添加主键ALTER TABLE demo.testADD COLUMN itemnumber int PRIMARY KEY AUTO_INCREMENT;-- 向表中添加数据INSERT INTO demo.test(barcode,goodsname,price)VALUES (&#x27;0001&#x27;,&#x27;本&#x27;,3);\n\n\n\n\n\n02 | 字段：这么多字段类型，该怎么定义？\nMySQL中有很多字段类型，比如整数、文本、浮点数，等等。如果类型定义合理，就能节省存储空间，提升数据查询和处理的速度，相反，如果数据类型定义不合理，就有可能会导致数据超出取值范围，引发系统报错，甚至可能会出现计算错误的情况，进而影响到整个系统。\n\n\n\n\n\n整数类型\n\n\n\n\n在评估用哪种整数类型的时候，需要考虑存储空间和可靠性的平衡问题：一方面，用占用字节数少的整数类型可以节省存储空间；另一方面，要是为了节省存储空间，使用的整数类型取值范围太小，一旦遇到超出取值范围的情况，就可能引起系统错误，影响可靠性。\n\n最佳实践\n\n在评估用哪种整数类型的时候，需要考虑存储空间和可靠性的平衡问题（在实际工作中，系统故障产生的成本远远超过增加几个字段存储空间所产生的成本）\n确保数据不会超过取值范围，再去考虑如何节省存储空间\n\n\n\n\n\n\n\n浮点数类型和定点数类型\n可以把整数看成小数的一个特例\n\n\nFLOAT表示单精度浮点数\nDOUBLE表示双精度浮点数\nREAL默认就是DOUBLE。如果你把SQL模式设定为启用“REAL_AS_FLOAT”，那么，MySQL就认为REAL是FLOAT\n\n# 如果要启用“REAL_AS_FLOAT”，就可以通过以下SQL语句实现：SET sql_mode = “REAL_AS_FLOAT”;\n\n\nFLOAT占用字节数少，取值范围小；DOUBLE占用字节数多，取值范围也大\n\n\n\n\n\n\n为什么浮点数类型的无符号数取值范围，只相当于有符号数取值范围的一半，也就是只相当于有符号数取值范围大于等于零的部分呢？\n\n\n原因是：MySQL是按照这个格式存储浮点数的：符号（S）、尾数（M）和阶码（E）。因此，无论有没有符号，MySQL的浮点数都会存储表示符号的部分。因此，所谓的无符号数取值范围，其实就是有符号数取值范围大于等于零的部分。\n\n\n\n浮点数类型有缺陷：不精准\n不精准问题原因在于：MySQL对浮点类型数据的存储方式上\n\n\nMySQL用4个字节存储FLOAT类型数据，用8个字节来存储DOUBLE类型数据。无论哪个，都是采用二进制的方式来进行存储的。比如9.625，用二进制来表达，就是1001.101，或者表达成1.001101×2^3。看到了吗？如果尾数不是0或5（比如9.624），你就无法用一个二进制数来精确表达。怎么办呢？就只好在取值允许的范围内进行近似（四舍五入）。\n\n\n为什么数据类型是DOUBLE的时候，计算结果误差比FLOAT小一点？\n\n\n原因：DOUBLE有8位字节，精度更高\n\n\n\n定点数类型：DECIMAL\nDECIMAL的存储方式决定了它一定是精准的\n\n\n浮点数类型是把十进制数转换成二进制数存储，DECIMAL则不同，它是把十进制数的整数部分和小数部分拆开，分别转换成十六进制数，进行存储。这样，所有的数值，就都可以精准表达了，不会存在因为无法表达而损失精度的问题\n\n小结：浮点数和定点数的特点/适用场景/最佳实践\n浮点类型取值范围大，但是不精准，适用于需要取值范围大，又可以容忍微小误差的科学计算场景（比如计算化学、分子建模、流体动力学等）；定点数类型取值范围相对小，但是精准，没有误差，适合于对精度要求极高的场景（比如涉及金额计算的场景）\n\n\n\n文本类型\nCHAR(M)：固定长度字符串。CHAR(M)类型必须预先定义字符串长度。如果太短，数据可能会超出范围；如果太长，又浪费存储空间。\nVARCHAR(M)： 可变长度字符串。VARCHAR(M)也需要预先知道字符串的最大长度，不过只要不超过这个最大长度，具体存储的时候，是按照实际字符串长度存储的。\nTEXT：字符串。系统自动按照实际长度存储，不需要预先定义长度。\nENUM： 枚举类型，取值必须是预先设定的一组字符串值范围之内的一个，必须要知道字符串所有可能的取值。\nSET：是一个字符串对象，取值必须是在预先设定的字符串值范围之内的0个或多个，也必须知道字符串所有可能的取值。\n\n\nTEXT类型也有4种，它们的区别就是最大长度不同。\n\nTINYTEXT：占用255字符。\n\nTEXT： 占用65535字符。\n\nMEDIUMTEXT：占用16777215字符。\n\nLONGTEXT： 占用4294967295字符（相当于4GB）\n\n\n\nTEXT类型存在的问题：由于实际存储的长度不确定，MySQL不允许TEXT类型的字段做主键。遇到这种情况，你只能采用CHAR(M)，或者VARCHAR(M)\n\n最佳实践\n\n项目中，只要不是主键字段，就可以按照数据可能的最大长度，选择这几种TEXT类型中的的一种，作为存储字符串的数据类型\n\n\n\n\n\n\n\n日期与时间类型\n\n\n最佳实践\n\n\n在实际项目中，尽量用DATETIME类型。因为这个数据类型包括了完整的日期和时间信息，使用起来比较方便\n为了确保数据的完整性和系统的稳定性，优先考虑使用DATETIME类型。因为虽然DATETIME类型占用的存储空间最多，但是它表达的时间最为完整，取值范围也最大\n\n\n为什么时间类型TIME的取值范围不是-23:59:59～23:59:59呢\n\n\n原因是MySQL设计的TIME类型，不光表示一天之内的时间，而且可以用来表示一个时间间隔，这个时间间隔可以超过24小时。\n\n小结-- 修改字段类型语句ALTER TABLE demo.goodsmasterMODIFY COLUMN price DOUBLE;-- 计算字段合计函数：SELECT SUM(price)FROM demo.goodsmaster;\n\n\n\n\n在定义数据类型时，如果确定是整数，就用INT；如果是小数，一定用定点数类型DECIMAL；如果是字符串，只要不是主键，就用TEXT；如果是日期与时间，就用DATETIME。（首先确保你的系统不会因为数据类型定义出错。）\n\n\n\n\n\n03 | 表：怎么创建和修改数据表？创建数据表CREATE TABLE &lt;表名&gt;&#123;字段名1 数据类型 [字段级别约束] [默认值]，字段名2 数据类型 [字段级别约束] [默认值]，......[表级别约束]&#125;;\n\n\n“约束”限定了表中数据应该满足的条件\nMySQL会根据这些限定条件，对表的操作进行监控，阻止破坏约束条件的操作执行，并提示错误，从而确保表中数据的唯一性、合法性和完整性\n\n\n\n\n\n都有哪些约束1.非空约束\n\n非空约束表示字段值不能为空\n\n2.唯一性约束\n\n唯一性约束表示这个字段的值不能重复。满足主键约束的字段，自动满足非空约束，但是满足唯一性约束的字段，则可以是空值\n\n3.自增约束\n\n在数据表中，只有整数类型的字段（包括TINYINT、SMALLINT、MEDIUMINT、INT和BIGINT），才可以定义自增约束。自增约束的字段，每增加一条数据，值自动增加1。\n给自增约束的字段赋值，这个时候，MySQL会重置自增约束字段的自增基数，下次添加数据的时候，自动以自增约束字段的最大值加1为新的字段值。\n\n\n\n\n\n如何修改表CREATE demo.importheadhistLIKE demo.importhead;ALTER TABLE demo.importheadhist ADD confirmer INT;ALTER TABLE demo.importheadhist ADD confirmdate DATETIME;\n\n\n\n\n\n修改字段\nchange 可以更改列名 和 列类型 (每次都要把新列名和旧列名写上, 即使两个列名没有更改,只是改了类型)\nmodify 只能更改列属性 只需要写一次列名, 比change 省事点\n\n-- modify 能修改字段类型、类型长度、默认值、注释ALTER  TABLE 表名 MODIFY [COLUMN] 字段名 新数据类型 新类型长度  新默认值  新注释;ALTER  TABLE 表名 CHANGE [column] 旧字段名 新字段名 新数据类型;-- 指定添加字段在表中位置ALTER TABLE demo.importheadhist ADD suppliername TEXT AFTER supplierid;\n\n\n\n\n\n小结CREATE TABLE(字段名 字段类型 PRIMARY KEY);CREATE TABLE(字段名 字段类型 NOT NULL);CREATE TABLE(字段名 字段类型 UNIQUE);CREATE TABLE(字段名 字段类型 DEFAULT 值);-- 这里要注意自增类型的条件，字段类型必须是整数类型。CREATE TABLE(字段名 字段类型 AUTO_INCREMENT);-- 在一个已经存在的表基础上，创建一个新表CREATE demo.importheadhist LIKE demo.importhead;-- 修改表的相关语句ALTER TABLE 表名 CHANGE 旧字段名 新字段名 数据类型;ALTER TABLE 表名 ADD COLUMN 字段名 字段类型 FIRST|AFTER 字段名;ALTER TABLE 表名 MODIFY 字段名 字段类型 FIRST|AFTER 字段名;\n\n\n\n\n\n04 | 增删改查：如何操作表中的数据？添加数据INSERT INTO 表名 [(字段名 [,字段名] ...)] VALUES (值的列表);\n\n\n\n\n\n插入数据记录\n部分插入一条数据记录是可以的，但前提是，没有赋值的字段，一定要让MySQL知道如何处理，比如可以为空、有默认值，或者是自增约束字段，等等，否则，MySQL会提示错误的\n\n\n\n\n\n插入查询结果INSERT INTO 表名 （字段名）SELECT 字段名或值FROM 表名WHERE 条件\n\n\n\n\n\n删除数据DELETE FROM 表名 WHERE 条件\n\n\n\n\n\n修改数据UPDATE 表名 SET 字段名=值 WHERE 条件\n\n\n不要修改主键字段的值，如果你必须要修改主键的值，那有可能就是主键设置得不合理\n\n\n\n\n\n查询数据SELECT *|字段列表FROM 数据源WHERE 条件GROUP BY 字段HAVING 条件ORDER BY 字段LIMIT 起始点，行数-- GROUP BY：作用是告诉MySQL，查询结果要如何分组，经常与MySQL的聚合函数一起使用-- HAVING：用于筛选查询结果，跟WHERE类似\n\n\n\n\n\n小结INSERT INTO 表名 [(字段名 [,字段名] ...)] VALUES (值的列表); INSERT INTO 表名 （字段名）SELECT 字段名或值FROM 表名WHERE 条件 DELETE FROM 表名WHERE 条件 UPDATE 表名SET 字段名=值WHERE 条件SELECT *|字段列表FROM 数据源WHERE 条件GROUP BY 字段HAVING 条件ORDER BY 字段LIMIT 起始点，行数\n\n\n如果我们把查询的结果插入到表中时，导致主键约束或者唯一性约束被破坏了，就可以用“ON DUPLICATE”关键字进行处理。这个关键字的作用是，告诉MySQL，如果遇到重复的数据，该如何处理。\n\nINSERT INTO demo.goodsmaster SELECT *FROM demo.goodsmaster1 as aON DUPLICATE KEY UPDATE barcode = a.barcode,goodsname=a.goodsname;\n\n\n\n\n\n05 | 主键：如何正确设置主键？业务字段做主键\n尽量不要用业务字段，也就是跟业务有关的字段做主键。毕竟，作为项目设计的技术人员，我们谁也无法预测在项目的整个生命周期中，哪个业务字段会因为项目的业务需求而有重复，或者重用之类的情况出现\n\n\n\n使用自增字段做主键UPDATE demo.trans AS a,demo.membermaster AS bSET a.memberid=b.idWHERE a.transactionno &gt; 0  AND a.cardno = b.cardno; -- 这样操作可以不用删除trans的内容，在实际工作中更适合\n\n\n如果是一个小项目，只有一个MySQL数据库服务器，用添加自增字段作为主键的办法是可以的。不过，这并不意味着，在任何情况下你都可以这么做\n自增字段做主键，对于单机系统来说是没问题的。但是，如果有多台服务器，各自都可以录入数据，那就不一定适用了。因为如果每台机器各自产生的数据需要合并，就可能会出现主键重复的问题\n\n\n\n手动赋值字段做主键\n我们可以采用手动赋值的办法，通过一定的逻辑，确保字段值在全系统的唯一性，这样就可以规避主键重复的问题了\n\n\n取消字段“id”的自增属性，改成信息系统在添加会员的时候对“id”进行赋值。\n门店在添加会员的时候，先到总部MySQL数据库中获取这个最大值，在这个基础上加1，然后用这个值作为新会员的“id”，同时，更新总部MySQL数据库管理信息表中的当前会员编号的最大值\n各个门店添加会员的时候，都对同一个总部MySQL数据库中的数据表字段进行操作，就解决了各门店添加会员时会员编号冲突的问题，同时也避免了使用业务字段导致数据错误的问题\n\n\n\n最佳实践\n刚开始使用MySQL时，很多人都很容易犯的错误是喜欢用业务字段做主键，想当然地认为了解业务需求，但实际情况往往出乎意料，而更改主键设置的成本非常高。所以，如果你的系统比较复杂，尽量给表加一个字段做主键，采用手动赋值的办法，虽然系统开发的时候麻烦一点，却可以避免后面出大问题。\n\n\n\n\n\n06 | 外键和连接：如何做关联查询？\n把分散在多个不同的表里的数据查询出来的操作，就是多表查询\n\n\n\n创建外键\n外键就是从表中用来引用主表中数据的那个公共字段\n\n\n在MySQL中，外键是通过外键约束来定义的。外键约束就是约束的一种，它必须在从表中定义，包括指明哪个是外键字段，以及外键字段所引用的主表中的主键字段是什么。MySQL系统会根据外键约束的定义，监控对主表中数据的删除操作。如果发现要删除的主表记录，正在被从表中某条记录的外键字段所引用，MySQL就会提示错误，从而确保了关联数据不会缺失。\n\n-- 外键约束定义的语法结构[CONSTRAINT &lt;外键约束名称&gt;] FOREIGN KEY 字段名REFERENCES &lt;主表名&gt; 字段名-- 外键约束可以在创建表的时候定义CREATE TABLE 从表名(  字段名 类型,  ...-- 定义外键约束，指出外键字段和参照的主表字段CONSTRAINT 外键约束名FOREIGN KEY (字段名) REFERENCES 主表名 (字段名))-- 可以通过修改表来定义。ALTER TABLE 从表名 ADD CONSTRAINT 约束名 FOREIGN KEY 字段名 REFERENCES 主表名 （字段名）;\n\n\n\n连接\nMySQL中，有2种类型的连接，分别是内连接（INNER JOIN）和外连接（OUTER JOIN\n\n内连接表示查询结果只返回符合连接条件的记录\n外连接则不同，表示查询结果返回某一个表中的所有记录，以及另一个表中满足连接条件的记录\n左连接，一般简写成LEFT JOIN，返回左边表中的所有记录，以及右表中符合连接条件的记录。\n右连接，一般简写成RIGHT JOIN，返回右边表中的所有记录，以及左表中符合连接条件的记录\n\n\n\n\n在MySQL里面，关键字JOIN、INNER JOIN、CROSS JOIN的含义是一样的，都表示内连接\n\n\n\n大型网站的中央数据库，可能会因为外键约束的系统开销而变得非常慢。所以，MySQL允许你不使用系统自带的外键约束，在应用层面完成检查数据一致性的逻辑。也就是说，即使你不用外键约束，也要想办法通过应用层面的附加逻辑，来实现外键约束的功能，确保数据的一致性。\n\n\n\n小结-- 定义外键约束：CREATE TABLE 从表名(字段 字段类型....CONSTRAINT 外键约束名称FOREIGN KEY (字段名) REFERENCES 主表名 (字段名称));ALTER TABLE 从表名 ADD CONSTRAINT 约束名 FOREIGN KEY 字段名 REFERENCES 主表名 （字段名）;-- 连接查询SELECT 字段名FROM 表名 AS aJOIN 表名 AS bON (a.字段名称=b.字段名称); SELECT 字段名FROM 表名 AS aLEFT JOIN 表名 AS bON (a.字段名称=b.字段名称); SELECT 字段名FROM 表名 AS aRIGHT JOIN 表名 AS bON (a.字段名称=b.字段名称);\n\n\n无法承担外键约束的成本，也可以不定义外键约束，但是一定要在应用层面实现外键约束的逻辑功能，这样才能确保系统的正确可靠\n\n\n\n\n\n07 | 条件语句：WHERE 与 HAVING有什么不同?\n\n\n\n\n\n08 | 聚合函数：怎么高效地进行分组统计？\n\n\n\n\n\n09 | 时间函数：时间类数据，MySQL是怎么处理的？\n\nSQL汇总-- 创建数据库CREATE DATABASE demo；-- 删除数据库DROP DATABASE demo；-- 查看数据库SHOW DATABASES;-- 创建数据表：CREATE TABLE demo.test(    barcode text,  goodsname text,  price int); -- 查看表结构DESCRIBE demo.test;-- 查看所有表-- DESCRIBE TABLES;-- 添加主键ALTER TABLE demo.testADD COLUMN itemnumber int PRIMARY KEY AUTO_INCREMENT;-- 向表中添加数据INSERT INTO demo.test(barcode,goodsname,price)VALUES (&#x27;0001&#x27;,&#x27;本&#x27;,3);-- 修改字段类型语句ALTER TABLE demo.goodsmasterMODIFY COLUMN price DOUBLE;-- 计算字段合计函数：SELECT SUM(price)FROM demo.goodsmaster;\n\n\n\n\n\n\n\n参考延伸\nSQL样式指南\n\n\n学习备注\n\nwork_bench 的熟悉使用\n浮点数存储数据的方式，需要深入理解一下\n需要了解，修改表名，不同位置插入等\n\n\n\n\n\n\n\n\n\n\n\n\n","categories":["database","MySQL"],"tags":["database","MySQL"]},{"title":"《Nginx体系化深度精讲》study notes","url":"/%E3%80%8ANginx%E4%BD%93%E7%B3%BB%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%B2%BE%E8%AE%B2%E3%80%8Bstudy-notes/","content":"Nginx初体验Nginx概念\nNginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。Nginx是由伊戈尔·赛索耶夫为俄罗斯访问量第二的Rambler.ru站点（俄文：Рамблер）开发的，公开版本1.19.6发布于2020年12月15日。\n\n其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、简单的配置文件和低系统资源的消耗而闻名。2022年01月25日，nginx 1.21.6发布。\n\nNginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，在BSD-like 协议下发行。其特点是占有内存少，并发能力强，事实上nginx的并发能力在同类型的网页服务器中表现较好。\n\n\n\n\n\n\nNginx缘起历史\n互联网数据的快速增长\nApache处理请求的低效性\n\n\n\n\nApache\nNginx\n\n\n\n一个进程处理一个请求\n一个进程处理多个请求\n\n\n阻塞式的\n非阻塞式的\n\n\n\n\n\n\nNginx三个主要企业应用场景\n\n\n\n\n\nNginx核心优势\n高并发、高性能\n扩展性好\n异步非阻塞的事件驱动模型\n高可靠性\n热部署\n\n\n\n\n\n安装rpm包Nginx# （1）下载epel yum源yum install epel-release -y# （2）查看yum源里可安装的nginxyum list all |grep nginx# （3）下载nginxyum install nginx -y# （4）列出 nginx 安装的文件rpm -ql nginx\t# （5）查看nginx启动文件所在目录rpm -ql nginx |grep bin# Nginx的二进制文件所在目录/usr/sbin/nginx\n\n\n\n\n\n\n\nNginx进程结构与热部署多进程与多线程多进程Nginx的进程结构\n\n\n真正处理请求的不是 master process，二是 worker process\n\n\n\n\n\nLinux的信号量管理机制\nlinux中的所有信号量\n\n[root@localhost nginx]# kill -l 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR111) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+338) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+843) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-758) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-263) SIGRTMAX-1  64) SIGRTMAX\n\n\n常用信号量\n\n\n\n\n\n\n\n利用信号量管理Nginx# 关闭nginxkill -s SIGTERM [nginx master进程pid]# 重新读取配置文件，会关闭之前的work子进程，生成新的work子进程 kill -s SIGHUP [nginx master进程pid]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n配置文件重载的原理真相reload 重载配置文件的流程\n向master进程发送HUP信号（reload命令）\nmaster进程检查配置语法是否正确\nmaster进程打开监听端口\nmaster进程使用新的配置文件启动新的worker子进程\nmaster进程向老的worker子进程发送QUIT信号\n旧的worker进程关闭监听句柄，处理完当前连接后关闭进程\n\n\n\n\n\n\n\nNginx的热部署热升级的流程（前提：新旧Nginx的编译目录一致）\n将旧的nginx文件替换成新的nginx文件（二进制主程序文件）\n向master进程发送USR2信号\nmaster进程修改pid文件，加后缀.oldbin\nmaster进程用新nginx文件启动新master进程\n向旧的master进程发送WINCH信号，旧的worker子进程退出\n回滚槽形：向旧master发送HUP ,向新的master发送QUIT\n\n\n\n\n\nNginx热部署完整步骤演示Nginx热升级核心命令解释# 备份nginx二进制文件cp nginx nginx.bak# 生成新的nginx 主进程 和子进程（新老master、worker进程共存）kill -s SIGUSR2 [pid]# 关闭nginx master进程下的worker子进程kill -s SIGWINCH [pid]# 关闭进程kill -s SIGQUIT [pid]# 让旧master进程 启动work子进程（使用的还是旧的nginx二进制文件）kill -s SIGHUP [pid]\n\n\n注意事项\n\n\n不能使用 kill -s SIGHU [] 退出旧的master进程，如果这样做的话，旧的 master主进程和其子进程会直接退出（被kill掉），这样（当新启的nginx进程有问题时）就无法回滚。\n所以应该使用 kill -s SIGWINCH []，先将旧的master主进程下的work子进程全部kill掉，验证新启的nginx进程没有问题后，再使用 kill -s SIGHU []    kill掉旧的master进程。如果验证新启的nginx进程有问题，这时使用 kill -s SIGHUP [] 就可以让旧master进程重新启动work子进程。（达到回滚的效果）\n\n\n\nNginx正常热升级详细步骤演示# （1）查看nginx处于正常运行状态[root@bogon nginx]# ps -ef |grep nginxroot     105723   1480  0 16:35 pts/0    00:00:00 grep --color=auto nginx[root@bogon nginx]# /usr/local/nginx/sbin/nginx[root@bogon nginx]# ps -ef |grep nginxroot     105739      1  0 16:35 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    105740 105739  0 16:35 ?        00:00:00 nginx: worker processnginx    105741 105739  0 16:35 ?        00:00:00 nginx: worker processnginx    105742 105739  0 16:35 ?        00:00:00 nginx: worker processnginx    105743 105739  0 16:35 ?        00:00:00 nginx: worker processroot     105747   1480  0 16:35 pts/0    00:00:00 grep --color=auto nginx# （2）备份nginx的二进制文件，并将新的nginx替换成旧的nginx[root@bogon nginx]# cd /usr/local/nginx/sbin/[root@bogon sbin]# ll总用量 6128-rwxr-xr-x. 1 root root 6272440 10月  6 16:16 nginx[root@bogon sbin]# cp nginx nginx.old[root@bogon sbin]# ll总用量 12256-rwxr-xr-x. 1 root root 6272440 10月  6 16:16 nginx-rwxr-xr-x. 1 root root 6272440 10月  6 16:36 nginx.old# （3）给旧的nginx master 进程发送 SIGUSR2信号后。nginx 新旧master进程、worker子进程共存。[root@bogon sbin]# ps -ef |grep nginxroot     105739      1  0 16:35 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    105740 105739  0 16:35 ?        00:00:00 nginx: worker processnginx    105741 105739  0 16:35 ?        00:00:00 nginx: worker processnginx    105742 105739  0 16:35 ?        00:00:00 nginx: worker processnginx    105743 105739  0 16:35 ?        00:00:00 nginx: worker processroot     106243   1480  0 16:45 pts/0    00:00:00 grep --color=auto nginx[root@bogon sbin]# kill -s SIGUSR2 105739[root@bogon sbin]# ps -ef |grep nginxroot     105739      1  0 16:35 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    105740 105739  0 16:35 ?        00:00:00 nginx: worker processnginx    105741 105739  0 16:35 ?        00:00:00 nginx: worker processnginx    105742 105739  0 16:35 ?        00:00:00 nginx: worker processnginx    105743 105739  0 16:35 ?        00:00:00 nginx: worker processroot     106255 105739  0 16:45 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    106256 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106257 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106258 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106259 106255  0 16:45 ?        00:00:00 nginx: worker processroot     106268   1480  0 16:45 pts/0    00:00:00 grep --color=auto nginx[root@bogon nginx]# ll pid/总用量 8-rw-r--r--. 1 root root 7 10月  6 16:45 nginx.pid-rw-r--r--. 1 root root 7 10月  6 16:35 nginx.pid.oldbin[root@bogon nginx]# cat pid/nginx.pid106255[root@bogon nginx]# cat pid/nginx.pid.oldbin105739# （4）向旧的master进程发送 SIGWINCH 信号，旧的 worker子进程退出。此时，所有请求会被新的worker进程处理[root@bogon nginx]# kill -s SIGWINCH 105739[root@bogon nginx]# ps -ef |grep nginxroot     105739      1  0 16:35 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxroot     106255 105739  0 16:45 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    106256 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106257 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106258 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106259 106255  0 16:45 ?        00:00:00 nginx: worker processroot     106643   1480  0 16:52 pts/0    00:00:00 grep --color=auto nginx# （5）验证新的ngixn 的 worker子进程没有错误后，向旧的master进程发送 SIGQUIT 信号。此时 旧的master进程退出。# 至此，nginx热升级成功[root@bogon nginx]# kill -s SIGQUIT 105739[root@bogon nginx]#[root@bogon nginx]# ps -ef |grep nginxroot     106255      1  0 16:45 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    106256 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106257 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106258 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106259 106255  0 16:45 ?        00:00:00 nginx: worker processroot     106814   1480  0 16:56 pts/0    00:00:00 grep --color=auto nginx[root@bogon nginx]# ll pid/总用量 4-rw-r--r--. 1 root root 7 10月  6 16:45 nginx.pid[root@bogon nginx]# cat pid/nginx.pid106255[root@bogon nginx]# ll sbin/总用量 12256-rwxr-xr-x. 1 root root 6272440 10月  6 16:16 nginx-rwxr-xr-x. 1 root root 6272440 10月  6 16:36 nginx.old[root@bogon nginx]# rm -rf sbin/nginx.old\n\n\n\nNginx热升级——回滚情形演示# （1）~（2）查看nginx处于正常运行状态；备份nginx的二进制文件，并将新的nginx替换成旧的nginx[root@bogon nginx]# ll sbin/总用量 6128-rwxr-xr-x. 1 root root 6272440 10月  6 16:16 nginx[root@bogon nginx]# cp sbin/nginx sbin/nginx.bak[root@bogon nginx]# ll sbin/总用量 12256-rwxr-xr-x. 1 root root 6272440 10月  6 16:16 nginx-rwxr-xr-x. 1 root root 6272440 10月  6 17:01 nginx.bak[root@bogon nginx]# ps -ef |grep nginxroot     106255      1  0 16:45 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    106256 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106257 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106258 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106259 106255  0 16:45 ?        00:00:00 nginx: worker processroot     107093   1480  0 17:01 pts/0    00:00:00 grep --color=auto nginx# （3）给旧的nginx master 进程发送 SIGUSR2信号后。nginx 新旧master进程、worker子进程共存。[root@bogon nginx]# kill -s SIGUSR2 106255[root@bogon nginx]# ps -ef |grep nginxroot     106255      1  0 16:45 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    106256 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106257 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106258 106255  0 16:45 ?        00:00:00 nginx: worker processnginx    106259 106255  0 16:45 ?        00:00:00 nginx: worker processroot     107206 106255  0 17:03 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    107207 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107208 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107209 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107210 107206  0 17:03 ?        00:00:00 nginx: worker processroot     107217   1480  0 17:04 pts/0    00:00:00 grep --color=auto nginx# （4）向旧的master进程发送 SIGWINCH 信号，旧的 worker子进程退出。此时，所有请求会被新的worker进程处理[root@bogon nginx]# kill -s SIGWINCH 106255[root@bogon nginx]# ps -ef |grep nginxroot     106255      1  0 16:45 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxroot     107206 106255  0 17:03 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    107207 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107208 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107209 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107210 107206  0 17:03 ?        00:00:00 nginx: worker processroot     107264   1480  0 17:04 pts/0    00:00:00 grep --color=auto nginx# （5）验证新的ngixn 的 worker子进程 发现有错误，开启回滚：# 向旧的master 发送 SIGHUP 信号；向 新的master进程发送 SIGQUIT 信号[root@bogon nginx]# kill -s SIGWINCH 106255[root@bogon nginx]# ps -ef |grep nginxroot     106255      1  0 16:45 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxroot     107206 106255  0 17:03 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    107207 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107208 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107209 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107210 107206  0 17:03 ?        00:00:00 nginx: worker processroot     107264   1480  0 17:04 pts/0    00:00:00 grep --color=auto nginx[root@bogon nginx]# kill -s SIGHUP 106255[root@bogon nginx]# ps -ef |grep nginxroot     106255      1  0 16:45 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxroot     107206 106255  0 17:03 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    107207 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107208 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107209 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107210 107206  0 17:03 ?        00:00:00 nginx: worker processnginx    107401 106255  0 17:07 ?        00:00:00 nginx: worker processnginx    107402 106255  0 17:07 ?        00:00:00 nginx: worker processnginx    107403 106255  0 17:07 ?        00:00:00 nginx: worker processnginx    107404 106255  0 17:07 ?        00:00:00 nginx: worker processroot     107412   1480  0 17:07 pts/0    00:00:00 grep --color=auto nginx[root@bogon nginx]# kill -s SIGQUIT 107206[root@bogon nginx]# ps -ef |grep nginxroot     106255      1  0 16:45 ?        00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnginx    107401 106255  0 17:07 ?        00:00:00 nginx: worker processnginx    107402 106255  0 17:07 ?        00:00:00 nginx: worker processnginx    107403 106255  0 17:07 ?        00:00:00 nginx: worker processnginx    107404 106255  0 17:07 ?        00:00:00 nginx: worker processroot     107440   1480  0 17:08 pts/0    00:00:00 grep --color=auto nginx# 至此，nginx热升级回滚成功\n\n\n\n\n\nNginx模块化设计机制模块结构图\n\n\n\n\n\n模块体系结构\n\n\n\n\n\nNginx编译安装的配置参数\n\n\n\n\n\n定制编译安装Nginx# （0）准备nginx的管理用户[root@bogon install]# useradd nginx# （1）准备安装文件[root@localhost install]# wget https://nginx.org/download/nginx-1.22.1.tar.gz[root@bogon install]# ll总用量 3688-rw-r--r--. 1 root root 1073322 5月  24 22:29 nginx-1.22.0.tar.gz-rw-r--r--. 1 root root 2085854 10月  6 16:08 pcre-8.43.tar.gz-rw-r--r--. 1 root root  607698 1月  16 2017 zlib-1.2.11.tar.gz# （2）解压安装文件[root@bogon install]# ll总用量 16drwxr-xr-x.  8 1001  1001  158 5月  24 07:59 nginx-1.22.0drwxr-xr-x.  7 1169  1169 8192 2月  24 2019 pcre-8.43drwxr-xr-x. 14  501 games 4096 1月  16 2017 zlib-1.2.11# （3）解压后进入 nginx源码目录，查看相关编译参数[root@bogon nginx-1.22.0]# ./configure --help# （4）编译安装前下载相关依赖[root@bogon nginx-1.22.0]# yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel gd gd-devel# （5）编译安装[root@bogon nginx-1.22.0]# ./configure --prefix=/usr/local/nginx --conf-path=/usr/local/nginx/conf/nginx.conf --user=nginx --group=nginx --pid-path=/usr/local/nginx/pid/nginx.pid --error-log-path=/usr/local/nginx/logs/error.log --with-pcre=/install/pcre-8.43 --with-zlib=/install/zlib-1.2.11 --with-http_ssl_module --with-http_image_filter_module --with-http_stub_status_module --http-log-path=/usr/local/nginx/logs/access.log[root@bogon nginx-1.22.0]# make[root@bogon nginx-1.22.0]# make install# 至次，nginx编译安装完成[root@bogon nginx-1.22.0]# cd /usr/local/nginx/[root@bogon nginx]# ll总用量 4drwxr-xr-x. 2 root root 4096 10月  6 16:16 confdrwxr-xr-x. 2 root root   40 10月  6 16:16 htmldrwxr-xr-x. 2 root root    6 10月  6 16:16 logsdrwxr-xr-x. 2 root root    6 10月  6 16:16 piddrwxr-xr-x. 2 root root   19 10月  6 16:16 sbin[root@bogon nginx]# sbin/nginx[root@bogon nginx]# ps -ef | grep nginxroot     104771      1  0 16:18 ?        00:00:00 nginx: master process sbin/nginxnginx    104772 104771  0 16:18 ?        00:00:00 nginx: worker processroot     104780   1480  0 16:18 pts/0    00:00:00 grep --color=auto nginx\n\n\n\n\n\nNginx配置文件结构\n\n\n\n\n\n虚拟主机的分类（三种）\n基于多IP的虚拟主机\n多网卡多IP\n单网卡多IP\n\n\n基于多端口的虚拟主机\n基于域名的虚拟主机\n\n\n\n基于多网卡的虚拟主机实现\n这里我们使用多网卡多IP的方式\n\nserver &#123;\tlisten\t192.168.146.132:8080;\tserver_name\tlocalhost;\tlocation / &#123;\t\troot\t/usr/local/nginx/html/virtual_host_by_ip/132;\t\tindex\tindex.html;\t&#125;&#125;server &#123;\tlisten\t192.168.146.133:8080;\tserver_name\tlocalhost;\tlocation / &#123;\t\troot\t/usr/local/nginx/html/virtual_host_by_ip/133;\t\tindex\tindex.html;\t&#125;&#125;server &#123;\tlisten\t192.168.146.134:8080;\tserver_name\tlocalhost;\tlocation / &#123;\t\troot\t/usr/local/nginx/html/virtual_host_by_ip/134;\t\tindex\tindex.html;\t&#125;&#125;\n\n\n\n\n\n基于端口的虚拟主机实现server &#123;\tlisten\t90;\tserver_name\tlocalhost;\tlocation / &#123;\t\troot\t/usr/local/nginx/html/virtual_host_by_port/90;\t\tindex\tindex.html;\t&#125;&#125;server &#123;\tlisten\t91;\tserver_name\tlocalhost;\tlocation / &#123;\t\troot\t/usr/local/nginx/html/virtual_host_by_port/91;\t\tindex\tindex.html;\t&#125;&#125;server &#123;\tlisten\t92;\tserver_name\tlocalhost;\tlocation / &#123;\t\troot\t/usr/local/nginx/html/virtual_host_by_port/92;\t\tindex\tindex.html;\t&#125;&#125;\n\n\n\n基于域名的虚拟主机实现server &#123;\tlisten\t9090;\tserver_name\ttest1.nginx.com;\tlocation / &#123;\t\troot\t/usr/local/nginx/html/virtual_host_by_domain/test1;\t\tindex\tindex.html;\t&#125;&#125;server &#123;\tlisten\t9090;\tserver_name\ttest2.nginx.com;\tlocation / &#123;\t\troot\t/usr/local/nginx/html/virtual_host_by_domain/test2;\t\tindex\tindex.html;\t&#125;&#125;server &#123;\tlisten\t9090;\tserver_name\ttest3.nginx.com;\tlocation / &#123;\t\troot\t/usr/local/nginx/html/virtual_host_by_domain/test3;\t\tindex\tindex.html;\t&#125;&#125;\n\n\n\n\n\n\n\n核心指令-Nginx基础应用配置文件main段核心参数用法# main段核心参数:user USERNAME [GROUP]    解释：指定运行nginx的worker子进程的属主和属组，其中属组可以不指定 \t示例：\t\tuser nginx nginx;pid DIR    解释：指定运行nginx的master主进程的pid文件存放路径 \t示例：\t\tpid /ropt/nginx/logs/nginx.pid;worker_rlimit_nofile number   \t解春：指定worker子进程可以打开的最大文件句柄数 \t示例：         worker_rlimit_nofile 20480;worker_rlimit_core size \t一 解释：指定worker子进程异常终止后的core文件，用于记录分析问题 \t示例：         worker_rlimit_core 50M;         working_directory /opt/nginx/tmp;worker_processes number | auto   解释：指定nginx启动的worker子进程数量   示例：         worker_processes 4;         worker_processes auto;worker_cpu_affinity cpumaskl cpumask2...   解霹：将每个worker子进程与我们的CPU物理核心绑定。   示例：         worker_cpu_affinity 0001 0010 0100 1000； #         4个物理核心，4个worker子进程         worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000         00100060 01000000 10000000; # 8物理核心，8个worker子进程         worker_cpu_affinity 01 10 01 10;         # 2个物理核心，4个子进程  备注：将每个worker子进程与特定CPU物理核心绑定，优势在于：避免同个worker子进程  在不同的CPU核心上切换，缓存失效，降低性能；其并不能真正的避免进程切换worker_priority number   解释：指定worker子进程的nice值，以调整运行nginx的优先级，通常设定为负值，以优先 调用nginx   示例：        worker_priority -10;   备注：Linux默认进程的优先级值是120,值越小越优先；nice设定范围为-20到+19worker_shutdown_timeout time   解春：指定证WOrker子进程优雅退出时的超时时间   示例：        worker_shutdown_timeout 5s;timer_resolution time   解释：worker子进程内部使用的计时器精度，调整时间间隔越大，系统调用越少，有利于性 能提升；反之，系统调用越多，性能下降   示例：        worker_resolution 100ms;daemon on|off  解释：设定nginx的运行方式，前台还是后台，前台用户调试，后台用于生产 示例：       daemon off;lock_file DIR  解释：负载均衡互斥锁文件存放路径       lock_file logs/nginx.lock\t\n\n\n\n配置文件events段核心参数用法\n\n\n参数\n含义\n\n\n\nuse\nnginx使用何种事件驱动模型\n\n\nworker_connections\nworker子进程能够处理的最大并发连接数\n\n\naccept_mutex\n是否打开负载均衡互斥锁\n\n\naccept_mutex_delay\n新连接分配给worker子进程的超时时间\n\n\nmuti_accept\nworker子进程可以接收的新连接个数\n\n\n\n\n\n参数\n语法\n可选值\n默认配置\n推荐配置\n\n\n\nuse\nuse method\nselect、poll、kqueue、epoll、/dev/poll、eventport\n无\n不指定，让nginx自己选择\n\n\nworker_connections\nworker_connections number\n\nworker_connections 1024\nworker_connections 65535/worker_processes|65535\n\n\naccept_mutex\naccept_mutex on|off\non、off\naccept_mutex off\naccept_mutex on\n\n\naccept_mutex_delay\naccept_mutex_delay time\n\naccept_mutex_delay 500ms\naccept_mutex_delay 200ms\n\n\nmuti_accept\nmuti_accept on|off\non、off\nmuti_accept off\nmuti_accept on\n\n\n\n\n配置文件http段核心参数用法server_name指令# 可以写多个server name，可以使用正则表达式，通配符，也可以是ip 具体的域名。server_name name1 name2 name3;\n\n\n匹配优先级\n精确匹配 &gt; 左侧通配符匹配 &gt; 右侧通配符匹配 &gt; 正则表达式匹配\n\n\n\n\n\nroot和alias\n\n\n\n语法\n上下文\n共同点\n区别\n\n\n\nroot\nroot path;\nhttp server location if\nURI到磁盘文件的映射\nroot会将定义路径与URI叠加\n\n\nalias\nalias path;\nlocation\nURI到磁盘文件的映射\nalias只取定义路径\n\n\n\n\nlocation的基础用法# 语法：\tlocaltion [ = | ~ | ~* | ^~ ] uri &#123;...&#125;\t# 上下文：\tserver location\n\n\n\n\n匹配规则\n含义\n示例\n\n\n\n=\n精确匹配\nlocation = /images/ &#123;...&#125;\n\n\n~\n正则匹配，区分大小写\n`location ~ .(jpg\n\n\n~*\n正则匹配，不区分大小写\n`location ~* .(jpg\n\n\n^~\n匹配到即停止搜索\nlocation ^~ /images/ &#123;...&#125;\n\n\n不带任何符号\n\nlocation / &#123;...&#125;\n\n\n\n匹配规则优先级\n\n\n\n\n\n理解location中url结尾的反斜线location /some-dir &#123;&#125;location /some-dir/ &#123;&#125;\n\n\n如果URL的结构是https://domain.com/some-dir/。尾部如果缺少/将导致重定向。因为根据约定，URL尾部的/表示目录，没有/表示文件。\n所以访问/some-dir/时，服务器会自动去该目录下找对应的默认文件。\n如果访问/some-dir的话，服务器会先去找some-dir文件，找不到的话会将some-dir当成目录，重定向到/some-dir/，去该目录下找默认文件。\n\n\n\n\n\nstub_status模块用法\nstub_status的使用，需要Nginx编译进去\n\n# 语法结构\tstub_status;# 低于1.7.5 版本：\tstub_status on;# 上下文：\tserver location\t# 配置示例\tlocation /uri &#123;\t\tstub_status;\t&#125;\n\n\n状态项\n\n\n\n\n\n\n内嵌变量\n\n\n\n\n\n\n\n\n\nHTTP核心模块connection &amp; request\nconnection 是连接，即常说的tcp连接，三次握手，状态机\nrequest是请求，例如http请求，无状态的协议\nrequest是必须建立在connection之上的\n\n学习备注\n\nlinux信号量这块的管理机制可以再抽时间深入理解一下\n第三章、4 的相关内容算是比较简单，后续实践一下\n需要理解请求过程，连接、请求\n其实第二章的内容也很重要，要对Nginx有总体上的认知，特点、优势等等，需要说出个所以然来\n多进程和多线程相关的知识还需要深入理解一下\nNginx的模块整体还需要有一个把握\nlocation这块的内容 还需要进一步熟悉一下\n\n\n\n\n\n\n\n\n\n\n","categories":["Nginx"],"tags":["Nginx"]},{"title":"《一站式学习Redis-从入门到高可用分布式实践》study notes","url":"/%E3%80%8A%E4%B8%80%E7%AB%99%E5%BC%8F%E5%AD%A6%E4%B9%A0Redis-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E9%AB%98%E5%8F%AF%E7%94%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E8%B7%B5%E3%80%8Bstudy-notes/","content":"Redis初识Redis是什么\n开源\n基于键值的存储服务系统\n多种数据结构\n高性能、功能丰富\n\n\n\nRedis的特性\n速度快（10w OPS）\n数据存储在内存（速度快的主要原因）\n使用C语言编写\n单线程\n\n\n持久化\nRedis的所有数据保存在内存中，对数据的更新异步的保存在磁盘上\n\n\n多种数据结构\n5中主要类型\n\n\n支持多种编程语言\n主流编程语言都支持Redis\n\n\n功能丰富\n发布订阅\n事物\nlua脚本\npipeline\n\n\n简单\n早期代码23000行\n不依赖外部库\n单线程模型\n\n\n主从复制\n高可用、分布式\n\n\n\nRedis典型使用场景\n缓存系统\n计数器\n消息队列系统\n排行榜\n社交网络\n事实系统\n\n\n\nRedis安装\n安装前环境准备\n\nyum -y install gcc gcc-c++ kernel-devel\n\n\n下载安装\n\n[root@localhost ~]# cd /install[root@localhost install]# wget https://github.com/redis/redis/archive/7.0.4.tar.gz[root@localhost install]# tar -zxvf redis-7.0.4.tar.gz[root@localhost install]# mv redis-7.0.4 /usr/local/[root@localhost install]# cd /usr/local/[root@localhost local]# ln -s redis-7.0.4/ redis[root@localhost local]# cd redis# 直接 make 会失败报错 原因：建立redis时系统默认使用jemalloc作为内存管理工具，但是当前无可用jemalloc，切换为标准内存管理工具libc问题解决[root@localhost redis]# make MALLOC=libc[root@localhost redis]# make install\n\n\n\n\n\n\n\nRedis三种启动方式\n最简启动\n\n# 使用默认配置启动redis-server\n\n\n动态参数启动\n\nredis-server --port 6380\n\n\n配置文件启动（推荐）\n\nredis-server configPath\n\n\n启动方式比较\n\n\n生产环境选择配置启动\n单机多实例配置文件可以用端口区分开来\n\n\n\n验证ps -ef |grep redisnetstat -antpl |grep redisredis-cli -h [ip] -p [port] ping \n\n\n\nRedis可执行文件说明\nredis-server    -    redis服务器\nredis-cli    -    redis命令行客户端\nredis-benchmark    -    redis性能测试工具\nredis-check-aof    -    AOF文件修复工具\nredis-check-dump    -    RDB文件检查工具\nredis-sentinel    -    Sentinel服务器（2.8之后）\n\n\n\nRedis常用配置# 是否以守护进程方式启动 [yes|no]daemonize yes# redis 对外端口port 6380# 配置日志名称logfile &quot;6380.log&quot;# redis 工作目录（包括日志文件、持久化文件存储位置）dir &quot;/usr/local/redis/data/&quot;\n\n\n\nAPI的理解和使用通用命令# 遍历所有的key，可以使用通配符# 复杂度 O(n) ，不建议在生产环境使用，除非数量特别小keys *# 内置的对键值 统计的计数器dbsize# 检查key是否存在，返回 1 或 0exists# 删除指定 key-value，返回 1 或 0del key [key...]# 设置 key 在 seconds 秒后过期expire key seconds# 查询key 还有多长时间过期，不过期则返回 -1ttl key# 去除过期时间，persist key# 不存在则返回 nonetype key\n\n\n\n数据结构和内部编码\n\n\n\n\nredisObject\n\n\n\n\n\n单线程单线程为什么这么快\n纯内存（主要原因）\n阻塞IO\n避免线程切换和竞态消耗\n\n\n\n注意事项\n一次只运行一条命令\n\n拒绝长（慢）命命令：kesy flushall flushdb slow lua script mutil/exec operate big value(collection)\n\n其实不是单线程：fysnc file descriptor close file descriptor\n\n\n\n\nString（字符串）结构\n可以是真的字符串，同时也可以是数字，二进制数字等等。大小限制 512MB\n\n\n\n\n\n场景\n缓存\n计数器\n分布式锁\n……\n\n\n\n命令\n\n\n命令\n举例\n时间复杂度\n说明\n\n\n\nset\nset hello word\nO(1)\n不管key是否存在，都设置。成功返回ok\n\n\nsetnx\nsetnx k v\nO(1)\nkey不存在才设置\n\n\nset xx\nset k v xx\nO(1)\nkey存在才设置。不存在返回nil\n\n\nmset\nmset k1 v1 k2 v2\nO(n)\n批量设置key-value，原子操作\n\n\ndel\ndel hello\nO(1)\n成功返回1,失败返回0\n\n\nget\nget hello\nO(1)\n成功返回的value，失败返回nil\n\n\nmget\nmget k1 k2\nO(n)\n批量获取key-value，原子操作\n\n\nincr\nincr counter\nO(1)\n自增1，并返回自增后的value值。如果key不存在，自增后get(key) = 1\n\n\ndecr\ndecr counter\nO(1)\n自减1，并返回自减后的value值。如果key不存在，自减后get(key) = -1\n\n\nincrby\nincrby view k\nO(1)\n自增k，并返回自增k后的value值。如果key不存在，自增后get(key) = k\n\n\ndecrby\ndecrby view k\nO(1)\n自减k，并返回自减后的value值。如果key不存在，自减后get(key) = -k\n\n\ngetset\ngetset k newvalue\nO(1)\nset key newValue，并返回旧的value\n\n\napend\napend k v\nO(1)\n将value追加到旧的value\n\n\nstrlen\nstrlen k\nO(1)\n返回字符串的长度[字节]（utf-8 中文占 2个字节）\n\n\nincrbyfloat\nincrbyfloat k v\nO(1)\n增加指定的浮点数\n\n\ngetrange\ngetrange k start end\nO(1)\n获取字符串指定下标所有的值\n\n\nsetrange\nsetrange k index value\nO(1)\n设置指定下标对应的值\n\n\n\n\n实战\n记录网站每个用户的个人主页访问量\n\n# 单线程：无竞争（并发不会出现计错数的情况）incr userId:pageView\n\n\n\n\n缓存视频的基本信息（数据源在MySQL中）\n\n\n\n\n\n\n分布式id生成器\n\n\n\n查漏补缺\n\n\n\n\n\n\n\n\n\n\n\nhash（哈希）\n\nRedis客户端Java客户端JedisJedis简单使用\nmaven依赖\n\n&lt;dependency&gt;    &lt;groupId&gt;redis.clients&lt;/groupId&gt;    &lt;artifactId&gt;jedis&lt;/artifactId&gt;    &lt;version&gt;2.9.0&lt;/version&gt;    &lt;type&gt;jar&lt;/type&gt;    &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;\n\n\nJedis直连\n\n\n\n\n\nJedisPool简单使用\n\n\n\n\n\n\n\nJedis 与 JedisPool比较\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJedis配置优化pool配置 - 资源数控制\n\n\n\npool配置 - 借还参数\n\n\n\n适合的 maxTotal\n\n\n\n\n\n\n\n适合的maxIdle和minIdle\n\n\n\n常见问题和解决思路\n常见问题\n\n\n\n\n\n\n解决思路\n\n\n\n\n\n\n错误示例\n\n\n\n\n\n\n推荐写法\n\n\n\n\n\nRedis其他功能slowlog（慢查询）命令生命周期\n\n\n\n\n（1）慢查询发生在第3阶段\n（2）客户端超时不一定是慢查询，但慢查询是客户端超时的一个可能因素\n\n\n\n配置slowlog-max-len\nslowlog-max-len 表示慢查询队列长度\n\n慢查询是一个先进先出的队列；如果在第3步执行过程中，被列入慢查询的范围内，就会进入一个队列（用redis的列表实现的）\n\n慢查询队列是固定长度的\n\n慢查询队列数据保存在内存中\n\n\n\n\n\n\nslowlog-log-slower-than\nslowlog-log-slower-than 表示慢查询命令执行时间阈值（单位：微秒，1ms=1000微秒），超过阈值会被加入慢查询队列中\nslowlog-log-slower-than = 0 ，记录所有命令\nslowlog-log-slower-than &lt; 0 ，不记录任何命令\n\n\n\n默认值127.0.0.1:6380&gt; config get slowlog-max-len1) &quot;slowlog-max-len&quot;2) &quot;128&quot;# 10000微秒 =》 10ms127.0.0.1:6380&gt; config get slowlog-log-slower-than1) &quot;slowlog-log-slower-than&quot;2) &quot;10000&quot;\n\n\n\n配置方法\n方法一：修改配置文件重启（一般在第一次启动redis前进行配置。但如果redis正在运行中，不推荐此方式）\n\n方法二：动态配置\n\n\nconfig set slowlog-max-len 1000config set slowlog-log-slower-than 1000\n\n# 操作示例127.0.0.1:6380&gt; config set slowlog-max-len 1000OK127.0.0.1:6380&gt; config set slowlog-log-slower-than 1000OK127.0.0.1:6380&gt; config get slowlog-max-len1) &quot;slowlog-max-len&quot;2) &quot;1000&quot;127.0.0.1:6380&gt; config get slowlog-log-slower-than1) &quot;slowlog-log-slower-than&quot;2) &quot;1000&quot;127.0.0.1:6380&gt;\n\n\n\n慢查询命令\n\n\n慢查询命令\n说明\n\n\n\nslowlog get [n]\n获取慢查询队列指定条数\n\n\nslowlog len\n获取慢查询队列长度\n\n\nslowlog reset\n清空慢查询队列\n\n\n\n\n运维经验\nslowlog-max-len不要设置过大。默认10ms，通常设置1ms（实际情况要根据QPS来决定阈值大小，有可能1ms就已经对我们的QPS产生影响了）\nslowlog-log-slower-than不要设置过小，通常设置1000左右\n理解命令生命周期，理解慢查询处于命令生命周期的位置。便于我们排错和优化（慢查询、阻塞、网络都可能成为客户端超时的原因）\n定期持久化查询（因为慢查询是存在内存中的，且当慢查询数量逐步增多，早前的慢查询就会丢掉。做好持久化，可以分析历史的慢查询问题）。可以通过其它手段或开源软件实现这个功能\n\n\n\npipeline（流水线）网络命令通信模型1次网络命令通信模型\n\n\n\n批量网络命令通信模型\n\n\n\n什么是pipeline（流水线）\n我们知道redis的命令执行是很快的，但是网络时间却不一定。使用pipeline可以帮我们节约大量网络时间\n\n\n\n\n\npipeline的作用\n\n\n命令\nN个命令操作\n1次pipeline（N个命令）\n\n\n\n时间\nn次网络+n次命令\n1次网络时间+n次命令\n\n\n数量\n1条命令\nn条命令\n\n\n\n注意\n\n\nRedis的命令时间是微秒级别\npipeline每次条数要控制（网络）\n\n\n举例\n\n\n\n\n\npipeline的jedis实现\n添加maven依赖\n\n&lt;dependency&gt;    &lt;groupId&gt;redis.clients&lt;/groupId&gt;    &lt;artifactId&gt;jedis&lt;/artifactId&gt;    &lt;version&gt;2.9.0&lt;/version&gt;    &lt;type&gt;jar&lt;/type&gt;    &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;\n\n\n\n\n没有pipe-line\n\n\n\n\n\n\n使用pipeline\n\n\n\n\n\npipeline与mget/mset操作的对比\n原生M操作\n\n\n\n\n\n\npipeline\n\n\n\n\n\npipeline命令可拆分\n\n\npipeline使用建议\n注意每次pipeline携带数量\npipeline每次只能作用在一个Redis节点上\n注意pipeline与M操作的区别\n\n发布订阅角色\n发布者（publisher）\n订阅者（subscriber）\n频道（channel）\n\n\n\n发布订阅模型\n\n\n\n\n新的订阅者订阅了一个频道，是无法收到之前的消息（因为无法做消息堆积，因为redis不是一个真正的消息队列这样一个工具）\n\n\n\n发布订阅APIpublish# 向频道发布消息PUBLISH [channel_name] [message]127.0.0.1:6380&gt; publish sohu:tv &quot;hello world&quot;(integer) 0127.0.0.1:6380&gt; publish sohu:auto &quot;taxi&quot;(integer) 0\n\n\n\nsubscribe# 订阅一个或多个频道SUBSCRIBE [channel_name]...127.0.0.1:6380&gt; subscribe sohu:tvReading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;sohu:tv&quot;3) (integer) 1\n\n\n\nunsubscribe# 订阅一个或多个频道UNSUBSCRIBE [channel_name]...127.0.0.1:6380&gt; UNSUBSCRIBE sohu:tv1) &quot;unsubscribe&quot;2) &quot;sohu:tv&quot;3) (integer) 0\n\n\n\n其它API\n\n\n\n\n\n发布订阅与消息队列\nRedis可以实现消息队列，消息队列是抢的模式\n注意二者的区别与使用场景\n\n\n\n\n\nBItmap（位图）HyperLogLog\nRedis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的（基于HyperLogLog算法：极小空间完成独立数量统计）\n本质还是字符串\n\n\n\nAPI（命令）# Pfadd 命令将所有元素参数添加到 HyperLogLog 数据结构中redis 127.0.0.1:6379&gt; PFADD key element [element ...]redis 127.0.0.1:6379&gt; PFADD mykey a b c d e f g h i j(integer) 1redis 127.0.0.1:6379&gt; PFCOUNT mykey(integer) 10\n\n# Pfcount 命令返回给定 HyperLogLog 的基数估算值redis 127.0.0.1:6379&gt; PFCOUNT key [key ...]redis 127.0.0.1:6379&gt; PFADD hll foo bar zap(integer) 1redis 127.0.0.1:6379&gt; PFADD hll zap zap zap(integer) 0redis 127.0.0.1:6379&gt; PFADD hll foo bar(integer) 0redis 127.0.0.1:6379&gt; PFCOUNT hll(integer) 3redis 127.0.0.1:6379&gt; PFADD some-other-hll 1 2 3(integer) 1redis 127.0.0.1:6379&gt; PFCOUNT hll some-other-hll(integer) 6redis&gt; \n\n#  PFMERGE 命令将多个 HyperLogLog 合并为一个 HyperLogLog ，合并后的 HyperLogLog 的基数估算值是通过对所有 给定 HyperLogLog 进行并集计算得出的PFMERGE destkey sourcekey [sourcekey ...]redis&gt; PFADD hll1 foo bar zap a(integer) 1redis&gt; PFADD hll2 a b c foo(integer) 1redis&gt; PFMERGE hll3 hll1 hll2&quot;OK&quot;redis&gt; PFCOUNT hll3(integer) 6redis&gt;  \n\n\n\n示例（百万独立用户-内存消耗）\n\n\n\n使用经验\n是否能容忍错误？（错误率：0.81%）\n是否需要单条数据？\n\n\n\nGEO\nRedis GEO 主要用于存储地理位置信息，并对存储的信息进行操作（存储经纬度，计算两地距离，范围计算等）\n底层使用 zset 实现\n\n\n\n应用场景\n类似微信摇一摇（计算指定范围类的用户）\n根据距离计算周围的酒店餐馆等\n\n\n\nAPI\ngeoadd：添加地理位置的坐标。\ngeopos：获取地理位置的坐标。\ngeodist：计算两个位置之间的距离。\ngeoradius：根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。\ngeoradiusbymember：根据储存在位置集合里面的某个地点获取指定范围内的地理位置集合。\ngeohash：返回一个或多个位置对象的 geohash 值。\n\n\n\nRedis持久化的取舍和选择持久化的作用\n什么是持久化\n\n\nredis所有的数据保存在内存中，对数据的更新将异步的保存在磁盘上\n\n内存 =》（持久化）=》磁盘\n内存 《=（恢复）《= 磁盘\n\n持久化的方式\n\n\n\n\n\nRDB（Redis DataBase）什么是RDB\nRDB：在不同的时间点，将 redis 存储的数据生成快照并存储到磁盘等介质上\n\n\n\n\n\nRDB触发机制的三种方式save（同步）\n可能会造成阻塞\n\n\n\n\n\n127.0.0.1:6380&gt;  saveOK\n\n\n文件策略：生成临时的rdb文件，当save执行完后。如果存在老的rdb文件，临时文件变成新文件替换老文件\n复杂度：O(n)\n\n\n\nbgsave（异步）\n客户端执行 bgsave redis会使用linux的 fork() 函数生成一个redis的子进程，由该子进程生成RDB文件\n一般情况下， bgsave 不会阻塞到redis\n\n\n\n\n\n127.0.0.1:6380&gt; bgsaveBackground saving started\n\n\n文件策略：生成临时的rdb文件，当save执行完后。如果存在老的rdb文件，临时文件变成新文件替换老文件\n复杂度：O(n)\n\n\n\nsave 与 bgsave比较\n\n\n\n自动\n\n\n\n\n说明：在 60s 中改变了10000 条数据（set，del），会自动做rdb的生成\n\n\n\n缺点\n数据写入量无法控制，生成规则无法控制。如果文件非常大，或很频繁的做这样的操作，会对硬盘造成一定压力\n\n\n\n默认配置################################ 快照  #################################  #  # Save the DB on disk:保存数据库到磁盘  #  #   save &lt;秒&gt; &lt;更新&gt;  #  #   如果指定的秒数和数据库写操作次数都满足了就将数据库保存。  #  #   下面是保存操作的实例：  #   900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化）  #   300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化）  #   60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化）  #  #   注释：注释掉“save”这一行配置项就可以让保存数据库功能失效。  #  #   你也可以通过增加一个只有一个空字符串的配置项（如下面的实例）来去掉前面的“save”配置。  #  #   save &quot;&quot;    save 900 1  save 300 10  save 60 10000    #在默认情况下，如果RDB快照持久化操作被激活（至少一个条件被激活）并且持久化操作失败，Redis则会停止接受更新操作。  #这样会让用户了解到数据没有被正确的存储到磁盘上。否则没人会注意到这个问题，可能会造成灾难。  #  #如果后台存储（持久化）操作进程再次工作，Redis会自动允许更新操作。  #  #然而，如果你已经恰当的配置了对Redis服务器的监视和备份，你也许想关掉这项功能。  #如此一来即使后台保存操作出错,redis也仍然可以继续像平常一样工作。  stop-writes-on-bgsave-error yes    #是否在导出.rdb数据库文件的时候采用LZF压缩字符串和对象？  #默认情况下总是设置成‘yes’， 他看起来是一把双刃剑。  #如果你想在存储的子进程中节省一些CPU就设置成&#x27;no&#x27;，  #但是这样如果你的kye/value是可压缩的，你的到处数据接就会很大。  rdbcompression yes    #从版本RDB版本5开始，一个CRC64的校验就被放在了文件末尾。  #这会让格式更加耐攻击，但是当存储或者加载rbd文件的时候会有一个10%左右的性能下降，  #所以，为了达到性能的最大化，你可以关掉这个配置项。  #  #没有校验的RDB文件会有一个0校验位，来告诉加载代码跳过校验检查。  rdbchecksum yes    # 导出数据库的文件名称  dbfilename dump.rdb    # 工作目录  #  # 导出的数据库会被写入这个目录，文件名就是上面&#x27;dbfilename&#x27;配置项指定的文件名。  #   # 只增的文件也会在这个目录创建（这句话没看明白）  #   # 注意你一定要在这个配置一个工作目录，而不是文件名称。  dir ./  \n\n\n\n最佳配置\n\n\n\n\n关闭自动配置\n\n触发机制 - 不容忽略方式\n全量复制（主从复制时候，主会自动生成RDB）\ndebug reload（相当于不会将内存清空的重启，也会生成RDB）\nshutdown\n\n\n\nRDB现存问题\n耗时耗性能\n\n\n\n\n\n\n不可控，丢失数据\n\n\n\n\n\nAOF（Append Only File）\n将 redis 执行过的所有写指令记录下来（它的写入是实时的），在下次 redis 重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了\n\nAOF运行原理\n创建\n\n\n\n\n\n\n恢复\n\n\n\n\n\nAOF的三种策略always\n写入数据不会丢失\n\n\n\n\n\neverysec\n是redis的配置默认值\n可能会丢失1s的数据\n\n\n\n\n\nno\n根据操作系统决定\n\n\n\nAOF的三种策略对比\n\n\n\nAOF重写\n减少磁盘占用量\n加速恢复速度\n\n\n\n\n\nAOF重写的两种方式\nBGREWRITEAOF （类似rdb的bgsave）\n将Redis中的数据进行回溯， 回溯成AOF文件\n\n\n\n\n\n\n\n\nAOF重写配置\n\n\n\n\n\n\n\n\n\n\n\n\n\nAOF重写流程\n\n\n\nRDB与AOF的抉择\n\n\n\nRDB最佳策略\nRDB\n\n\n”关闭“\n集中管理\n主从，从开\n\nAOF最佳策略\n”开“：缓存和存储\nAOF集中管理\neverysec\n\n最佳策略\n小分片\n缓存或存储\n监控（硬盘、内存、负载、网络）\n足够的内存\n\n\n\n常见的持久化开发运维问题fork操作\n\n\n\n\n\n\n\nfork改善\n\n\n\n\n\n\n\n子进程开销和优化\n\n\n\n\n\n\n硬盘优化\n\n\n\nAOF追加阻塞\n\n\n\nAOF阻塞定位\n\n\n\n\n\n\n\n\n\n\n\nRedis复制的原理与优化什么是主从复制\n一个master可以有多个slave，但一个slave只能有一个master\n数据流向必须是单向的。master -&gt; slave\n变成从节点前会把数据清楚\n\n主从复制作用\n一个数据提供了多个副本（成为高可用、分布式的基础）\n扩展读性能（读写分离）\n\n主从复制实现slaveof 命令\n复制（slaveof 这个命令是异步的）\n\n\n\n\n\n\n取消复制\n\n\n\n\n\n配置slaveof ip portslave-read-only yes\n\n\n\n主从复制-命令和配置的比较\n\n\n方式\n命令\n配置\n\n\n\n优点\n无需重启\n统一配置\n\n\n缺点\n不便于管理\n需要管理\n\n\n主从配置操作info replication\n\n\n\n主从复制原理全量复制过程原理\n\n\n\n全量复制开销\nbgsave时间\nRDB文件网络传输时间\n从节点清空数据时间\n从节点加载RDB时间\n可能的AOF重写时间\n\n部分复制过程原理\n\n\n\n主从复制中的故障处理与常见问题\n故障不可避免\n自动故障转移\n故障分为master故障和slave故障\n\n读写分离问题\n\n\n\n配置不一致\n\n\n\n规避全量复制\n\n\n\n规避复制风暴\n\n\n\nRedis Sentinel第9章 初识Redis Cluster\n\n学习备注\n\njedis 需要熟悉,有些代码还要手动过一遍才是\n生产环境普通用户后台启动redis\n部分图片内容是否应该转化为代码呢？\nbitmap不太懂，还需要深入理解。还包括 hyperloglog、geo\nRDB和AOF的恢复原理和过程是怎么样子的？\n主从复制操作虽然简单，但是最好是实践一下\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","categories":["database","redis","nosql","redis"],"tags":["database","redis","nosql"]}]